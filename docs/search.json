[{"path":"/articles/overview.html","id":"software","dir":"Articles","previous_headings":"","what":"Software","title":"precmed Overview","text":"precmed package CRAN precmed GitHUB repository","code":""},{"path":"/articles/overview.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"precmed Overview","text":"precmed package can installed CRAN follows: latest version can installed GitHub follows:","code":"install.packages(\"precmed\") install.packages(\"devtools\") devtools::install_github(\"smartdata-analysis-and-statistics/precmed\")"},{"path":"/articles/overview.html","id":"capabilities-of-precmed-package","dir":"Articles","previous_headings":"","what":"Capabilities of precmed package","title":"precmed Overview","text":"precmed package contains functions Estimate average treatment effects count, survival contiuous data Estimate conditional average treatment effect (CATE) score count, survival continuous data Cross-validation CATE score Compute area curves Plot validation curves","code":""},{"path":"/articles/overview.html","id":"main-functions","dir":"Articles","previous_headings":"","what":"Main functions","title":"precmed Overview","text":"main functions precmed package :","code":""},{"path":"/articles/overview.html","id":"background-materials","dir":"Articles","previous_headings":"","what":"Background materials","title":"precmed Overview","text":"Zhao et al. (2013), Effectively selecting target population future comparative study Yadlowsky et al. (2020), Estimation validation ratio-based conditional average treatment effects using observational data","code":""},{"path":"/articles/overview.html","id":"vignettes","dir":"Articles","previous_headings":"","what":"Vignettes","title":"precmed Overview","text":"construction [General introduction precmed] [Example count outcome] [Example survival outcome] [Detailed examples] [Theoretical details]","code":""},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lu Tian. Author. Xiaotong Jiang. Author. Gabrielle Simoneau. Author. Biogen  MA  Inc.. Copyright holder. Thomas Debray. Contributor, maintainer. Stan Wijn. Contributor. Joana Caldas. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Tian L, Jiang X, Simoneau G (2022). precmed: Precision Medicine. R package version 1.0.0.9000.","code":"@Manual{,   title = {precmed: Precision Medicine},   author = {Lu Tian and Xiaotong Jiang and Gabrielle Simoneau},   year = {2022},   note = {R package version 1.0.0.9000}, }"},{"path":"/index.html","id":"precmed-precision-medicine-in-r-","dir":"","previous_headings":"","what":"Precision Medicine","title":"Precision Medicine","text":"doubly robust precision medicine approach estimate validate conditional average treatment effects","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Precision Medicine","text":"precmed package can installed CRAN follows: latest version can installed GitHub follows:","code":"install.packages(\"precmed\") install.packages(\"devtools\") devtools::install_github(repo = \"smartdata-analysis-and-statistics/precmed\")"},{"path":"/index.html","id":"capabilities-of-precmed-package","dir":"","previous_headings":"","what":"Capabilities of precmed package","title":"Precision Medicine","text":"precmed package contains functions Estimate average treatment effects count, survival contiuous data Estimate conditional average treatment effect (CATE) score count, survival continuous data Cross-validation CATE score Compute area curves Plot validation curves","code":""},{"path":"/index.html","id":"main-functions","dir":"","previous_headings":"","what":"Main functions","title":"Precision Medicine","text":"main functions precmed package :","code":""},{"path":"/index.html","id":"background-materials","dir":"","previous_headings":"","what":"Background materials","title":"Precision Medicine","text":"Zhao et al. (2013), Effectively selecting target population future comparative study Yadlowsky et al. (2020), Estimation validation ratio-based conditional average treatment effects using observational data","code":""},{"path":"/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"Precision Medicine","text":"construction General introduction precmed Example count outcome Example survival outcome Detailed examples Theoretical details","code":""},{"path":"/reference/abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the area between curves from the ","title":"Compute the area between curves from the ","text":"Compute area curves (ABC) scoring method \"precmed\" object. run results catecv() obtained.","code":""},{"path":"/reference/abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the area between curves from the ","text":"","code":"abc(x)"},{"path":"/reference/abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the area between curves from the ","text":"x object class \"precmed\".","code":""},{"path":"/reference/abc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the area between curves from the ","text":"Returns matrix numeric values number columns equal number cross-validation iteration number rows equal number scoring methods x.","code":""},{"path":"/reference/abc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the area between curves from the ","text":"ABC area validation curve overall ATE validation set. calculated scoring method separately. Higher ABC values preferable indicate treatment effect heterogeneity captured scoring method. Negative values ABC possible segments validation curve cross overall ATE line. ABC calculated auc() MESS package natural cubic spline interpolation. calculation ABC always based validation curves based 100 proportions equally spaced min(prop.cutoff) max(prop.cutoff). ABC metric help users select best scoring method terms capturing treatment effect heterogeneity data. used complement visual inspection validation curves validation set plot().","code":""},{"path":"/reference/abc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the area between curves from the ","text":"Zhao, L., Tian, L., Cai, T., Claggett, B., & Wei, L. J. (2013). Effectively selecting target population future comparative study. Journal American Statistical Association, 108(502), 527-539.","code":""},{"path":[]},{"path":"/reference/abc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the area between curves from the ","text":"","code":"# \\donttest{ # Count outcome cv_count <- catecv(response = \"count\",                    data = countExample,                    score.method = \"poisson\",                    cate.model = y ~ age + female + previous_treatment +                                 previous_cost + previous_number_relapses +                                 offset(log(years)),                    ps.model = trt ~ age + previous_treatment,                    higher.y = FALSE, cv.n = 5, verbose = 1)  # ABC of the validation curves for each method and each CV iteration abc(cv_count)  # Survival outcome library(survival) cv_surv <- catecv(response = \"survival\",                   data = survivalExample,                   score.method = c(\"poisson\", \"randomForest\"),                   cate.model = Surv(y, d) ~ age + female + previous_cost +                                previous_number_relapses,                   ps.model = trt ~ age + previous_treatment,                   higher.y = FALSE,                   cv.n = 5)  # ABC of the validation curves for each method and each CV iteration abc(cv_surv)  # }"},{"path":"/reference/abc.precmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the area between curves from the ","title":"Compute the area between curves from the ","text":"Compute area curves (ABC) scoring method \"precmed\" object. run results catecv() obtained.","code":""},{"path":"/reference/abc.precmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the area between curves from the ","text":"","code":"# S3 method for precmed abc(x)"},{"path":"/reference/abc.precmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the area between curves from the ","text":"x object class \"precmed\".","code":""},{"path":"/reference/abc.precmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the area between curves from the ","text":"Returns matrix numeric values number columns equal number cross-validation iteration number rows equal number scoring methods x.","code":""},{"path":"/reference/abc.precmed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the area between curves from the ","text":"ABC area validation curve overall ATE validation set. calculated scoring method separately. Higher ABC values preferable indicate treatment effect heterogeneity captured scoring method. Negative values ABC possible segments validation curve cross overall ATE line. ABC calculated auc() MESS package natural cubic spline interpolation. calculation ABC always based validation curves based 100 proportions equally spaced min(prop.cutoff) max(prop.cutoff). ABC metric help users select best scoring method terms capturing treatment effect heterogeneity data. used complement visual inspection validation curves validation set plot().","code":""},{"path":"/reference/abc.precmed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the area between curves from the ","text":"Zhao, L., Tian, L., Cai, T., Claggett, B., & Wei, L. J. (2013). Effectively selecting target population future comparative study. Journal American Statistical Association, 108(502), 527-539.","code":""},{"path":[]},{"path":"/reference/abc.precmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the area between curves from the ","text":"","code":"# \\donttest{ # Count outcome cv_count <- catecv(response = \"count\",                    data = countExample,                    score.method = \"poisson\",                    cate.model = y ~ age + female + previous_treatment +                                 previous_cost + previous_number_relapses +                                 offset(log(years)),                    ps.model = trt ~ age + previous_treatment,                    higher.y = FALSE, cv.n = 5, verbose = 1)  # ABC of the validation curves for each method and each CV iteration abc(cv_count)  # Survival outcome library(survival) cv_surv <- catecv(response = \"survival\",                   data = survivalExample,                   score.method = c(\"poisson\", \"randomForest\"),                   cate.model = Surv(y, d) ~ age + female + previous_cost +                                previous_number_relapses,                   ps.model = trt ~ age + previous_treatment,                   higher.y = FALSE,                   cv.n = 5)  # ABC of the validation curves for each method and each CV iteration abc(cv_surv)  # }"},{"path":"/reference/arg.checks.common.html","id":null,"dir":"Reference","previous_headings":"","what":"Check arguments that are common to all types of outcome\r\nUSed inside arg.checks() — arg.checks.common","title":"Check arguments that are common to all types of outcome\r\nUSed inside arg.checks() — arg.checks.common","text":"Check arguments common types outcome USed inside arg.checks()","code":""},{"path":"/reference/arg.checks.common.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check arguments that are common to all types of outcome\r\nUSed inside arg.checks() — arg.checks.common","text":"","code":"arg.checks.common(   fun,   ps.method,   minPS,   maxPS,   higher.y = NULL,   abc = NULL,   prop.cutoff = NULL,   prop.multi = NULL,   B = NULL,   Kfold = NULL,   plot.gbmperf = NULL,   tree.depth = NULL,   n.trees.boosting = NULL,   error.maxNR = NULL,   max.iterNR = NULL,   tune = NULL,   train.prop = NULL,   cv.n = NULL,   error.max = NULL,   max.iter = NULL,   n.boot = NULL,   plot.boot = NULL )"},{"path":"/reference/arg.checks.common.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check arguments that are common to all types of outcome\r\nUSed inside arg.checks() — arg.checks.common","text":"fun function argument check needed; \"pm\" pmcount(), \"cv\" cvcount(), \"drinf\" drcount.inference(). default. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. n.boot numeric value indicating number bootstrap samples used. relevant inference = TRUE. Default 500. plot.boot logic value indicating whether histograms bootstrapped log(rate ratio) produced every n.boot/10-th iteration whether final histogram outputted. Default FALSE.","code":""},{"path":"/reference/arg.checks.common.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check arguments that are common to all types of outcome\r\nUSed inside arg.checks() — arg.checks.common","text":"Nothing. stop arguments incorrect.","code":""},{"path":"/reference/arg.checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Check arguments\r\nCatered to all types of outcome\r\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","title":"Check arguments\r\nCatered to all types of outcome\r\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","text":"Check arguments Catered types outcome Apply beginning pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), drsurv.inference()","code":""},{"path":"/reference/arg.checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check arguments\r\nCatered to all types of outcome\r\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","text":"","code":"arg.checks(   fun,   response,   data,   followup.time = NULL,   tau0 = NULL,   surv.min = NULL,   ipcw.method = NULL,   ps.method,   minPS,   maxPS,   higher.y = NULL,   score.method = NULL,   abc = NULL,   prop.cutoff = NULL,   prop.multi = NULL,   train.prop = NULL,   cv.n = NULL,   error.max = NULL,   max.iter = NULL,   initial.predictor.method = NULL,   tree.depth = NULL,   n.trees.rf = NULL,   n.trees.boosting = NULL,   B = NULL,   Kfold = NULL,   plot.gbmperf = NULL,   error.maxNR = NULL,   max.iterNR = NULL,   tune = NULL,   n.boot = NULL,   plot.boot = NULL,   interactions = NULL )"},{"path":"/reference/arg.checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check arguments\r\nCatered to all types of outcome\r\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","text":"fun function argument check needed; \"catefit\" catefitcount() catefitsurv(), \"crossv\" catecvcount() catecvsurv(), \"drinf\" drcount.inference() drsurv.inference(). default. response type response. Always 'survival' function. data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). followup.time Follow-time, interpreted potential censoring time. potential censoring time known, followup.time name corresponding column data. Otherwise, set followup.time == NULL. tau0 truncation time defining restricted mean time lost. surv.min Lower truncation limit probability censored (positive close 0). ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. Default specifies 5 methods. abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'randomForest', 'boosting' 'logistic' (fastest). Default 'randomForest'. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 150. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). n.boot numeric value indicating number bootstrap samples used. relevant inference = TRUE. Default 500. plot.boot logic value indicating whether histograms bootstrapped log(rate ratio) produced every n.boot/10-th iteration whether final histogram outputted. Default FALSE. interactions logical value indicating whether outcome model assume interactions x trt. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE.","code":""},{"path":"/reference/arg.checks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check arguments\r\nCatered to all types of outcome\r\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","text":"Nothing. stop arguments incorrect.","code":""},{"path":"/reference/atefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"Doubly robust estimator average treatment effect two treatments, rate ratio count outcomes, restricted mean time lost ratio survival outcomes mean difference continuous outcome. Bootstrap used inference.","code":""},{"path":"/reference/atefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"","code":"atefit(   response,   data,   cate.model,   ps.model,   ps.method = \"glm\",   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   surv.min = 0.025,   interactions = TRUE,   n.boot = 500,   seed = NULL,   verbose = 0 )"},{"path":"/reference/atefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"response string describing type outcome data. Allowed values include \"count\" (see catecvcount()), \"survival\" (see catecvsurv()) \"continuous\" (see catecvmean()). data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). cate.model formula describing outcome model fitted. outcome must appear left-hand side. survival outcomes, Surv object must used describe outcome. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. applies survival outcomes. Default NULL, corresponds specifying IPCW covariates outcome model cate.model, plus treatment. ipcw.method character value censoring model. applies survival outcomes. Allowed values : 'breslow' (Cox regression Breslow estimator t baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. applies survival outcomes. Default NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. applies survival outcomes. Default NULL, corresponds setting truncation time maximum survival time data. surv.min Lower truncation limit probability censored. must positive value chosen close 0. applies survival outcomes. Default 0.025. interactions logical value indicating whether outcome model assume interactions x trt. Applies count outcomes. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE. n.boot numeric value indicating number bootstrap samples used. Default 500. seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating whether intermediate progress messages histograms printed. 1 indicates messages printed 0 otherwise. Default 0.","code":""},{"path":"/reference/atefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"count response, see description outputs atefitcount(). survival response, see description outputs atefitsurv().","code":""},{"path":"/reference/atefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"count response, see details atefitcount(). survival response, see details atefitsurv().","code":""},{"path":"/reference/atefit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"","code":"# Count outcome output <- atefit(response = \"count\",                  data = countExample,                  cate.model = y ~ age + female + previous_treatment +                               previous_cost + previous_number_relapses +                               offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  n.boot = 50,                  seed = 999) output plot(output)  # \\donttest{  # Survival outcome tau0 <- with(survivalExample,                  min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  output2 <- atefit(response = \"survival\",                   data = survivalExample,                   cate.model = survival::Surv(y, d) ~ age + female +                         previous_cost + previous_number_relapses,                         ps.model = trt ~ age + previous_treatment,                   tau0 = tau0,                   seed = 999) output2 plot(output2)  # }"},{"path":"/reference/atefitcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of and inference for the average treatment effect\r\nfor count data — atefitcount","title":"Doubly robust estimator of and inference for the average treatment effect\r\nfor count data — atefitcount","text":"Doubly robust estimator average treatment effect two treatments, rate ratio count outcomes. Bootstrap used inference.","code":""},{"path":"/reference/atefitcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of and inference for the average treatment effect\r\nfor count data — atefitcount","text":"","code":"atefitcount(   data,   cate.model,   ps.model,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   interactions = TRUE,   n.boot = 500,   seed = NULL,   verbose = 0 )"},{"path":"/reference/atefitcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of and inference for the average treatment effect\r\nfor count data — atefitcount","text":"data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0 1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value 0 1 estimated propensity scores truncated. Default 0.01. maxPS numerical value 0 1 estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. interactions logical value indicating whether outcome model assume treatment-covariate interaction x. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE. n.boot numeric value indicating number bootstrap samples used. Default 500. seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating whether intermediate progress messages printed. 1 indicates messages printed 0 otherwise. Default 0.","code":""},{"path":"/reference/atefitcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of and inference for the average treatment effect\r\nfor count data — atefitcount","text":"Return item class atefit following elements: log.rate.ratio:  vector numeric values estimated   ATE (expressed log rate ratio trt=1 trt=0),   bootstrap standard error, lower upper limits 95% confidence   interval, p-value. rate0:  numeric value estimated rate group   trt=0. rate1:  numeric value estimated rate group   trt=1. trt.boot:  Estimated log rate ratios bootstrap   sample. warning:  warning message produced treatment   variable coded 0 1. key map original coding   variable 0-1 coding displayed warning facilitate   interpretation remaining output.","code":""},{"path":"/reference/atefitcount.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly robust estimator of and inference for the average treatment effect\r\nfor count data — atefitcount","text":"helper function estimates average treatment effect (ATE) two treatment groups given dataset. ATE estimated doubly robust estimator accounts imbalances covariate distributions two treatment groups inverse probability treatment weighting. count outcomes, estimated ATE estimated rate ratio treatment 1 versus treatment 0.","code":""},{"path":"/reference/atefitcount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly robust estimator of and inference for the average treatment effect\r\nfor count data — atefitcount","text":"","code":"output <- atefitcount(data = countExample,                       cate.model = y ~ age + female + previous_treatment +                                    previous_cost + previous_number_relapses +                                    offset(log(years)),                       ps.model = trt ~ age + previous_treatment,                       verbose = 1, n.boot = 50, seed = 999) output plot(output)"},{"path":"/reference/atefitmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of and inference for the average treatment effect for\r\ncontinuous data — atefitmean","title":"Doubly robust estimator of and inference for the average treatment effect for\r\ncontinuous data — atefitmean","text":"Doubly robust estimator average treatment effect two treatments, rate ratio treatment 1 treatment 0 count outcomes. Bootstrap used inference.","code":""},{"path":"/reference/atefitmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of and inference for the average treatment effect for\r\ncontinuous data — atefitmean","text":"","code":"atefitmean(   data,   cate.model,   ps.model,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   interactions = TRUE,   n.boot = 500,   plot.boot = FALSE,   seed = NULL,   verbose = 0 )"},{"path":"/reference/atefitmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of and inference for the average treatment effect for\r\ncontinuous data — atefitmean","text":"data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value 0 1 estimated propensity scores truncated. Default 0.01. maxPS numerical value 0 1 estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. interactions logical value indicating whether outcome model fitted separately treatment arm variables cate.model, equivalent assuming treatment-covariate interaction variables cate.model. TRUE, outcome model fitted separately treatment arms least 10 patients received treatment option. Default TRUE. n.boot numeric value indicating number bootstrap samples used. Default 500. plot.boot logical value indicating whether histograms bootstrapped treatment effect estimates produced every n.boot/10-th iteration whether final histogram outputted. Default FALSE. seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating whether intermediate progress messages histograms printed. 1 indicates messages printed 0 otherwise. Default 0.","code":""},{"path":"/reference/atefitmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of and inference for the average treatment effect for\r\ncontinuous data — atefitmean","text":"Return list 8 elements: log.rate.ratio:  numeric value estimated log rate ratio. se.boot.log.rate.ratio:  numeric value bootstrap standard error log rate ratio. rate.ratio:  numeric value estimated rate ratio. rate.ratio0:  numeric value estimated rate group trt=0. rate.ratio1:  numeric value estimated rate group trt=1. rate.ratio.CIl:  numeric value lower limit 95% bootstrap confidence interval     estimated rate ratio. rate.ratio.CIu:  numeric value upper limit 95% bootstrap confidence interval     estimated rate ratio. pvalue:  numeric value p-value derived bootstrapped values     based Chi-squared distribution. warning:  warning message produced treatment variable coded 0/1. key   map original coding variable 0/1 key displayed warning facilitate   interpretation remaining output. plot:  plot.boot TRUE, histogram displaying distribution bootstrapped log rate ratios.   red vertical reference line histogram represents estimated log rate ratio.","code":""},{"path":"/reference/atefitmean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly robust estimator of and inference for the average treatment effect for\r\ncontinuous data — atefitmean","text":"helper function estimates average treatment effect (ATE) two  treatment groups given dataset specified y, trt, x.cate, x.ps, time. ATE  estimated doubly robust estimator accounts imbalances covariate distributions  two treatment groups inverse probability treatment weighting.  count outcomes, estimated ATE estimated  rate ratio treatment 1 versus treatment 0. original log-transformed ATEs  returned, well rate either treatment group.  inference = TRUE, variability estimated rate ratio also calculated  using bootstrap. Additional variability outputs include standard error log rate ratio,  95% confidence interval rate ratio, p-value, histogram log rate ratio.","code":""},{"path":"/reference/atefitmean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly robust estimator of and inference for the average treatment effect for\r\ncontinuous data — atefitmean","text":"","code":"# This module is not implemented yet!"},{"path":"/reference/atefitsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"Doubly robust estimator average treatment effect two treatments, restricted mean time lost ratio survival outcomes. Bootstrap used inference.","code":""},{"path":"/reference/atefitsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"","code":"atefitsurv(   data,   cate.model,   ps.model,   ps.method = \"glm\",   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   surv.min = 0.025,   n.boot = 500,   seed = NULL,   verbose = 0 )"},{"path":"/reference/atefitsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). cate.model formula describing outcome model fitted. outcome must appear left-hand side. survival outcomes, Surv object must used describe outcome. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. applies survival outcomes. Default NULL, corresponds specifying IPCW covariates outcome model cate.model, plus treatment. ipcw.method character value censoring model. applies survival outcomes. Allowed values : 'breslow' (Cox regression Breslow estimator t baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. applies survival outcomes. Default NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. applies survival outcomes. Default NULL, corresponds setting truncation time maximum survival time data. surv.min Lower truncation limit probability censored. must positive value chosen close 0. applies survival outcomes. Default 0.025. n.boot numeric value indicating number bootstrap samples used. Default 500. seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating whether intermediate progress messages printed. 1 indicates messages printed 0 otherwise. Default 0.","code":""},{"path":"/reference/atefitsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"Return object class atefit 6 elements: rmst1:  vector numeric values estimated RMST, bootstrap standard error,   lower upper limits 95% confidence interval, p-value group trt=1. rmst0:  vector numeric values estimated RMST, bootstrap standard error,   lower upper limits 95% confidence interval, p-value group trt=0. log.rmtl.ratio:  vector numeric values estimated log RMTL ratio   trt=1 trt=0, bootstrap standard error, lower upper limits 95% confidence   interval, p-value. log.hazard.ratio:  vector numeric values estimated adjusted log hazard ratio   trt=1 trt=0, bootstrap standard error, lower upper limits 95% confidence   interval, p-value. trt.boot:  Estimates rmst1, rmst0,   log.rmtl.ratio log.hazard.ratio bootstrap sample. warning:  warning message produced treatment variable coded 0/1.   key map original coding variable 0/1 key displayed warning facilitate   interpretation remaining output.","code":""},{"path":"/reference/atefitsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"helper function estimates average treatment effect (ATE) survival data two treatment groups given dataset. ATE estimated doubly robust estimator accounts imbalances covariate distributions two treatment groups inverse probability treatment censoring weighting. survival outcomes, estimated ATE estimated RMTL ratio treatment 1 versus treatment 0. log-transformed ATEs log-transformed adjusted hazard ratios returned, well estimated RMST either treatment group. variability estimated RMTL ratio calculated using bootstrap. Additional outputs include standard error log RMTL ratio, 95% confidence interval, p-value, histogram bootstrap estimates.","code":""},{"path":"/reference/atefitsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"","code":"# \\donttest{ library(survival) tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  output <- atefitsurv(data = survivalExample,                      cate.model = Surv(y, d) ~ age + female +                                   previous_cost + previous_number_relapses,                      ps.model = trt ~ age + previous_treatment,                      tau0 = tau0,                      n.boot = 50,                      seed = 999,                      verbose = 1) output plot(output) # }"},{"path":"/reference/balance.split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split the given dataset into balanced training and validation sets\r\n(within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","title":"Split the given dataset into balanced training and validation sets\r\n(within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","text":"Split given dataset balanced training validation sets (within pre-specified tolerance) Balanced means 1) ratio treated controls maintained training validation sets                2) covariate distributions balanced training validation sets","code":""},{"path":"/reference/balance.split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split the given dataset into balanced training and validation sets\r\n(within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","text":"","code":"balance.split(   y,   trt,   x.cate,   x.ps,   time,   minPS = 0.01,   maxPS = 0.99,   train.prop = 3/4,   error.max = 0.1,   max.iter = 5000 )"},{"path":"/reference/balance.split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split the given dataset into balanced training and validation sets\r\n(within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","text":"y Observed outcome; vector size n (observations) trt Treatment received; vector size n treatment coded 0/1 x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) time Log-transformed person-years follow-; vector size n minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000.","code":""},{"path":"/reference/balance.split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split the given dataset into balanced training and validation sets\r\n(within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","text":"list 10 objects, 5 training 5 validation y, trt, x.cate, x.ps, time:             y.train          - observed outcome training set; vector size m (observations training set)             trt.train        - treatment received training set; vector size m coded 0/1             x.cate.train     - baseline covariates outcome model training set; matrix dimension m p.cate x.ps.train       - baseline covariates (plus intercept) propensity score model training set; matrix dimension m p.ps + 1 time.train       - log-transformed person-years follow-training set; vector size m y.valid          - observed outcome validation set; vector size n-m trt.valid        - treatment received validation set; vector size n-m coded 0/1             x.cate.valid     - baseline covariates outcome model validation set; matrix dimension n-m p.cate x.ps.valid       - baseline covariates (plus intercept) propensity score model validation set; matrix dimension n-m p.ps + 1 time.valid       - log-transformed person-years follow-validation set; vector size n-m","code":""},{"path":"/reference/balancemean.split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","title":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","text":"Split given dataset balanced training validation sets (within pre-specified tolerance) Balanced means 1) ratio treated controls maintained training validation sets                2) covariate distributions balanced training validation sets","code":""},{"path":"/reference/balancemean.split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","text":"","code":"balancemean.split(   y,   trt,   x.cate,   x.ps,   minPS = 0.01,   maxPS = 0.99,   train.prop = 3/4,   error.max = 0.1,   max.iter = 5000 )"},{"path":"/reference/balancemean.split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","text":"y Observed outcome; vector size n (observations) trt Treatment received; vector size n treatment coded 0/1 x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000.","code":""},{"path":"/reference/balancemean.split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","text":"list 10 objects, 5 training 5 validation y, trt, x.cate, x.ps, time:             y.train          - observed outcome training set; vector size m (observations training set)             trt.train        - treatment received training set; vector size m coded 0/1             x.cate.train     - baseline covariates outcome model training set; matrix dimension m p.cate x.ps.train       - baseline covariates (plus intercept) propensity score model training set; matrix dimension m p.ps + 1 y.valid          - observed outcome validation set; vector size n-m trt.valid        - treatment received validation set; vector size n-m coded 0/1             x.cate.valid     - baseline covariates outcome model validation set; matrix dimension n-m p.cate x.ps.valid       - baseline covariates (plus intercept) propensity score model validation set; matrix dimension n-m p.ps + 1 bestid.valid     - id validation set best split; vector size n-m","code":""},{"path":"/reference/balancesurv.split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","title":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","text":"Split given time--event dataset balanced training validation sets (within pre-specified tolerance) Balanced means 1) ratio treated controls maintained training validation sets                2) covariate distributions balanced training validation sets","code":""},{"path":"/reference/balancesurv.split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","text":"","code":"balancesurv.split(   y,   d,   trt,   x.cate,   x.ps,   x.ipcw,   yf = NULL,   train.prop = 3/4,   error.max = 0.1,   max.iter = 5000 )"},{"path":"/reference/balancesurv.split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. trt Treatment received; vector size n treatment coded 0/1. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. unknown, set yf == NULL yf taken y function. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000.","code":""},{"path":"/reference/balancesurv.split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\r\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\r\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","text":"list 14 objects, 7training 7 validation y, trt, x.cate, x.ps, x.ipcw, time, yf:             y.train          - observed survival censoring time training set; vector size m (observations training set)             d.train          - event indicator training set; vector size m coded 0/1             trt.train        - treatment received training set; vector size m coded 0/1             x.cate.train     - baseline covariates outcome model training set; matrix dimension m p.cate x.ps.train       - baseline covariates (plus intercept) propensity score model training set; matrix dimension m p.ps + 1 x.ipcw.train      - baseline covariates inverse probability censoring training set; matrix dimension m p.ipw yf.train         - follow-time training set; known, vector size m; unknown, yf == NULL y.valid          - observed survival censoring time validation set; vector size n-m d.valid          - event indicator validation set; vector size n-m coded 0/1             trt.valid        - treatment received validation set; vector size n-m coded 0/1             x.cate.valid     - baseline covariates outcome model validation set; matrix dimension n-m p.cate x.ps.valid       - baseline covariates (plus intercept) propensity score model validation set; matrix dimension n-m p.ps + 1 x.ipcw.valid      - baseline covariates inverse probability censoring validation set; matrix dimension n-m p.ipw yf.valid         - follow-time training set; known, vector size n-m; unknown, yf == NULL","code":""},{"path":"/reference/boxplot.precmed.html","id":null,"dir":"Reference","previous_headings":"","what":"A set of box plots of estimated ATEs from the ","title":"A set of box plots of estimated ATEs from the ","text":"Provides box plots depict distributions estimated ATEs multi-category subgroup validation set across cross-validation iterations. subgroups mutually exclusive categorized CATE score percentiles (prop.multi specified catecv() catecvmean()). Box plots mutually exclusive subgroups constructed separately scoring method specified catecv(). run results catecv() catecvmean()) obtained.","code":""},{"path":"/reference/boxplot.precmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A set of box plots of estimated ATEs from the ","text":"","code":"# S3 method for precmed boxplot(   x,   ylab = NULL,   plot.hr = FALSE,   title = waiver(),   theme = theme_classic(),   ... )"},{"path":"/reference/boxplot.precmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A set of box plots of estimated ATEs from the ","text":"x object class \"precmed\". ylab character value y-axis label describe ATE . Default NULL, creates default y-axis label based available data. plot.hr logical value indicating whether hazard ratios plotted validation curves (TRUE). Otherwise, restricted mean time lost plotted (FALSE). argument applicable survival outcomes. Default FALSE. title text title theme Defaults theme_classic(). options include theme_grey(), theme_bw(), theme_light(), theme_dark(), theme_void() ... parameters","code":""},{"path":"/reference/boxplot.precmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A set of box plots of estimated ATEs from the ","text":"Returns sets box plots, one set scoring method, multi-category subgroups. gray horizontal dashed line overall ATE included reference.","code":""},{"path":"/reference/boxplot.precmed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A set of box plots of estimated ATEs from the ","text":"boxplot() takes outputs catecv() generates box plots estimated ATEs multi-category subgroups validation set. box plots together overall ATE reference line can help compare scoring methods' ability distinguish subgroups patients different treatment effects. given scoring method, box plots showing increasing decreasing trends across multi-category subgroups indicate presence treatment effect heterogeneity (ability scoring method capture ). contrary, box plots relatively aligned across multi-category subgroups indicate absence treatment effect heterogeneity (inability scoring method capture ).","code":""},{"path":"/reference/boxplot.precmed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A set of box plots of estimated ATEs from the ","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/boxplot.precmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A set of box plots of estimated ATEs from the ","text":"","code":"# \\donttest{ # Count outcome eval_1 <- catecv(response = \"count\",                  data = countExample,                  score.method = \"poisson\",                  cate.model = y ~ age + female + previous_treatment +                                   previous_cost + previous_number_relapses +                                   offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  higher.y = FALSE,                  cv.n = 5)  boxplot(eval_1, ylab = \"Rate ratio of drug1 vs drug0 in each subgroup\")  # Survival outcome library(survival) tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95))) eval_2 <- catecv(response = \"survival\",                  data = survivalExample,                  score.method = c(\"poisson\", \"randomForest\"),                  cate.model = Surv(y, d) ~ age + female + previous_cost +                                            previous_number_relapses,                  ps.model = trt ~ age + previous_treatment,                  initial.predictor.method = \"randomForest\",                  ipcw.model = ~ age + previous_cost + previous_treatment,                  tau0 = tau0,                  higher.y = TRUE,                  cv.n = 5,                  seed = 999)  boxplot(eval_2, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") # }"},{"path":"/reference/catecv.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"Provides (doubly robust) estimation average treatment effect (ATE) count, survival continuous outcomes nested mutually exclusive subgroups patients defined estimated conditional average treatment effect (CATE) score via cross-validation (CV).","code":""},{"path":"/reference/catecv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"","code":"catecv(   response,   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   init.model = NULL,   initial.predictor.method = NULL,   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   prop.multi = c(0, 1/3, 2/3, 1),   abc = TRUE,   train.prop = 3/4,   cv.n = 10,   error.max = 0.1,   max.iter = 5000,   surv.min = 0.025,   xvar.smooth.score = NULL,   xvar.smooth.init = NULL,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = TRUE,   verbose = 0 )"},{"path":"/reference/catecv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"response string describing type outcome data. Allowed values include \"count\" (see catecvcount()), \"survival\" (see catecvsurv()) \"continuous\" (see catecvmean()) . data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'twoReg', 'contrastReg', 'poisson' (count survival outcomes ), 'randomForest' (survival, continuous outcomes ), negBin (count outcomes ), 'gam' (continuous outcomes ), 'gaussian' (continuous outcomes ). cate.model formula describing outcome model fitted. outcome must appear left-hand side. survival outcomes, Surv object must used describe outcome. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. initial.predictor.method character vector method used get initial outcome predictions conditional covariates specified cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'randomForest' (survival outcomes ), 'boosting', 'logistic' (survival outcomes , fast), 'poisson' (count outcomes , fast), 'gaussian' (continuous outcomes ) 'gam' (count continuous outcomes ). Default NULL, assigns 'boosting' count outcomes 'randomForest' survival outcomes. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. applies survival outcomes. Default NULL, corresponds specifying IPCW covariates outcome model cate.model, plus treatment. ipcw.method character value censoring model. applies survival outcomes. Allowed values : 'breslow' (Cox regression Breslow estimator t baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. applies survival outcomes. Default NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. applies survival outcomes. Default NULL, corresponds setting truncation time maximum survival time data. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. surv.min Lower truncation limit probability censored. must positive value chosen close 0. applies survival outcomes. Default 0.025. xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress bar run time. 2 means progress bar, run time, errors warnings. Default 0.","code":""},{"path":"/reference/catecv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"count response, see description outputs catecvcount(). survival response, see description outputs catecvsurv(). continuous response, see description outputs catecvmean().","code":""},{"path":"/reference/catecv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"count response, see details catecvcount(). survival response, see details catecvsurv(). continuous response, see details catecvmean().","code":""},{"path":"/reference/catecv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/catecv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"","code":"# \\donttest{ cate_1 <- catecv(response = \"count\",                  data = countExample,                  score.method = \"poisson\",                  cate.model = y ~ age + female + previous_treatment +                               previous_cost + previous_number_relapses +                               offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  higher.y = FALSE, cv.n = 5, seed = 999, verbose = 1)  plot(cate_1, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") boxplot(cate_1, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") abc(cate_1)  # Survival outcome library(survival) tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  cate_2 <- catecv(response = \"survival\",                  data = survivalExample,                  score.method = c(\"poisson\", \"randomForest\"),                  cate.model = Surv(y, d) ~ age + female + previous_cost +                               previous_number_relapses,                  ps.model = trt ~ age + previous_treatment,                  initial.predictor.method = \"randomForest\",                  ipcw.model = ~ age + previous_cost + previous_treatment,                  tau0 = tau0,                  higher.y = TRUE,                  surv.min = 0.025,                  cv.n = 5,                  seed = 999)  plot(cate_2, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") boxplot(cate_2, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") abc(cate_2)   # }"},{"path":"/reference/catecvcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of the conditional average treatment effect (CATE) score\r\nfor count outcomes — catecvcount","title":"Cross-validation of the conditional average treatment effect (CATE) score\r\nfor count outcomes — catecvcount","text":"Provides doubly robust estimation average treatment effect (ATE) nested mutually exclusive subgroups patients defined estimated conditional average treatment effect (CATE) score via cross-validation (CV). CATE score can estimated 5 methods among following: Poisson regression, boosting, two regressions, contrast regression, negative binomial (see score.method).","code":""},{"path":"/reference/catecvcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of the conditional average treatment effect (CATE) score\r\nfor count outcomes — catecvcount","text":"","code":"catecvcount(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   initial.predictor.method = \"boosting\",   minPS = 0.01,   maxPS = 0.99,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   prop.multi = c(0, 1/3, 2/3, 1),   abc = TRUE,   train.prop = 3/4,   cv.n = 10,   error.max = 0.1,   max.iter = 5000,   xvar.smooth = NULL,   tree.depth = 2,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = TRUE,   verbose = 0,   ... )"},{"path":"/reference/catecvcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of the conditional average treatment effect (CATE) score\r\nfor count outcomes — catecvcount","text":"data data frame containing variables outcome propensity score model; data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0 1. data randomized trial, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'poisson' (fastest), 'boosting' 'gam'. Default 'boosting'. minPS numerical value 0 1 estimated propensity scores truncated. Default 0.01. maxPS numerical value 0 1 estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values 0 1 specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values 0 1 specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. train.prop numerical value 0 1 indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. xvar.smooth vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress bar run time. 2 means progress bar, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"/reference/catecvcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of the conditional average treatment effect (CATE) score\r\nfor count outcomes — catecvcount","text":"Returns list containing following components saved \"precmed\" object: ate.poisson: list results output score.method includes  'poisson': ate.est.train.high.cv: matrix numerical values     length(prop.cutoff) rows cv.n columns.     ith row/jth column cell contains estimated ATE nested subgroup high responders     defined CATE score (higher.y = TRUE) (higher.y = FALSE)     prop.cutoff[]x100% percentile estimated CATE score training set jth     cross-validation iteration. ate.est.train.low.cv: matrix numerical values     length(prop.cutoff) - 1 rows cv.n columns.     ith row/jth column cell contains estimated ATE nested subgroup low responders     defined CATE score (higher.y = TRUE) (higher.y = FALSE)     prop.cutoff[]x100% percentile estimated CATE score training set jth     cross-validation iteration. ate.est.valid.high.cv: ate.est.train.high.cv,     validation set. ate.est.valid.low.cv: ate.est.train.low.cv,     validation set. ate.est.train.group.cv: matrix numerical values     length(prop.multi) - 1 rows cv.n columns.     jth column contains estimated ATE length(prop.multi) - 1     mutually exclusive subgroups defined prop.multi training set jth     cross-validation iteration. ate.est.valid.group.cv: ate.est.train.group.cv,     validation set. abc.valid: vector numerical values length cv.n.     ith element returns ABC validation curve ith cross-validation     iteration. returned abc = TRUE. ate.boosting: list results similar ate.poisson output  score.method includes 'boosting'. ate.twoReg: list results similar ate.poisson output  score.method includes 'twoReg'. ate.contrastReg: list results similar ate.poisson output  score.method includes 'contrastReg'.  method additional element list results: converge.contrastReg.cv: vector logical value length cv.n.     ith element indicates whether algorithm converged ith cross-validation     iteration. ate.negBin: list results similar ate.poisson output  score.method includes 'negBin'. props: list 3 elements: prop.onlyhigh: original argument prop.cutoff,     reformatted necessary. prop.bi: original argument prop.cutoff,     similar prop.onlyhigh reformatted exclude 1. prop.multi: original argument prop.multi,     reformatted necessary include 0 1. overall.ate.valid: vector numerical values length cv.n.  ith element contains ATE validation set ith cross-validation  iteration, estimated doubly robust estimator. overall.ate.train: vector numerical values length cv.n.  ith element contains ATE training set ith cross-validation  iteration, estimated doubly robust estimator. fgam: formula used GAM initial.predictor.method = 'gam'. higher.y: original higher.y argument. abc: original abc argument. cv.n: original cv.n argument. response: type response. Always 'count' function. formulas:list 3 elements: (1) cate.model argument,  (2) ps.model argument (3) original labels left-hand side variable  ps.model (treatment) 0/1.","code":""},{"path":"/reference/catecvcount.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of the conditional average treatment effect (CATE) score\r\nfor count outcomes — catecvcount","text":"CATE score represents individual-level treatment effect expressed rate ratio count outcomes. can estimated boosting, Poisson regression, negative binomial regression, doubly robust estimator two regressions (Yadlowsky, 2020) applied separately treatment group doubly robust estimator contrast regression (Yadlowsky, 2020) applied entire data set. Internal CV applied reduce optimism choosing CATE estimation method captures treatment effect heterogeneity. CV applied repeating following steps cv.n times: Split data training validation set according train.prop.  training validation sets must balanced respect covariate distributions  doubly robust rate ratio estimates (see error.max). Estimate CATE score training set specified scoring method. Predict CATE score validation set using scoring model fitted  training set. Build nested subgroups treatment responders training validation sets,  separately, estimate ATE within nested subgroup. element  prop.cutoff (e.g., prop.cutoff[] = 0.6), take following steps: Identify high responders observations 60%    (.e., prop.cutoff[]x100%) highest (higher.y = TRUE)    lowest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup high responders using doubly robust estimator. Conversely, identify low responders observations 40%    (.e., 1 - prop.cutoff[]x100%) lowest (higher.y = TRUE)    highest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup low responders using doubly robust estimator. abc = TRUE, calculate area ATE series ATEs  nested subgroups high responders validation set. Build mutually exclusive subgroups treatment responders training  validation sets, separately, estimate ATE within subgroup. Mutually exclusive  subgroups built splitting estimated CATE scores according prop.multi.","code":""},{"path":"/reference/catecvcount.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of the conditional average treatment effect (CATE) score\r\nfor count outcomes — catecvcount","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/catecvcount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of the conditional average treatment effect (CATE) score\r\nfor count outcomes — catecvcount","text":"","code":"# \\donttest{ catecv <- catecvcount(data = countExample,                       score.method = \"poisson\",                       cate.model = y ~ age + female + previous_treatment +                                    previous_cost + previous_number_relapses +                                    offset(log(years)),                       ps.model = trt ~ age + previous_treatment,                       higher.y = FALSE,                       cv.n = 5,                       seed = 999,                       plot.gbmperf = FALSE,                       verbose = 1)  plot(catecv, ylab = \"Rate ratio of drug1 vs drug0 in each subgroup\") boxplot(catecv, ylab = \"Rate ratio of drug1 vs drug0 in each subgroup\") abc(catecv) # }"},{"path":"/reference/catecvmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"Provides doubly robust estimation average treatment effect (ATE) nested mutually exclusive subgroups patients defined estimated conditional average treatment effect (CATE) score via cross-validation (CV). CATE score can estimated 6 methods among following: Linear regression, boosting, two regressions, contrast regression, random forest generalized additive model (see score.method).","code":""},{"path":"/reference/catecvmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"","code":"catecvmean(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   init.model = NULL,   initial.predictor.method = \"boosting\",   minPS = 0.01,   maxPS = 0.99,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   prop.multi = c(0, 1/3, 2/3, 1),   abc = TRUE,   train.prop = 3/4,   cv.n = 10,   error.max = 0.1,   max.iter = 5000,   xvar.smooth.score = NULL,   xvar.smooth.init = NULL,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 6,   plot.gbmperf = TRUE,   error.maxNR = 0.001,   tune = c(0.5, 2),   seed = NULL,   verbose = 0,   ... )"},{"path":"/reference/catecvmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'poisson' (fastest), 'boosting' 'gam'. Default 'boosting'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress bar run time. 2 means progress bar, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"/reference/catecvmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"Returns list containing following components saved \"precmed\" object: ate.gaussian: list results output score.method includes  'gaussian': ate.est.train.high.cv: matrix numerical values     length(prop.cutoff) rows cv.n columns.     ith column/jth row cell contains estimated ATE nested subgroup high responders     defined CATE score (higher.y = TRUE) (higher.y = FALSE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. ate.est.train.low.cv: matrix numerical values     length(prop.cutoff) - 1 rows cv.n columns.     ith column/jth row cell contains estimated ATE nested subgroup low responders     defined CATE score (higher.y = TRUE) (higher.y = FALSE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. ate.est.valid.high.cv: ate.est.train.high.cv,     validation set. ate.est.valid.low.cv: ate.est.train.low.cv,     validation set. ate.est.train.group.cv: matrix numerical values     length(prop.multi) - 1 rows cv.n columns.     ith column contains estimated ATE length(prop.multi) - 1     mutually exclusive subgroups defined prop.multi training set ith     cross-validation iteration. ate.est.valid.group.cv: ate.est.train.group.cv,     validation set. abc.valid: vector numerical values length cv.n,     ith element returns ABC validation curve ith cross-validation     iteration. returned abc = TRUE. ate.boosting: list results similar ate.gaussian output  score.method includes 'boosting'. ate.twoReg: list results similar ate.gaussian output  score.method includes 'twoReg'. ate.contrastReg: list results similar ate.gaussian output  score.method includes 'contrastReg'. ate.randomForest: list results similar ate.gaussian output  score.method includes 'randomForest'. ate.gam: list results similar ate.gaussian output  score.method includes 'gam'. props: list 3 elements: prop.onlyhigh: original argument prop.cutoff,     reformatted necessary. prop.bi: original argument prop.cutoff,     similar prop.onlyhigh reformatted exclude 1. prop.multi: original argument prop.multi,     reformatted necessary. overall.ate.train: vector numerical values length cv.n.  ith element contains ATE training set ith cross-validation  iteration, estimated doubly robust estimator. overall.ate.valid: vector numerical values length cv.n.  ith element contains ATE validation set ith cross-validation  iteration, estimated doubly robust estimator. higher.y: original higher.y argument. abc: original abc argument. cv.n: original cv.n argument. response: type response. Always 'continuous' function. formulas:list 3 elements: (1) cate.model argument,  (2) ps.model argument (3) original labels left-hand side variable  ps.model (treatment) 0/1.","code":""},{"path":"/reference/catecvmean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"CATE score represents individual-level treatment effect continuous data, estimated boosting, linear regression, random forest, generalized additive model doubly robust estimator (two regressions, Yadlowsky, 2020) applied separately treatment group doubly robust estimators (contrast regression, Yadlowsky, 2020) applied entire data set. Internal CV applied reduce optimism choosing CATE estimation method captures treatment effect heterogeneity. CV applied repeating following steps cv.n times: Split data training validation set according train.prop.  training validation sets must balanced respect covariate distributions  doubly robust rate ratio estimates (see error.max). Estimate CATE score training set specified scoring method. Predict CATE score validation set using scoring model fitted  training set. Build nested subgroups treatment responders training validation sets,  separately, estimate ATE within nested subgroup. element  prop.cutoff (e.g., prop.cutoff[] = 0.6), take following steps: Identify high responders observations 60%    (.e., prop.cutoff[]x100%) highest (higher.y = TRUE)    lowest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup high responders using doubly robust estimator. Conversely, identify low responders observations 40%    (.e., 1 - prop.cutoff[]x100%) lowest (higher.y = TRUE)    highest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup low responders using doubly robust estimator. Build mutually exclusive subgroups treatment responders training  validation sets, separately, estimate ATE within subgroup. Mutually exclusive  subgroups built splitting estimated CATE scores according prop.multi. abc = TRUE, calculate area ATE series ATEs  nested subgroups high responders validation set.","code":""},{"path":"/reference/catecvmean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/catecvmean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"","code":"# Not implemented yet!"},{"path":"/reference/catecvsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"Provides doubly robust estimation average treatment effect (ATE) RMTL (restricted mean time lost) ratio nested mutually exclusive subgroups patients defined estimated conditional average treatment effect (CATE) score via cross-validation (CV). CATE score can estimated 5 methods among following: Random forest, boosting, poisson regression, two regressions, contrast regression (see score.method).","code":""},{"path":"/reference/catecvsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"","code":"catecvsurv(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   initial.predictor.method = \"randomForest\",   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   prop.multi = c(0, 1/3, 2/3, 1),   abc = TRUE,   train.prop = 3/4,   cv.n = 10,   error.max = 0.1,   max.iter = 5000,   surv.min = 0.025,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = TRUE,   verbose = 0 )"},{"path":"/reference/catecvsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'randomForest', 'boosting', 'poisson', 'twoReg', 'contrastReg'. cate.model standard Surv formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates specified cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'randomForest', 'boosting' 'logistic' (fastest). Default 'randomForest'. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. Default ipcw.model = NULL, corresponds specifying IPCW model covariates outcome model cate.model plus treatment. ipcw.method character value censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. Default followup.time = NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. Default NULL, corresponds setting truncation time maximum survival time data. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. surv.min Lower truncation limit probability censored. must positive value chosen close 0. Default 0.025. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress bar run time. 2 means progress bar, run time, errors warnings. Default 0.","code":""},{"path":"/reference/catecvsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"Returns list containing following components saved \"precmed\" object: ate.randomForest: list ATE output measured RMTL ratio  score.method includes 'randomForest': ate.est.train.high.cv: matrix numerical values     length(prop.cutoff) rows cv.n columns.     ith column/jth row cell contains estimated ATE nested subgroup high responders     defined CATE score (higher.y = FALSE) (higher.y = TRUE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. ate.est.train.low.cv: matrix numerical values     length(prop.cutoff) - 1 rows cv.n columns.     TThe ith column/jth row cell contains estimated ATE nested subgroup low responders     defined CATE score (higher.y = FALSE) (higher.y = TRUE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. ate.est.valid.high.cv: ate.est.train.high.cv,     validation set. ate.est.valid.low.cv: ate.est.train.low.cv,     validation set. ate.est.train.group.cv: matrix numerical values     length(prop.multi) - 1 rows cv.n columns.     ith column contains estimated ATE length(prop.multi) - 1     mutually exclusive subgroups defined prop.multi training set ith     cross-validation iteration. ate.est.valid.group.cv: ate.est.train.group.cv,     validation set. abc.valid: vector numerical values length cv.n,     ith element returns ABC validation curve ith cross-validation     iteration. returned abc = TRUE. ate.boosting: list results similar ate.randomForest output  score.method includes 'boosting'. ate.poisson: list results similar ate.randomForest output  score.method includes 'poisson'. ate.twoReg: list results similar ate.randomForest output  score.method includes 'twoReg'. ate.contrastReg: list results similar ate.randomForest output  score.method includes 'contrastReg'.  method additional element list results: converge.contrastReg.cv: vector logical value length cv.n.     ith element indicates whether algorithm converged ith cross-validation     iteration. hr.randomForest: list adjusted hazard ratio score.method includes  'randomForest': hr.est.train.high.cv: matrix numerical values     length(prop.cutoff) rows cv.n columns.     ith column/jth row cell contains estimated HR nested subgroup high responders     defined CATE score (higher.y = FALSE) (higher.y = TRUE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. hr.est.train.low.cv: matrix numerical values     length(prop.cutoff) - 1 rows cv.n columns.     TThe ith column/jth row cell contains estimated HR nested subgroup low responders     defined CATE score (higher.y = FALSE) (higher.y = TRUE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. hr.est.valid.high.cv: hr.est.train.high.cv,     validation set. hr.est.valid.low.cv: hr.est.train.low.cv,     validation set. hr.est.train.group.cv: matrix numerical values     length(prop.multi) - 1 rows cv.n columns.     ith column contains estimated HR length(prop.multi) - 1     mutually exclusive subgroups defined prop.multi training set ith     cross-validation iteration. hr.est.valid.group.cv: hr.est.train.group.cv,     validation set. hr.boosting: list results similar hr.randomForest output  score.method includes 'boosting'. hr.poisson: list results similar hr.randomForest output  score.method includes 'poisson'. hr.twoReg: list results similar hr.randomForest output  score.method includes 'twoReg'. hr.contrastReg: list results similar hr.randomForest output  score.method includes 'contrastReg'.  props: list 3 elements: prop.onlyhigh: original argument prop.cutoff,     reformatted necessary. prop.bi: original argument prop.cutoff,     similar prop.onlyhigh reformatted exclude 1. prop.multi: original argument prop.multi,     reformatted necessary include 0 1.","code":""},{"path":"/reference/catecvsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"CATE score represents individual-level treatment effect expressed restricted mean survival time (RMTL) ratio) survival outcomes. can estimated boosting, Poisson regression, random forest, doubly robust estimator two regressions (Yadlowsky, 2020) applied separately treatment group doubly robust estimator contrast regression (Yadlowsky, 2020) applied entire data set. Internal CV applied reduce optimism choosing CATE estimation method captures treatment effect heterogeneity. CV applied repeating following steps cv.n times: Split data training validation set according train.prop.  training validation sets must balanced respect covariate distributions  doubly robust RMTL ratio estimates (see error.max). Estimate CATE score training set specified scoring method. Predict CATE score validation set using scoring model fitted  training set. Build nested subgroups treatment responders training validation sets,  separately, estimate ATE within nested subgroup. element  prop.cutoff (e.g., prop.cutoff[] = 0.6), take following steps: Identify high responders observations 60%    (.e., prop.cutoff[]x100%) highest (higher.y = FALSE)    lowest (higher.y = TRUE) estimated CATE scores. Estimate ATE subgroup high responders using doubly robust estimator. Conversely, identify low responders observations 40%    (.e., 1 - prop.cutoff[]x100%) lowest (higher.y = FALSE)    highest (higher.y = TRUE) estimated CATE scores. Estimate ATE subgroup low responders using doubly robust estimator. abc = TRUE, calculate area ATE series ATEs  nested subgroups high responders validation set. Build mutually exclusive subgroups treatment responders training  validation sets, separately, estimate ATE within subgroup. Mutually exclusive  subgroups built splitting estimated CATE scores according prop.multi.","code":""},{"path":"/reference/catecvsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/catecvsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"","code":"# \\donttest{ library(survival)  tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  catecv <- catecvsurv(data = survivalExample,                      score.method = \"poisson\",                      cate.model = Surv(y, d) ~ age + female + previous_cost +                                                previous_number_relapses,                      ps.model = trt ~ age + previous_treatment,                      initial.predictor.method = \"logistic\",                      ipcw.model = ~ age + previous_cost + previous_treatment,                      tau0 = tau0,                      higher.y = TRUE,                      cv.n = 5, seed = 999, verbose = 1)  # Try: plot(catecv, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") boxplot(catecv, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") abc(catecv) # }"},{"path":"/reference/catefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"Provides singly robust doubly robust estimation CATE score count, survival continuous data following scoring methods among following: Random forest (survival, continuous ), boosting, poisson regression (count, survival ), two regressions, contrast regression, negative binomial regression (count ), linear regression (continuous ), generalized additive model (continuous ).","code":""},{"path":"/reference/catefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"","code":"catefit(   response,   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   init.model = NULL,   initial.predictor.method = NULL,   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   surv.min = 0.025,   xvar.smooth.score = NULL,   xvar.smooth.init = NULL,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = TRUE,   verbose = 0,   ... )"},{"path":"/reference/catefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"response string describing type outcome data. Allowed values include \"count\" (see catecvcount()), \"survival\" (see catecvsurv()) \"continuous\" (see catecvmean()). data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'twoReg', 'contrastReg', 'poisson' (count survival outcomes ), 'randomForest' (survival, continuous outcomes ), negBin (count outcomes ), 'gam' (continuous outcomes ), 'gaussian' (continuous outcomes ). cate.model formula describing outcome model fitted. outcome must appear left-hand side. survival outcomes, Surv object must used describe outcome. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. initial.predictor.method character vector method used get initial outcome predictions conditional covariates specified cate.model. applies score.method includes 'twoReg' 'contrastReg'.Allowed values include one 'randomForest' (survival outcomes ), 'boosting', 'logistic' (survival outcomes , fast), 'poisson' (count outcomes , fast), 'gaussian' (continuous outcomes ) 'gam' (count continuous outcomes ). Default NULL, assigns 'boosting' count outcomes 'randomForest' survival outcomes. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. applies survival outcomes. Default NULL, corresponds specifying IPCW covariates outcome model cate.model, plus treatment. ipcw.method character value censoring model. applies survival outcomes. Allowed values : 'breslow' (Cox regression Breslow estimator t baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. applies survival outcomes. Default NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. applies survival outcomes. Default NULL, corresponds setting truncation time maximum survival time data. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). surv.min Lower truncation limit probability censored. must positive value chosen close 0. applies survival outcomes. Default 0.025. xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating whether intermediate progress messages histograms printed. 1 indicates messages printed 0 otherwise. Default 0. ... Additional arguments gbm()","code":""},{"path":"/reference/catefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"count response, see description outputs catefitcount(). survival response, see description outputs catefitsurv().","code":""},{"path":"/reference/catefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"count response, see details catefitcount(). survival response, see details catefitsurv().","code":""},{"path":"/reference/catefit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/catefit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"","code":"# Count outcome fit_1 <- catefit(response = \"count\",                  data = countExample,                  score.method = \"poisson\",                  cate.model = y ~ age + female + previous_treatment +                                   previous_cost + previous_number_relapses +                                   offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  higher.y = TRUE,                  seed = 999)  coef(fit_1)  # \\donttest{ # Survival outcome library(survival) tau0 <- with(survivalExample,                  min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  fit_2 <- catefit(response = \"survival\",                  data = survivalExample,                  score.method = c(\"poisson\", \"boosting\", \"randomForest\"),                  cate.model = Surv(y, d) ~ age + female + previous_cost +                                            previous_number_relapses,                  ps.model = trt ~ age + previous_treatment,                  initial.predictor.method = \"logistic\",                  ipcw.model = ~ age + previous_cost + previous_treatment,                  tau0 = tau0, higher.y = TRUE, seed = 999, n.cores = 1)  coef(fit_2)  # }"},{"path":"/reference/catefitcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"Provides singly robust doubly robust estimation CATE score 5 scoring methods among following: Poisson regression, boosting, two regressions, contrast regression, negative binomial.","code":""},{"path":"/reference/catefitcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"","code":"catefitcount(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   initial.predictor.method = \"boosting\",   minPS = 0.01,   maxPS = 0.99,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   xvar.smooth = NULL,   tree.depth = 2,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = FALSE,   verbose = 0,   ... )"},{"path":"/reference/catefitcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"data data frame containing variables outcome propensity score model; data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized trial, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'poisson' (fastest), 'boosting' 'gam'. Default 'boosting'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). xvar.smooth vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress run time. 2 means progress, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"/reference/catefitcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"Returns list containing following components: ate.poisson: vector numerical values length prop.cutoff  containing estimated ATE nested subgroups (defined prop.cutoff)  constructed based estimated CATE scores poisson regression.  provided score.method includes 'poisson'. ate.boosting: ate.poisson, nested subgroups based  estimated CATE scores boosting. provided score.method  includes 'boosting'. ate.twoReg: ate.poisson, nested subgroups based  estimated CATE scores two regressions.  provided score.method includes 'twoReg'. ate.contrastReg: ate.poisson, nested subgroups based  estimated CATE scores contrast regression.  provided score.method includes 'contrastReg'. ate.negBin: ate.poisson, nested subgroups based  estimated CATE scores negative binomial regression.  provided score.method includes 'negBin'. score.poisson: vector numerical values length n  (number observations data) containing estimated log-CATE scores  according Poisson regression. provided score.method  includes 'poisson'. score.boosting: score.poisson, estimated log-CATE score  according boosting. provided score.method includes  'boosting'. score.twoReg: score.poisson, estimated log-CATE score  according two regressions. provided score.method includes  'twoReg'. score.contrastReg: score.poisson, estimated log-CATE score  according contrast regression. provided score.method includes  'contrastReg'. score.negBin: score.poisson, estimated log-CATE score  according negative binomial regression. provided score.method  includes 'negBin'. fit: Additional details model fitting score.method  includes 'boosting' 'contrastReg': result.boosting: Details boosting model fitted observations    treatment = 0 ($fit0.boosting) observations treatment = 1 ($fit1.boosting).    provided score.method includes 'boosting'. result.contrastReg$sigma.contrastReg: Variance-covariance matrix    estimated log-CATE coefficients contrast regression.    provided score.method includes 'contrastReg'. coefficients: data frame coefficients estimated log-CATE  score score.method. data frame number rows equal number  covariates cate.model number columns equal length(score.method).  score.method includes 'contrastReg', data frame additional  column containing standard errors coefficients estimated contrast regression.  'boosting' coefficient results tree-based methods typically  express log-CATE linear combination coefficients covariates.","code":""},{"path":"/reference/catefitcount.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"CATE score represents individual-level treatment effect, estimated either Poisson regression, boosting negative binomial regression applied separately treatment group two doubly robust estimators, two regressions contrast regression (Yadlowsky, 2020) applied entire dataset. catefitcount() provides coefficients CATE score scoring method requested score.method. Currently, contrast regression method allows inference CATE coefficients providing standard errors coefficients. coefficients can used learn effect size variable predict CATE score new observation. catefitcount() also provides predicted CATE score observation data set, scoring method. predictions allow ranking observations potentially high responders treatment potentially low standard responders. estimated ATE among nested subgroups high responders also provided scoring method. Note ATEs catefitcount() derived based CATE score estimated using data sample. Therefore, overfitting may issue. catecvcount() suitable inspect estimated ATEs across scoring methods implements internal cross validation reduce optimism.","code":""},{"path":"/reference/catefitcount.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/catefitcount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"","code":"fit <- catefitcount(data = countExample,                     score.method = \"poisson\",                     cate.model = y ~ age + female + previous_treatment +                                  previous_cost + previous_number_relapses +                                  offset(log(years)),                     ps.model = trt ~ age + previous_treatment,                     higher.y = FALSE,                     seed = 999, verbose = 1)"},{"path":"/reference/catefitmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"Provides singly robust doubly robust estimation CATE score 6 scoring methods among following: Linear regression, boosting, two regressions, contrast regression, random forest generalized additive model.","code":""},{"path":"/reference/catefitmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"","code":"catefitmean(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   init.model = NULL,   initial.predictor.method = \"boosting\",   minPS = 0.01,   maxPS = 0.99,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   xvar.smooth.score = NULL,   xvar.smooth.init = NULL,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 6,   plot.gbmperf = FALSE,   error.maxNR = 0.001,   tune = c(0.5, 2),   seed = NULL,   verbose = 0,   ... )"},{"path":"/reference/catefitmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model specified ps.model). init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. initial.predictor.method character vector method used get initial outcome predictions conditional covariates init.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'gaussian' (fastest), 'boosting' 'gam'. Default 'boosting'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.rf positive integer specifying number trees. Used score.method = 'randomForest'. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress run time. 2 means progress, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"/reference/catefitmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"Returns list containing following components: ate.gaussian: vector numerical values length prop.cutoff  containing estimated ATE nested subgroups (defined prop.cutoff)  constructed based estimated CATE scores Poisson regression.  provided score.method includes 'gaussian'. ate.boosting: ate.gaussian, nested subgroups based  estimated CATE scores boosting. provided score.method  includes 'boosting'. ate.twoReg: ate.gaussian, nested subgroups based  estimated CATE scores two regressions.  provided score.method includes 'twoReg'. ate.contrastReg: ate.gaussian, nested subgroups based  estimated CATE scores contrast regression.  provided score.method includes 'contrastReg'. ate.randomForest: ate.gaussian, nested subgroups based  estimated CATE scores random forest.  provided score.method includes 'gam'. ate.gam: ate.gaussian, nested subgroups based  estimated CATE scores generalized additive model.  provided score.method includes 'gam'. score.gaussian: vector numerical values length n  (number observations data) containing estimated CATE scores  according linear regression. provided score.method  includes 'gaussian'. score.boosting: score.gaussian, estimated CATE score  according boosting. provided score.method includes  'boosting'. score.twoReg: score.gaussian, estimated CATE score  according two regressions. provided score.method includes  'twoReg'. score.contrastReg: score.gaussian, estimated CATE score  according contrast regression. provided score.method includes  'contrastReg'. score.randomForest: score.gaussian, estimated CATE score  according random forest. provided score.method  includes 'randomForest'. score.gam: score.gaussian, estimated CATE score  according generalized additive model. provided score.method  includes 'gam'. fit: Additional details model fitting score.method  includes 'boosting' 'contrastReg': result.boosting: Details boosting model fitted observations    treatment = 0 ($fit0.boosting) observations treatment = 1 ($fit1.boosting).    provided score.method includes 'boosting'. result.randomForest: Details boosting model fitted observations    treatment = 0 ($fit0.randomForest) observations treatment = 1 ($fit1.randomForest).    provided score.method includes 'randomForest'. result.gam: Details boosting model fitted observations    treatment = 0 ($fit0.gam) observations treatment = 1 ($fit1.gam).    provided score.method includes 'gam'. result.contrastReg$sigma.contrastReg: Variance-covariance matrix    estimated CATE coefficients contrast regression.    provided score.method includes 'contrastReg'. coefficients: data frame coefficients estimated CATE  score score.method. data frame number rows equal number  covariates cate.model number columns equal length(score.method).  score.method includes 'contrastReg', data frame additional  column containing standard errors coefficients estimated contrast regression.  'boosting', 'randomForest', 'gam' coefficient results methods  express CATE linear combination coefficients covariates.","code":""},{"path":"/reference/catefitmean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"CATE score represents individual-level treatment effect, estimated either linear regression, boosting, random forest generalized additive model applied separately treatment group two doubly robust estimators, two regressions contrast regression (Yadlowsky, 2020) applied entire dataset. catefitmean() provides coefficients CATE score scoring method requested score.method. Currently, contrast regression method allows inference CATE coefficients providing standard errors coefficients. coefficients can used learn effect size variable predict CATE score new observation. catefitmean() also provides predicted CATE score observation data set, scoring method. predictions allow ranking observations potentially high responders treatment potentially low standard responders. estimated ATE among nested subgroups high responders also provided scoring method. Note ATEs catefitmean() derived based CATE score estimated using data sample. Therefore, overfitting may issue. catefitmean() suitable inspect estimated ATEs across scoring methods implements internal cross validation reduce optimism.","code":""},{"path":"/reference/catefitmean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/catefitsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"Provides singly robust doubly robust estimation CATE score survival data 5 scoring methods among following: Random forest, boosting, poisson regression, two regressions, contrast regression.","code":""},{"path":"/reference/catefitsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"","code":"catefitsurv(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   initial.predictor.method = \"randomForest\",   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   surv.min = 0.025,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   plot.gbmperf = TRUE,   error.maxNR = 0.001,   max.iterNR = 100,   tune = c(0.5, 2),   seed = NULL,   verbose = 0,   ... )"},{"path":"/reference/catefitsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'randomForest', 'boosting', 'poisson', 'twoReg', 'contrastReg'. cate.model standard Surv formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates specified cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'randomForest', 'boosting' 'logistic' (fastest). Default 'randomForest'. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. Default ipcw.model = NULL, corresponds specifying IPCW model covariates outcome model cate.model plus treatment. ipcw.method character value censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. Default followup.time = NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. Default NULL, corresponds setting truncation time maximum survival time data. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). surv.min Lower truncation limit probability censored. must positive value chosen close 0. Default 0.025. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress run time. 2 means progress, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"/reference/catefitsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"Returns object class catefit containing following components: ate.randomForest: vector numerical values length prop.cutoff  containing estimated ATE RMTL ratio nested subgroups (defined prop.cutoff)  constructed based estimated CATE scores random forest method.  provided score.method includes 'randomForest'. ate.boosting: ate.randomForest, nested subgroups based  estimated CATE scores boosting. provided score.method  includes 'boosting'. ate.poisson: ate.randomForest, nested subgroups based  estimated CATE scores poisson regression.  provided score.method includes 'poisson'. ate.twoReg: ate.randomForest, nested subgroups based  estimated CATE scores two regressions.  provided score.method includes 'twoReg'. ate.contrastReg: ate.randomForest, nested subgroups based  estimated CATE scores contrast regression.  provided score.method includes 'contrastReg'. hr.randomForest: vector numerical values length prop.cutoff  containing adjusted hazard ratio nested subgroups (defined prop.cutoff)  constructed based estimated CATE scores random forest method.  provided score.method includes 'randomForest'. hr.boosting: hr.randomForest, nested subgroups based  estimated CATE scores boosting. provided score.method  includes 'boosting'. hr.poisson: hr.randomForest, nested subgroups based  estimated CATE scores poisson regression.  provided score.method includes 'poisson'. hr.twoReg: hr.randomForest, nested subgroups based  estimated CATE scores two regressions.  provided score.method includes 'twoReg'. hr.contrastReg: hr.randomForest, nested subgroups based  estimated CATE scores contrast regression.  provided score.method includes 'contrastReg'. score.randomForest: vector numerical values length n  (number observations data) containing estimated log-CATE scores  according random forest. provided score.method  includes 'randomForest'. score.boosting: score.randomForest, estimated log-CATE score  according boosting. provided score.method includes  'boosting'. score.poisson: score.randomForest, estimated log-CATE score  according Poisson regression. provided score.method  includes 'poisson'. score.twoReg: score.randomForest, estimated log-CATE score  according two regressions. provided score.method includes  'twoReg'. score.contrastReg: score.randomForest, estimated log-CATE score  according contrast regression. provided score.method includes  'contrastReg'. fit: Additional details model fitting score.method  includes 'randomForest', 'boosting' 'contrastReg': result.randomForest: Details random forest model fitted observations    treatment = 0 ($fit0.rf) observations treatment = 1 ($fit1.rf).    provided score.method includes 'randomForest'. result.boosting: Details boosting model fitted observations    treatment = 0, ($fit0.boosting) ($fit0.gam) observations treatment = 1,    ($fit1.boosting) ($fit1.gam).    provided score.method includes 'boosting'. result.contrastReg$converge.contrastReg: Whether contrast regression algorithm converged    . provided score.method includes 'contrastReg'. coefficients: data frame coefficients estimated log-CATE  score score.method. data frame number rows equal number  covariates cate.model number columns equal length(score.method).  score.method includes 'contrastReg', data frame additional  column containing standard errors coefficients estimated contrast regression.  'randomForest' 'boosting' coefficient results  tree-based methods typically express log-CATE linear combination coefficients  covariates. errors/warnings: nested list errors warnings wrapped  calculation ATE. Errors warnings organized score.method.","code":""},{"path":"/reference/catefitsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"CATE score represents individual-level treatment effect survival data, estimated random forest, boosting, Poisson regression, doubly robust estimator (two regressions, Yadlowsky, 2020) applied separately treatment group doubly robust estimators (contrast regression, Yadlowsky, 2020) applied entire data set. catefitsurv() provides coefficients CATE score scoring method requested score.method. Currently, contrast regression method allows inference CATE coefficients providing standard errors coefficients. coefficients can used learn effect size variable predict CATE score new observation. catefitsurv() also provides predicted CATE score observation data set, scoring method. predictions allow ranking observations potentially high responders treatment potentially low standard responders. estimated ATE among nested subgroups high responders also provided scoring method. Note ATEs catefitsurv() derived based CATE score estimated using data sample. Therefore, overfitting may issue. catecvsurv() suitable inspect estimated ATEs across scoring methods implements internal cross validation reduce optimism.","code":""},{"path":"/reference/catefitsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/catefitsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"","code":"# \\donttest{ library(survival)  tau0 <- with(survivalExample, min(quantile(y[trt == \"drug1\"], 0.95),                                quantile(y[trt == \"drug0\"], 0.95)))  fit <- catefitsurv(data = survivalExample,                    score.method = \"randomForest\",                    cate.model = Surv(y, d) ~ age + female + previous_cost +                                              previous_number_relapses,                    ps.model = trt ~ age + previous_treatment,                    ipcw.model = ~ age + previous_cost + previous_treatment,                    tau0 = tau0,                    seed = 999)  coef(fit) # }"},{"path":"/reference/countExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data with count outcome — countExample","title":"Simulated data with count outcome — countExample","text":"dataset containing count outcome, length follow-6 baseline covariates","code":""},{"path":"/reference/countExample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated data with count outcome — countExample","text":"","code":"data(countExample)"},{"path":"/reference/countExample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data with count outcome — countExample","text":"dataframe 4000 rows (patients) 9 variables: age age baseline, centered 48 years old, years female sex, 0 male, 1 female previous_treatment previous treatment, \"drugA\", \"drugB\", \"drugC\" previous_cost previous medical cost, US dollars previous_number_symptoms previous number symptoms, \"0\", \"1\", \">=2\" previous_number_relapses previous number relapses trt current treatment, \"drug0\" \"drug1\" y count oucome, current number relapses years length follow-, years","code":""},{"path":"/reference/countExample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated data with count outcome — countExample","text":"","code":"data(countExample) str(countExample) rate <- countExample$y / countExample$years"},{"path":"/reference/cox.rmst.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","title":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","text":"Estimate restricted mean survival time (RMST) based Cox regression model","code":""},{"path":"/reference/cox.rmst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","text":"","code":"cox.rmst(y, d, x.cate, xnew, tau0)"},{"path":"/reference/cox.rmst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. xnew Matrix p.cate baseline covariates want estimate RMST; dimension m (observations new data set) p.cate tau0 truncation time defining restricted mean time lost.","code":""},{"path":"/reference/cox.rmst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","text":"estimated RMST new subjects covariates xnew; vector size m.","code":""},{"path":"/reference/data.preproc.html","id":null,"dir":"Reference","previous_headings":"","what":"Data preprocessing\r\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","title":"Data preprocessing\r\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","text":"Data preprocessing Apply beginning pmcount() cvcount(), arg.checks()","code":""},{"path":"/reference/data.preproc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data preprocessing\r\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","text":"","code":"data.preproc(   fun,   cate.model,   ps.model,   data,   prop.cutoff = NULL,   prop.multi = NULL,   ps.method,   initial.predictor.method = NULL )"},{"path":"/reference/data.preproc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data preprocessing\r\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","text":"fun function argument check needed; \"pm\" pmcount(), \"cv\" cvcount(), \"drinf\" drcount.inference(). default. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'boosting', 'poisson' (fast), 'gam'. Default NULL, assigns 'boosting' count outcomes.","code":""},{"path":"/reference/data.preproc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data preprocessing\r\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","text":"list 6 elements:            - y: outcome; vector length n (observations)            - trt: binary treatment; vector length n - x.ps: matrix p.ps baseline covariates (plus intercept); dimension n p.ps + 1 - x.cate: matrix p.cate baseline covariates; dimension n p.cate - time: offset; vector length n - fun = \"pm\":                - prop: formatted prop.cutoff - fun = \"cv\" - prop.onlyhigh: formatted prop.cutoff 0 removed applicable                - prop.bi; formatted prop.cutoff 0 1 removed applicable                - prop.multi: formatted prop.multi, starting 0 ending 1","code":""},{"path":"/reference/data.preproc.mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Data preprocessing\r\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","title":"Data preprocessing\r\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","text":"Data preprocessing Apply beginning catefitmean() catecvmean(), arg.checks()","code":""},{"path":"/reference/data.preproc.mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data preprocessing\r\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","text":"","code":"data.preproc.mean(   fun,   cate.model,   init.model,   ps.model,   data,   prop.cutoff = NULL,   prop.multi = NULL,   ps.method,   score.method = NULL,   initial.predictor.method = NULL )"},{"path":"/reference/data.preproc.mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data preprocessing\r\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","text":"fun function argument check needed; \"pm\" catefitmean(), \"cv\" catecvmean(), \"drinf\" drmean.inference(). default. cate.model formula describing outcome model fitted. outcome must appear left-hand side. init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. initial.predictor.method character vector method used get initial outcome predictions conditional covariates. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'boosting', 'poisson' (fast), 'gam'. Default NULL, assigns 'boosting' count outcomes.","code":""},{"path":"/reference/data.preproc.mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data preprocessing\r\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","text":"list 6 elements:            - y: outcome; vector length n (observations)            - trt: binary treatment; vector length n - x.ps: matrix p.ps baseline covariates (plus intercept); dimension n p.ps + 1 - x.cate: matrix p.cate baseline covariates; dimension n p.cate - x.init: matrix p.init baseline covariates; dimension n p.init - fun = \"pm\":                - prop: formatted prop.cutoff - fun = \"cv\" - prop.onlyhigh: formatted prop.cutoff 0 removed applicable                - prop.bi; formatted prop.cutoff 0 1 removed applicable                - prop.multi: formatted prop.multi, starting 0 ending 1","code":""},{"path":"/reference/data.preproc.surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Data preprocessing\r\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","title":"Data preprocessing\r\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","text":"Data preprocessing Apply beginning catefitcount(), catecvcount(), catefitsurv(), catecvsurv(), arg.checks()","code":""},{"path":"/reference/data.preproc.surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data preprocessing\r\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","text":"","code":"data.preproc.surv(   fun,   cate.model,   ps.model,   ipcw.model = NULL,   tau0 = NULL,   data,   prop.cutoff = NULL,   prop.multi = NULL,   ps.method,   initial.predictor.method = NULL,   response = \"count\" )"},{"path":"/reference/data.preproc.surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data preprocessing\r\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","text":"fun function argument check needed; \"catefit\" catefitcount() catefitsurv(), \"crossv\" catecvcount() catecvsurv(), \"drinf\" drcount.inference() drsurv.inference(). default. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. ipcw.model formula describing inverse probability censoring weighting(IPCW) model fitted. covariates outcome model, set ipcw.model = NULL. Otherwise, left-hand side must empty right-hand side covariates model. tau0 truncation time defining restricted mean time lost. Default NULL, corresponds setting truncation time maximum survival time data data data frame containing variables outcome, propensity score, IPCW models; data frame n rows (1 row per observation). prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'randomForest' (survival outcomes ), 'boosting', 'logistic' (survival outcomes , fast), 'poisson' (count outcomes , fast), 'gam' (count outcomes ). Default NULL, assigns 'boosting' count outcomes 'randomForest' survival outcomes. response type response variables; count (default) survival.","code":""},{"path":"/reference/data.preproc.surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data preprocessing\r\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","text":"list elements:            - y: outcome; vector length n (observations)            - d : event indicator; vector length n; respone = \"survival\" - trt: binary treatment; vector length n - x.ps: matrix p.ps baseline covariates specified propensity score model (plus intercept); dimension n p.ps + 1 - x.cate: matrix p.cate baseline covariates specified outcome model; dimension n p.cate - x.ipcw: matrix p.ipw baseline covarites specified inverse probability censoring weighting model; dimension n p.ipw - time: offset; vector length n; response = \"count\" - fun = \"catefit\":                - prop: formatted prop.cutoff - prop.no1: formatted prop.cutoff 1 removed applicable; otherwise prop.no1 prop            - fun = \"crossv\" - prop.onlyhigh: formatted prop.cutoff 0 removed applicable                - prop.bi; formatted prop.cutoff 0 1 removed applicable                - prop.multi: formatted prop.multi, starting 0 ending 1","code":""},{"path":"/reference/drcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of the average treatment effect for count data — drcount","title":"Doubly robust estimator of the average treatment effect for count data — drcount","text":"Doubly robust estimator average treatment effect two treatments, rate ratio treatment 1 treatment 0 count outcomes.","code":""},{"path":"/reference/drcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of the average treatment effect for count data — drcount","text":"","code":"drcount(   y,   trt,   x.cate,   x.ps,   time,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   interactions = TRUE )"},{"path":"/reference/drcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of the average treatment effect for count data — drcount","text":"y numeric vector size n element representing observed count outcome subject. trt numeric vector (0, 1) size n element representing treatment received subject. x.cate numeric matrix dimension n p.cate column representing baseline covariate specified outcome model subjects. x.ps numeric matrix dimension n p.ps + 1 leading column 1 intercept remaining column representing baseline covariate specified propensity score model subjects. time numeric vector size n element representing log-transformed person-years follow-subject. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value 0 1 estimated propensity scores truncated. Default 0.01. maxPS numerical value 0 1 estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. interactions logical value indicating whether outcome model allow treatment-covariate interaction x. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE.","code":""},{"path":"/reference/drcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of the average treatment effect for count data — drcount","text":"Return list 4 elements: log.rate.ratio:  numeric value estimated log rate ratio. rate0:  numeric value estimated rate group trt=0. rate1:  numeric value estimated rate group trt=1.","code":""},{"path":"/reference/drmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of the average treatment effect for continuous data — drmean","title":"Doubly robust estimator of the average treatment effect for continuous data — drmean","text":"Doubly robust estimator average treatment effect two treatments, mean difference treatment 1 treatment 0 continuous outcomes.","code":""},{"path":"/reference/drmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of the average treatment effect for continuous data — drmean","text":"","code":"drmean(   y,   trt,   x.cate,   x.ps,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   interactions = TRUE )"},{"path":"/reference/drmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of the average treatment effect for continuous data — drmean","text":"y numeric vector size n element representing observed continuous outcome subject. trt numeric vector (0, 1) size n element representing treatment received subject. x.cate numeric matrix dimension n p.cate column representing baseline covariate specified outcome model subjects. x.ps numeric matrix dimension n p.ps + 1 leading column 1 intercept remaining column representing baseline covariate specified propensity score model subjects ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. interactions logical value indicating whether outcome model assume interactions x trt. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE.","code":""},{"path":"/reference/drmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of the average treatment effect for continuous data — drmean","text":"Return list 4 elements: mean.diff:  numeric value estimated mean difference. mean.diff0:  numeric value estimated mean difference   treatment group 0. mean.diff1:  numeric value estimated mean difference   treatment group 1.","code":""},{"path":"/reference/drsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","title":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","text":"Doubly robust estimator average treatment effect two treatments, restricted mean time lost (RMTL) ratio treatment 1 treatment 0 survival outcomes.","code":""},{"path":"/reference/drsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","text":"","code":"drsurv(   y,   d,   x.cate,   x.ps,   x.ipcw,   trt,   yf = NULL,   tau0,   surv.min = 0.025,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   ipcw.method = \"breslow\" )"},{"path":"/reference/drsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. trt Treatment received; vector size n treatment coded 0/1. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. tau0 truncation time defining restricted mean time lost. surv.min Lower truncation limit probability censored (positive close 0). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'.","code":""},{"path":"/reference/drsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","text":"Return list 4 elements: rmst1:  numeric value estimated restricted mean survival time n group trt = 1. rmst0:  numeric value estimated restricted mean survival time n group trt = 0. log.rmtl.ratio:  numeric value estimated log rmtl ratio. log.hazard.ratio:  numeric value estimated log hazard ratio.","code":""},{"path":"/reference/estcount.bilevel.subgroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the Average Treatment Effect of the log risk ratio in multiple\r\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","title":"Estimate the Average Treatment Effect of the log risk ratio in multiple\r\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","text":"care higher subgroup (cutoff), need trt.est.high set onlyhigh TRUE Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == TRUE;  estcount.bilevel.subgroups() always takes subgroup top highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"/reference/estcount.bilevel.subgroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the Average Treatment Effect of the log risk ratio in multiple\r\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","text":"","code":"estcount.bilevel.subgroups(   y,   x.cate,   x.ps,   time,   trt,   score,   higher.y,   prop,   onlyhigh,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99 )"},{"path":"/reference/estcount.bilevel.subgroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the Average Treatment Effect of the log risk ratio in multiple\r\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","text":"y Observed outcome; vector size n (observations) x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) time Log-transformed person-years follow-; vector size n trt Treatment received; vector size n units treatment coded 0/1 score Estimated log CATE scores n observations one four methods (boosting, naive Poisson, two regressions, contrast regression); vector size n higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated log CATE scores define subgroups calculate ATE ; vector floats (0,1] (onlyhigh=T) (0,1) (onlyhigh=F):              element prop represents high/low cutoff bi-level subgroup length prop              number bi-level subgroups onlyhigh Indicator returning ATEs higher--cutoff category bi-level subgroups; boolean ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"/reference/estcount.bilevel.subgroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the Average Treatment Effect of the log risk ratio in multiple\r\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","text":"ate.est.high: estimated ATEs multiple bi-level subgroups higher--cutoff category; vector size equal length prop; always returned         ate.est.low: estimated ATEs multiple bi-level subgroups lower--cutoff category;         vector size equal length prop; returned onlyhigh == TRUE","code":""},{"path":"/reference/estcount.multilevel.subgroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","title":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","text":"Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == TRUE;  subgroups defined estcount.multilevel.subgroup() start lowest highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"/reference/estcount.multilevel.subgroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","text":"","code":"estcount.multilevel.subgroup(   y,   x.cate,   x.ps,   time,   trt,   score,   higher.y,   prop,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99 )"},{"path":"/reference/estcount.multilevel.subgroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","text":"y Observed outcome; vector size n (observations) x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) time Log-transformed person-years follow-; vector size n trt Treatment received; vector size n units treatment coded 0/1 score Estimated log CATE scores n observations one four methods (boosting, naive Poisson, two regressions, contrast regression); vector size n higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated log CATE scores define subgroups calculate ATE ; vector floats [0,1] always starting 0 ending 1:              element prop represents inclusive cutoffs multilevel subgroup length prop              number categories multilevel subgroup ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"/reference/estcount.multilevel.subgroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","text":"estimated ATEs categories one multilevel subgroup; vector size equal length categories multilevel subgroup","code":""},{"path":"/reference/estmean.bilevel.subgroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the mean difference in multiple bi-level subgroups\r\ndefined by the proportions — estmean.bilevel.subgroups","title":"Estimate the ATE of the mean difference in multiple bi-level subgroups\r\ndefined by the proportions — estmean.bilevel.subgroups","text":"care higher subgroup (cutoff), need trt.est.high set onlyhigh TRUE. Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == TRUE. estcount.bilevel.subgroups() always takes subgroup top highest adjusted scores,higher adjusted scores always represent high responders treatment group 1.","code":""},{"path":"/reference/estmean.bilevel.subgroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the mean difference in multiple bi-level subgroups\r\ndefined by the proportions — estmean.bilevel.subgroups","text":"","code":"estmean.bilevel.subgroups(   y,   x.cate,   x.ps,   trt,   score,   higher.y,   prop,   onlyhigh,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99 )"},{"path":"/reference/estmean.bilevel.subgroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the mean difference in multiple bi-level subgroups\r\ndefined by the proportions — estmean.bilevel.subgroups","text":"y Observed outcome; vector size n (observations) x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) trt Treatment received; vector size n units treatment coded 0/1 score Estimated CATE scores n observations one six methods (boosting, linear regression, two regressions, contrast regression, random forest, generalized additive model); vector size n higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated CATE scores define subgroups calculate ATE ; vector floats (0,1] (onlyhigh=T) (0,1) (onlyhigh=F):              element prop represents high/low cutoff bi-level subgroup length prop              number bi-level subgroups onlyhigh Indicator returning ATEs higher--cutoff category bi-level subgroups; boolean ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"/reference/estmean.bilevel.subgroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the mean difference in multiple bi-level subgroups\r\ndefined by the proportions — estmean.bilevel.subgroups","text":"ate.est.high: estimated ATEs multiple bi-level subgroups higher--cutoff category; vector size equal length prop; always returned         ate.est.low: estimated ATEs multiple bi-level subgroups lower--cutoff category;         vector size equal length prop; returned onlyhigh == TRUE","code":""},{"path":"/reference/estmean.multilevel.subgroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","title":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","text":"Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == TRUE;  subgroups defined estmean.multilevel.subgroup() start lowest highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"/reference/estmean.multilevel.subgroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","text":"","code":"estmean.multilevel.subgroup(   y,   x.cate,   x.ps,   trt,   score,   higher.y,   prop,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99 )"},{"path":"/reference/estmean.multilevel.subgroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","text":"y Observed outcome; vector size n (observations) x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) trt Treatment received; vector size n units treatment coded 0/1 score Estimated CATE scores n observations one six methods (boosting, linear regression, two regressions, contrast regression, random forest, generalized additive model); vector size n higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated CATE scores define subgroups calculate ATE ; vector floats [0,1] always starting 0 ending 1:              element prop represents inclusive cutoffs multilevel subgroup length prop              number categories multilevel subgroup ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"/reference/estmean.multilevel.subgroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","text":"estimated ATEs categories one multilevel subgroup; vector size equal length categories multilevel subgroup","code":""},{"path":"/reference/estsurv.bilevel.subgroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","text":"care higher subgroup (cutoff), need ate.rmtl.high hr.high set \"onlyhigh\" TRUE Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == FALSE;  estsurv() function always takes subgroup top highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"/reference/estsurv.bilevel.subgroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","text":"","code":"estsurv.bilevel.subgroups(   y,   d,   x.cate,   x.ps,   x.ipcw,   trt,   yf,   tau0 = tau0,   score,   higher.y,   prop,   onlyhigh,   surv.min = 0.025,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   ipcw.method = \"breslow\" )"},{"path":"/reference/estsurv.bilevel.subgroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. trt Treatment received; vector size n treatment coded 0/1. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. tau0 truncation time defining restricted mean time lost. score Estimated log CATE scores n observations one five methods (random forest, boosting, naive Poisson, two regressions, contrast regression); vector size n. higher.y logical value indicating whether higher (TRUE) lower (FALSE) prop Proportions corresponding percentiles estimated log CATE scores define subgroups calculate ATE ; vector floats (0,1] (onlyhigh=TRUE) (0,1) (onlyhigh=FALSE):              element prop represents high/low cutoff bi-level subgroup length prop              number bi-level subgroups onlyhigh Indicator returning ATEs higher--cutoff category bi-level subgroups; boolean. surv.min Lower truncation limit probability censored (positive close 0). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'.","code":""},{"path":"/reference/estsurv.bilevel.subgroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","text":"ate.rmtl.high: estimated ATEs (ratio RMTL) multiple bi-level subgroups higher--cutoff category; vector size equal length prop; always returned.         ate.rmtl.low: estimated ATEs (ratio RMTL) multiple bi-level subgroups lower--cutoff category;         vector size equal length prop; returned onlyhigh = TRUE.         hr.high: unadjusted hazard ratio multiple bi-level subgroups higher--cutoff category;         vector size equal length prop; always returned.         hr.low: unadjusted hazard ratio multiple bi-level subgroups lower--cutoff category;         vector size equal length prop; returned onlyhigh = TRUE","code":""},{"path":"/reference/estsurv.multilevel.subgroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","text":"Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == FALSE;  estsurv function multilevel subgroups start lowest highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"/reference/estsurv.multilevel.subgroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","text":"","code":"estsurv.multilevel.subgroups(   y,   d,   x.cate,   x.ps,   x.ipcw,   trt,   yf,   tau0 = tau0,   score,   higher.y,   prop,   surv.min = 0.025,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   ipcw.method = \"breslow\" )"},{"path":"/reference/estsurv.multilevel.subgroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. trt Treatment received; vector size n treatment coded 0/1. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. tau0 truncation time defining restricted mean time lost. score Estimated log CATE scores n observations one five methods (random forest, boosting, naive Poisson, two regressions, contrast regression); vector size n. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated log CATE scores define subgroups calculate ATE ; vector floats [0,1] always starting 0 ending 1:              element prop represents inclusive cutoffs multilevel subgroup length prop              number categories multilevel subgroup surv.min Lower truncation limit probability censored (positive close 0). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'.","code":""},{"path":"/reference/estsurv.multilevel.subgroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","text":"ate.rmtl: estimated ATEs (ratio RMTL) categories one multilevel subgroup; vector size equal length categories multilevel subgroup.         ate.hr: unadjusted hazard ratio categories one multilevel subgroup;         vector size equal length categories multilevel subgroup.","code":""},{"path":"/reference/glm.ps.html","id":null,"dir":"Reference","previous_headings":"","what":"Propensity score estimation with LASSO — glm.ps","title":"Propensity score estimation with LASSO — glm.ps","text":"Propensity score based multivariate logistic regression LASSO penalization two-way interactions","code":""},{"path":"/reference/glm.ps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Propensity score estimation with LASSO — glm.ps","text":"","code":"glm.ps(trt, x.ps, xnew = NULL, minPS = 0.01, maxPS = 0.99)"},{"path":"/reference/glm.ps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Propensity score estimation with LASSO — glm.ps","text":"trt Treatment received; vector size n (observations) treatment coded 0/1 x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) xnew Matrix p.ps baseline covariates (plus leading column 1 intercept) want propensity scores predictions; dimension m (observations new data set) p.ps + 1 minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"/reference/glm.ps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Propensity score estimation with LASSO — glm.ps","text":"trimmed propensity score unit; vector size n (xnew NULL) m","code":""},{"path":"/reference/glm.simplereg.ps.html","id":null,"dir":"Reference","previous_headings":"","what":"Propensity score estimation with a linear model — glm.simplereg.ps","title":"Propensity score estimation with a linear model — glm.simplereg.ps","text":"Propensity score based multivariate logistic regression main effects ","code":""},{"path":"/reference/glm.simplereg.ps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Propensity score estimation with a linear model — glm.simplereg.ps","text":"","code":"glm.simplereg.ps(trt, x.ps, xnew = NULL, minPS = 0.01, maxPS = 0.99)"},{"path":"/reference/glm.simplereg.ps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Propensity score estimation with a linear model — glm.simplereg.ps","text":"trt Treatment received; vector size n (observations) treatment coded 0/1 x.ps matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) xnew matrix p.ps baseline covariates (plus leading column 1 intercept) want PS predictions; dimension m (observations new data set) p.ps + 1 minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"/reference/glm.simplereg.ps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Propensity score estimation with a linear model — glm.simplereg.ps","text":"estimated propensity score unit; vector size n (xnew NULL) m","code":""},{"path":"/reference/intxcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the CATE model using specified scoring methods — intxcount","title":"Estimate the CATE model using specified scoring methods — intxcount","text":"Coefficients CATE estimated boosting, naive Poisson, two regression, contrast regression, negative binomial","code":""},{"path":"/reference/intxcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the CATE model using specified scoring methods — intxcount","text":"","code":"intxcount(   y,   trt,   x.cate,   x.ps,   time,   score.method = c(\"boosting\", \"poisson\", \"twoReg\", \"contrastReg\", \"negBin\"),   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   initial.predictor.method = \"boosting\",   xvar.smooth = NULL,   tree.depth = 2,   n.trees.boosting = 200,   B = 3,   Kfold = 6,   plot.gbmperf = TRUE,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   ... )"},{"path":"/reference/intxcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the CATE model using specified scoring methods — intxcount","text":"y Observed outcome; vector size n (observations) trt Treatment received; vector size n units treatment coded 0/1 x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) time Log-transformed person-years follow-; vector size n score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. Default specifies 5 methods. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS number estimated propensity scores trimmed; scalar initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'poisson' (fastest), 'boosting' (default) 'gam'. xvar.smooth vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). ... Additional arguments gbm()","code":""},{"path":"/reference/intxcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the CATE model using specified scoring methods — intxcount","text":"Depending score.method , outputs combination following:           result.boosting: Results boosting fit best iteration, trt = 0 trt = 1 separately           result.poisson: Naive Poisson estimator (beta1 - beta0); vector length p.cate + 1           result.twoReg: Two regression estimator (beta1 - beta0); vector length p.cate + 1           result.contrastReg: list contrast regression results 3 elements:               $delta.contrastReg: Contrast regression DR estimator; vector length p.cate + 1               $sigma.contrastReg: Variance covariance matrix delta.contrastReg; matrix size p.cate + 1 p.cate + 1               $converge.contrastReg: Indicator Newton Raphson algorithm converged delta_0; boolean           result.negBin: Negative binomial estimator (beta1 - beta0); vector length p.cate + 1           best.iter: Largest best iterations boosting (used)           fgam: Formula applied GAM (used)","code":""},{"path":"/reference/intxmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the CATE model using specified scoring methods — intxmean","title":"Estimate the CATE model using specified scoring methods — intxmean","text":"Coefficients CATE estimated boosting, linear regression, two regression, contrast regression, random forest, generalized additive model","code":""},{"path":"/reference/intxmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the CATE model using specified scoring methods — intxmean","text":"","code":"intxmean(   y,   trt,   x.cate,   x.init,   x.ps,   score.method = c(\"boosting\", \"gaussian\", \"twoReg\", \"contrastReg\", \"gam\",     \"randomForest\"),   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   initial.predictor.method = \"boosting\",   xvar.smooth.init,   xvar.smooth.score,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 1,   Kfold = 2,   plot.gbmperf = TRUE,   ... )"},{"path":"/reference/intxmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the CATE model using specified scoring methods — intxmean","text":"y Observed outcome; vector size n (observations) trt Treatment received; vector size n units treatment coded 0/1 x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.init Matrix p.init baseline covariates; dimension n p.init must specified score.method = contrastReg twoReg. x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. Default specifies 6 methods. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS number estimated propensity scores trimmed; scalar initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'gaussian' (fastest), 'boosting' (default) 'gam'. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.rf positive integer specifying number trees. Used score.method = 'randomForest'. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. ... Additional arguments gbm()","code":""},{"path":"/reference/intxmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the CATE model using specified scoring methods — intxmean","text":"Depending score.method , outputs combination following:           result.boosting: Results boosting fit best iteration, trt = 0 trt = 1 separately           result.gaussian: Linear regression estimator (beta1 - beta0); vector length p.cate + 1           result.twoReg: Two regression estimator (beta1 - beta0); vector length p.cate + 1           result.contrastReg: list contrast regression results 3 elements:               $delta.contrastReg: Contrast regression DR estimator; vector length p.cate + 1               $sigma.contrastReg: Variance covariance matrix delta.contrastReg; matrix size p.cate + 1 p.cate + 1           result.randomForest: Results random forest fit best iteration, trt = 0 trt = 1 separately           result.gam: Results generalized additive model fit best iteration, trt = 0 trt = 1 separately           best.iter: Largest best iterations boosting (used)           fgam: Formula applied GAM initial.predictor.method = 'gam' warn.fit: Warnings occurred fitting score.method err.fit:: Errors occurred fitting score.method","code":""},{"path":"/reference/intxsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","title":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","text":"Coefficients CATE estimated random forest, boosting, naive Poisson, two regression, contrast regression","code":""},{"path":"/reference/intxsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","text":"","code":"intxsurv(   y,   d,   trt,   x.cate,   x.ps,   x.ipcw,   yf = NULL,   tau0,   surv.min = 0.025,   score.method = c(\"randomForest\", \"boosting\", \"poisson\", \"twoReg\", \"contrastReg\"),   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   ipcw.method = \"breslow\",   initial.predictor.method = \"randomForest\",   tree.depth = 3,   n.trees.rf = 1000,   n.trees.boosting = 150,   B = 3,   Kfold = 5,   plot.gbmperf = TRUE,   error.maxNR = 0.001,   max.iterNR = 100,   tune = c(0.5, 2),   ... )"},{"path":"/reference/intxsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. trt Treatment received; vector size n treatment coded 0/1. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. tau0 truncation time defining restricted mean time lost. surv.min Lower truncation limit probability censored (positive close 0). score.method vector one multiple methods estimate CATE score. Allowed values :  'randomForest', 'boosting', 'poisson', 'twoReg', 'contrastReg'. Default specifies 5 methods. ps.method character vector method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS number estimated propensity scores trimmed; scalar ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'randomForest', 'boosting' 'logistic' (fastest). Default 'randomForest'. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 3. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 150. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 100. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). ... Additional arguments gbm()","code":""},{"path":"/reference/intxsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","text":"Depending score.method , outputs combination following:           result.randomForest: Results random forest fit, trt = 0 trt = 1 separately           result.boosting: Results boosting fit, trt = 0 trt = 1 separately           result.poisson: Naive Poisson estimator (beta1 - beta0); vector length p.cate + 1           result.twoReg: Two regression estimator (beta1 - beta0); vector length p.cate + 1           result.contrastReg: list contrast regression results 2 elements:               $delta.contrastReg: Contrast regression DR estimator; vector length p.cate + 1               $converge.contrastReg: Indicator Newton Raphson algorithm converged delta_0; boolean","code":""},{"path":"/reference/ipcw.surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability of being censored — ipcw.surv","title":"Probability of being censored — ipcw.surv","text":"Probability censored used correct effect right censoring.","code":""},{"path":"/reference/ipcw.surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability of being censored — ipcw.surv","text":"","code":"ipcw.surv(   y,   d,   x.ipcw,   yf = NULL,   ipcw.method = \"breslow\",   tau0,   surv.min = 0.025 )"},{"path":"/reference/ipcw.surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability of being censored — ipcw.surv","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. unknown, set yf == NULL yf taken y function. ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'. tau0 truncation time defining restricted mean time lost. surv.min Lower truncation limit probability censored (positive close 0).","code":""},{"path":"/reference/ipcw.surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probability of being censored — ipcw.surv","text":"vector size n estimated probabilities Pr(C > min(y, tau0) | x.ipcw)","code":""},{"path":"/reference/meanCatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","text":"Storing errors warnings occurred estimating ATEs nested subgroups. errors warnings, estimated mean difference provided. warnings errors, estimated mean difference provided warning attribute set. errors, NA values returned mean difference. error attribute set also provided.","code":""},{"path":"/reference/meanCatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","text":"","code":"meanCatch(fun)"},{"path":"/reference/meanCatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","text":"fun drsurv function...","code":""},{"path":"/reference/meanCatch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","text":"list containing","code":""},{"path":"/reference/meanExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data with a continuous outcome — meanExample","title":"Simulated data with a continuous outcome — meanExample","text":"dataset containing continuous outcome 6 baseline covariates","code":""},{"path":"/reference/meanExample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated data with a continuous outcome — meanExample","text":"","code":"data(meanExample)"},{"path":"/reference/meanExample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data with a continuous outcome — meanExample","text":"dataframe 4000 rows (patients) 9 variables: age age baseline, centered 48 years old, years female sex, 0 male, 1 female previous_treatment previous treatment, \"drugA\", \"drugB\", \"drugC\" previous_cost previous medical cost, US dollars previous_number_symptoms previous number symptoms, \"0\", \"1\", \">=2\" previous_number_relapses previous number relapses trt current treatment, \"drug0\" \"drug1\" y count oucome, current number relapses","code":""},{"path":"/reference/meanExample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated data with a continuous outcome — meanExample","text":"","code":"data(meanExample) str(meanExample)"},{"path":"/reference/onearmglmcount.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","text":"Doubly robust estimators coefficients two regression","code":""},{"path":"/reference/onearmglmcount.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","text":"","code":"onearmglmcount.dr(y, x.cate, time, trt, ps, f.predictor)"},{"path":"/reference/onearmglmcount.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","text":"y Observed outcome; vector size n x.cate Matrix p baseline covariates; dimension n p time Log-transformed person-years follow-; vector size n trt Treatment received; vector size n units treatment coded 0/1 ps Estimated propensity scores observations; vector size n f.predictor Initial prediction outcome (expected number relapses one unit exposure time) conditioned covariates x one treatment group r; mu_r(x), step 1 two regression; vector size n","code":""},{"path":"/reference/onearmglmcount.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","text":"Doubly robust estimators regression coefficients beta_r doubly robust estimating equation r = 0, 1 treatment received; vector size p + 1 (intercept included)","code":""},{"path":"/reference/onearmglmmean.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","text":"Doubly robust estimators coefficients two regression","code":""},{"path":"/reference/onearmglmmean.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","text":"","code":"onearmglmmean.dr(y, x.cate, trt, ps, f.predictor)"},{"path":"/reference/onearmglmmean.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","text":"y Observed outcome; vector size n x.cate Matrix p baseline covariates; dimension n p trt Treatment received; vector size n units treatment coded 0/1 ps Estimated propensity scores observations; vector size n f.predictor Initial prediction outcome (expected number relapses one unit exposure time) conditioned covariates x one treatment group r; mu_r(x), step 1 two regression; vector size n","code":""},{"path":"/reference/onearmglmmean.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","text":"Doubly robust estimators regression coefficients beta_r doubly robust estimating equation r = 0, 1 treatment received; vector size p + 1 (intercept included)","code":""},{"path":"/reference/onearmsurv.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","title":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","text":"Doubly robust estimators coefficients two regression","code":""},{"path":"/reference/onearmsurv.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","text":"","code":"onearmsurv.dr(ynew, dnew, trt, x.cate, tau0, weightsurv, ps, f.predictor)"},{"path":"/reference/onearmsurv.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","text":"ynew Truncated survival censoring time; vector size n. dnew event indicator truncation, 1 = event censored truncation, 0 = censored truncation; vector size n. trt Treatment received; vector size n treatment coded 0/1. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. tau0 truncation time defining restricted mean time lost. weightsurv Estimated inverse probability censoring weights truncation observations; vector size n. ps Estimated propensity scores observations; vector size n f.predictor Initial prediction outcome (restricted mean time loss) conditioned covariates x.cate one treatment group r; mu_r(x.cate), step 1 two regression; vector size n","code":""},{"path":"/reference/onearmsurv.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","text":"Doubly robust estimators two regression coefficients beta_r r = 0, 1 treatment received; vector size p.cate + 1 (intercept included)","code":""},{"path":"/reference/plot.atefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Histogram of bootstrap estimates — plot.atefit","title":"Histogram of bootstrap estimates — plot.atefit","text":"Histogram bootstrap estimates","code":""},{"path":"/reference/plot.atefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Histogram of bootstrap estimates — plot.atefit","text":"","code":"# S3 method for atefit plot(x, bins, alpha = 0.7, title = waiver(), theme = theme_classic(), ...)"},{"path":"/reference/plot.atefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Histogram of bootstrap estimates — plot.atefit","text":"x object class \"atefit\". bins Number bins alpha Opacity title text title theme Defaults theme_classic(). options include theme_grey(), theme_bw(), theme_light(), theme_dark(), theme_void() ... parameters","code":""},{"path":"/reference/plot.atefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Histogram of bootstrap estimates — plot.atefit","text":"plot class ggplot, displaying estimated ATE across bootstrap samples","code":""},{"path":"/reference/plot.atefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Histogram of bootstrap estimates — plot.atefit","text":"Create histogram displaying distribution bootstrap estimates. red vertical reference line represents final estimate.","code":""},{"path":"/reference/plot.atefit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Histogram of bootstrap estimates — plot.atefit","text":"Thomas Debray","code":""},{"path":"/reference/plot.precmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Two side-by-side line plots of validation curves from the ","title":"Two side-by-side line plots of validation curves from the ","text":"Provides validation curves two side--side plots, visualizing estimated ATEs series nested subgroups training set validation set separately, line represents one scoring method specified catecv() catecvmean(). run results catecv() catecvmean() obtained.","code":""},{"path":"/reference/plot.precmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two side-by-side line plots of validation curves from the ","text":"","code":"# S3 method for precmed plot(   x,   cv.i = NULL,   combine = \"mean\",   show.abc = TRUE,   valid.only = FALSE,   plot.hr = FALSE,   ylab = NULL,   legend.position = \"bottom\",   xlim = NULL,   title = waiver(),   theme = theme_classic(),   ... )"},{"path":"/reference/plot.precmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two side-by-side line plots of validation curves from the ","text":"x object class \"precmed\". cv.positive integer indicating index CV iteration results plotted. Allowed values : positive integer \\(<=\\) cv.n catecv() NULL. cv.= NULL, results across CV iterations combined according combine plotted. Default NULL. combine character value indicating combine estimated ATEs across CV iterations validation curve nested subgroup, separately training validation results. Allowed values : 'mean' 'median'. Used cv.= NULL. Default 'mean'. show.abc logical value indicating whether show ABC statistics validation set. Used x$abc = TRUE xlim limited smaller range (.e., xlim = NULL equal entire x$prop.onlyhigh range). cv.NULL, ABC statistics based combined CV iterations. cv.integer, ABC statistics based solely CV iteration. Default TRUE. valid.logical value indicating whether validation curves validation set plotted (TRUE). Otherwise, validation curves training validation sets plotted side--side (FALSE). Default FALSE. plot.hr logical value indicating whether hazard ratios plotted validation curves (TRUE). Otherwise, restricted mean time lost plotted (FALSE). argument applicable survival outcomes. Default FALSE. ylab character value y-axis label describe ATE . Default NULL, creates default y-axis label based available data. legend.position character value legend position argument passed ggplot object. Default 'bottom'. xlim numeric value range x-axis. Default NULL, means range specified. title text title theme Defaults theme_classic(). options include theme_grey(), theme_bw(), theme_light(), theme_dark(), theme_void() ... parameters","code":""},{"path":"/reference/plot.precmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two side-by-side line plots of validation curves from the ","text":"Returns two side--side line plots, one shows validation curves training sets validation curves validation sets. gray horizontal dashed line overall ATE included reference. ABC statistics added legend show.abc = TRUE.","code":""},{"path":"/reference/plot.precmed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Two side-by-side line plots of validation curves from the ","text":"plot() takes outputs catecv() generates two plots validation curves side--side, one training set one validation set. Separate validation curves produced scoring method specified via score.method catecv() catecvmean(). validation curves (ABC statistics, applicable) can help compare performance different scoring methods terms discerning potential treatment heterogeneity subgroups internal validation. Steeper validation curves validation set suggest presence treatment effect heterogeneity (ability scoring methods capture ) flat validation curves indicate absence treatment effect heterogeneity (inability scoring method capture ).","code":""},{"path":"/reference/plot.precmed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two side-by-side line plots of validation curves from the ","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"/reference/plot.precmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two side-by-side line plots of validation curves from the ","text":"","code":"# \\donttest{ # Count outcome eval_1 <- catecv(response = \"count\",                  data = countExample,                  score.method = \"poisson\",                  cate.model = y ~ age + female + previous_treatment +                                   previous_cost + previous_number_relapses + offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  higher.y = FALSE,                  cv.n = 5)  # default setting plot(eval_1)  # turn off ABC annotation plot(eval_1, show.abc = FALSE)  # use a different theme plot(eval_1, theme = ggplot2::theme_bw())  # plot the validation curves from the 2nd CV iteration instead of the mean # of all validation curves plot(eval_1, cv.i = 2)  # median of the validation curves plot(eval_1, combine = \"median\")  # plot validation curves in validation set only plot(eval_1, valid.only = TRUE)  # Survival outcome library(survival) tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95))) eval_2 <- catecv(response = \"survival\",                  data = survivalExample,                  score.method = c(\"poisson\", \"randomForest\"),                  cate.model = Surv(y, d) ~ age + female + previous_cost +                                            previous_number_relapses,                  ps.model = trt ~ age + previous_treatment,                  initial.predictor.method = \"randomForest\",                  ipcw.model = ~ age + previous_cost + previous_treatment,                  tau0 = tau0,                  cv.n = 5,                  seed = 999)   # default setting, plot RMTL ratios in both training and validation sets plot(eval_2)  # plot hazard ratio plot(eval_2, plot.hr = TRUE)  # }"},{"path":"/reference/print.atefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for atefit — print.atefit","title":"Print function for atefit — print.atefit","text":"Print function atefit","code":""},{"path":"/reference/print.atefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for atefit — print.atefit","text":"","code":"# S3 method for atefit print(x, ...)"},{"path":"/reference/print.atefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for atefit — print.atefit","text":"x object class \"atefit\". ... parameters","code":""},{"path":"/reference/print.atefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print function for atefit — print.atefit","text":"return value","code":""},{"path":"/reference/print.atefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print function for atefit — print.atefit","text":"Display estimated treatment effects survival outcomes (log restricted mean time lost ratio log hazard ratio) count outcomes (log rate ratio).","code":""},{"path":"/reference/print.atefit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print function for atefit — print.atefit","text":"Thomas Debray","code":""},{"path":"/reference/print.catefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for atefit — print.catefit","title":"Print function for atefit — print.catefit","text":"Print function atefit","code":""},{"path":"/reference/print.catefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for atefit — print.catefit","text":"","code":"# S3 method for catefit print(x, ...)"},{"path":"/reference/print.catefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for atefit — print.catefit","text":"x object class \"catefit\". ... parameters","code":""},{"path":"/reference/print.catefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print function for atefit — print.catefit","text":"return value","code":""},{"path":"/reference/print.catefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print function for atefit — print.catefit","text":"Display estimated treatment effects survival outcomes (log restricted mean time lost ratio log hazard ratio) count outcomes (log rate ratio).","code":""},{"path":"/reference/print.catefit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print function for atefit — print.catefit","text":"Thomas Debray","code":""},{"path":"/reference/scorecount.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","text":"Based intxcount results CATE coefficients estimated boosting, naive Poisson, two regression, contrast regression, negative binomial","code":""},{"path":"/reference/scorecount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","text":"","code":"scorecount(   fit,   x.cate,   time,   score.method = c(\"boosting\", \"poisson\", \"twoReg\", \"contrastReg\", \"negBin\") )"},{"path":"/reference/scorecount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","text":"fit List objects generated intxcount: outputs boosting, naive Poisson, two regression, contrast regression, negative binomial x.cate Matrix p.cate baseline covariates; dimension n (observations) p.cate (covariates outcome model) time Log-transformed person-years follow-; vector size n score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. Default specifies 5 methods.","code":""},{"path":"/reference/scorecount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","text":"score.boosting: Estimated log CATE score n observations boosting method; vector size n score.poisson: Estimated log CATE score n observations naive Poisson method; vector size n score.twoReg: Estimated log CATE score n observations two regression method; vector size n score.contrastReg: Estimated log CATE score n observations contrast regression method; vector size n score.negBin: Estimated log CATE score n observations naive Poisson method; vector size n score = NA corresponding method called","code":""},{"path":"/reference/scoremean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","title":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","text":"Based intxmean results CATE coefficients estimated boosting, linear regression, two regression, contrast regression, random forest, generalized additive model","code":""},{"path":"/reference/scoremean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","text":"","code":"scoremean(   fit,   x.cate,   score.method = c(\"boosting\", \"gaussian\", \"twoReg\", \"contrastReg\", \"randomForest\",     \"gam\") )"},{"path":"/reference/scoremean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","text":"fit List objects generated intxmean: outputs boosting, linear regression, two regression, contrast regression, random forest, generalized additive model x.cate Matrix p.cate baseline covariates; dimension n (observations) p.cate (covariates outcome model) score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. Default specifies 6 methods.","code":""},{"path":"/reference/scoremean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","text":"score.boosting: Estimated CATE score n observations boosting method; vector size n score.gaussian: Estimated CATE score n observations linear regression method; vector size n score.twoReg: Estimated CATE score n observations two regression method; vector size n score.contrastReg: Estimated CATE score n observations contrast regression method; vector size n score.randomForest: Estimated CATE score n observations random forest method; vector size n score.gam: Estimated CATE score n observations generalized additive model; vector size n score = NA corresponding method called","code":""},{"path":"/reference/scoresurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","text":"Based intxsurv results CATE coefficients estimated random forest, boosting, naive Poisson, two regression, contrast regression","code":""},{"path":"/reference/scoresurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","text":"","code":"scoresurv(   fit,   x.cate,   tau0,   score.method = c(\"randomForest\", \"boosting\", \"poisson\", \"twoReg\", \"contrastReg\") )"},{"path":"/reference/scoresurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","text":"fit List objects generated intxsurv: outputs random forest, boosting, naive Poisson, two regression, contrast regression x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. tau0 truncation time defining restricted mean time lost. score.method vector one multiple methods estimate CATE score. Allowed values : 'randomForest', 'boosting', 'poisson', 'twoReg', 'contrastReg'. Default specifies 5 methods.","code":""},{"path":"/reference/scoresurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","text":"score.randomForest: Estimated log CATE score n observations random forest method; vector size n score.boosting: Estimated log CATE score n observations boosting method; vector size n score.poisson: Estimated log CATE score n observations naive Poisson method; vector size n score.twoReg: Estimated log CATE score n observations two regression method; vector size n score.contrastReg: Estimated log CATE score n observations contrast regression method; vector size n score = NA corresponding method called","code":""},{"path":"/reference/survCatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","text":"Storing errors warnings occurred estimating ATEs nested subgroups. errors warnings, estimated log.rmtl.ratio log.hazard.ratio provided. warnings errors, estimated log.rmtl.ratio log.hazard.ratio provided warning attribute set. errors, NA values returned log.rmtl.ratio log.hazard.ratio. error attribute set also provided.","code":""},{"path":"/reference/survCatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","text":"","code":"survCatch(fun)"},{"path":"/reference/survCatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","text":"fun drsurv function...","code":""},{"path":"/reference/survCatch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","text":"list containing","code":""},{"path":"/reference/survivalExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data with survival outcome — survivalExample","title":"Simulated data with survival outcome — survivalExample","text":"dataset containing time--event outcome, event indicator, treatment group, 6 baseline covariates","code":""},{"path":"/reference/survivalExample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated data with survival outcome — survivalExample","text":"","code":"data(survivalExample)"},{"path":"/reference/survivalExample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data with survival outcome — survivalExample","text":"dataframe 4000 rows (patients) 9 variables: age age baseline, centered 48 years old, years female sex, 0 male, 1 female previous_treatment previous treatment, \"drugA\", \"drugB\", \"drugC\" previous_cost previous medical cost, US dollars previous_number_symptoms previous number symptoms, \"0\", \"1\", \">=2\" previous_number_relapses previous number relapses trt current treatment, \"drug0\" \"drug1\" y time first relapse censoring d event indicator, 1: relapse, 0: censored","code":""},{"path":"/reference/survivalExample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated data with survival outcome — survivalExample","text":"","code":"data(survivalExample) str(survivalExample)"},{"path":"/reference/twoarmglmcount.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","text":"Newton-Raphson algorithm used solve estimating equation bar S_n (delta) = 0","code":""},{"path":"/reference/twoarmglmcount.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","text":"","code":"twoarmglmcount.dr(   y,   x.cate,   time,   trt,   ps,   f1.predictor,   f0.predictor,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2) )"},{"path":"/reference/twoarmglmcount.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","text":"y Observed outcome; vector size n x.cate Matrix p.cate baseline covariates; dimension n p.cate time Log-transformed person-years follow-; vector size n trt Treatment received; vector size n units treatment coded 0/1 ps Estimated propensity scores observations; vector size n f1.predictor Initial predictions outcome (expected number relapses one unit exposure time) conditioned covariates x treatment group trt = 1; mu_1(x), step 1 two regression; vector size n f0.predictor Initial predictions outcome (expected number relapses one unit exposure time) conditioned covariates x treatment group trt = 0; mu_0(x), step 1 two regression; vector size n error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2).","code":""},{"path":"/reference/twoarmglmcount.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","text":"coef: Doubly robust estimators regression coefficients delta_0; vector size p + 1 (intercept included)         vcov: Variance-covariance matrix estimated coefficient delta_0; matrix size p + 1 p + 1         converge: Indicator Newton Raphson algorithm converged delta_0; boolean","code":""},{"path":"/reference/twoarmglmmean.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix — twoarmglmmean.dr","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix — twoarmglmmean.dr","text":"Solving estimating equation bar S_n (delta) = 0","code":""},{"path":"/reference/twoarmglmmean.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix — twoarmglmmean.dr","text":"","code":"twoarmglmmean.dr(y, x.cate, trt, ps, f1.predictor, f0.predictor)"},{"path":"/reference/twoarmglmmean.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix — twoarmglmmean.dr","text":"y Observed outcome; vector size n x.cate Matrix p.cate baseline covariates; dimension n p.cate trt Treatment received; vector size n units treatment coded 0/1 ps Estimated propensity scores observations; vector size n f1.predictor Initial predictions outcome (expected number relapses one unit exposure time) conditioned covariates x treatment group trt = 1; mu_1(x), step 1 two regression; vector size n f0.predictor Initial predictions outcome (expected number relapses one unit exposure time) conditioned covariates x treatment group trt = 0; mu_0(x), step 1 two regression; vector size n","code":""},{"path":"/reference/twoarmglmmean.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix — twoarmglmmean.dr","text":"coef: Doubly robust estimators regression coefficients delta_0; vector size p + 1 (intercept included)         vcov: Variance-covariance matrix estimated coefficient delta_0; matrix size p + 1 p + 1","code":""},{"path":"/reference/twoarmsurv.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmsurv.dr","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmsurv.dr","text":"Newton-Raphson algorithm used solve estimating equation bar S_n (delta) = 0","code":""},{"path":"/reference/twoarmsurv.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmsurv.dr","text":"","code":"twoarmsurv.dr(   ynew,   dnew,   trt,   x.cate,   tau0,   weightsurv,   ps,   f1.predictor,   f0.predictor,   error.maxNR = 0.001,   max.iterNR = 100,   tune = c(0.5, 2) )"},{"path":"/reference/twoarmsurv.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmsurv.dr","text":"ynew Truncated survival time; vector size n dnew Event indicator truncation; vector size n trt Treatment received; vector size n treatment coded 0/1. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. tau0 truncation time defining restricted mean time lost. weightsurv Estimated inverse probability censoring weights truncation observations; vector size n. ps Estimated propensity scores observations; vector size n f1.predictor Initial predictions outcome (restricted mean time loss) conditioned covariates x.cate treatment group trt = 1; mu_1(x.cate), step 1 two regression; vector size n f0.predictor Initial predictions outcome (restricted mean time loss) conditioned covariates x.cate treatment group trt = 0; mu_0(x.cate), step 1 two regression; vector size n error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 100. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2).","code":""},{"path":"/reference/twoarmsurv.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the contrast regression\r\n as well as their covariance matrix and convergence information — twoarmsurv.dr","text":"coef: Doubly robust estimators contrast regression coefficients delta_0; vector size p.cate + 1 (intercept included)         converge: Indicator Newton Raphson algorithm converged delta_0; boolean","code":""},{"path":"/news/index.html","id":"precmed-1009000","dir":"Changelog","previous_headings":"","what":"precmed 1.0.0.9000","title":"precmed 1.0.0.9000","text":"Added NEWS.md file track changes package.","code":""}]
