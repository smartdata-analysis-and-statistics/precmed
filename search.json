[{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"additional-examples-for-the-precmed-package","dir":"Articles","previous_headings":"","what":"Additional examples for the precmed package","title":"Additional examples","text":"precmed can flexible given many arguments user can specify. example described one many ways perform analysis argument values kept default. provide examples show options user creative using precmed.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"load-required-packages","dir":"Articles","previous_headings":"","what":"Load required packages","title":"Additional examples","text":"","code":"library(precmed) library(dplyr) library(ggplot2)"},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"initial-predictor-method","dir":"Articles","previous_headings":"Additional examples with count outcomes","what":"Initial predictor method","title":"Additional examples","text":"choose two regressions contrast regression scoring method, option specify initial outcome regression estimates (\\(\\hat\\mu_r^k\\) \\(r = 0,1\\) treatment \\(k\\) CV fold) calculated. See Theoretical details section background initial predictors used two contrast regressions. list 3 options: generalized linear model, strong assumption Poisson distribution, fast ensemble method, typically tree-based, slow combination generalized linear model additive models linear predictor additive function covariates, can slow main example used Poisson regression can try 2 non-linear flexible options. , use catecvcount() example code can applied catefitcount() well. Note GAM method, additional argument called xvar.smooth. left default (NULL), GAM include independent variables cate.model smooth terms function s() linear predictor. can choose specify subset dependent variables smooth terms. example , specifications cate.model xvar.smooth lead following GAM formula: y ~ female + previous_treatment + previous_number_relapses + s(age) + s(previous_cost), age previous medical costs wrapped smooth function remaining 3 independent variables . Generally speaking, “poisson” initial predictor method fastest “gbm” slowest among 3 methods, “gam” somewhere longer computational time number smooth terms increases.","code":"# An example of using GBM as the initial predictor method catecv(response = \"count\",        data = countExample,        score.method = c(\"poisson\", \"boosting\", \"twoReg\", \"contrastReg\", \"negBin\"),        cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses + offset(log(years)),        ps.model = trt ~ age + previous_treatment,         higher.y = FALSE,        initial.predictor.method = \"boosting\",       # NEW        cv.n = 5,         seed = 999,        plot.gbmperf = FALSE,        verbose = 0)  # An example of using GAM as the initial predictor method catecv(response = \"count\",        data = countExample,        score.method = c(\"poisson\", \"boosting\", \"twoReg\", \"contrastReg\", \"negBin\"),        cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses + offset(log(years)),        ps.model = trt ~ age + previous_treatment,         higher.y = FALSE,         initial.predictor.method = \"gam\",        # NEW        xvar.smooth = c(\"age\", \"previous_cost\"), # NEW        cv.n = 5,        seed = 999,        plot.gbmperf = FALSE,        verbose = 0)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"subgroup-proportion","dir":"Articles","previous_headings":"Additional examples with count outcomes","what":"Subgroup proportion","title":"Additional examples","text":"ATE subgroups validation curve results depend subgroups defined, determined sorted CATE scores. nested binary subgroups (cutoffs specified prop.cutoff) mutually exclusive subgroups (cutoffs specified prop.multi). main example , used default values prop.cutoff prop.multi provided explanations ATE results. recap: prop.cutoff = seq(0.5, 1, length = 6) means 6 sets nested binary subgroups first subgroup splits sample 50/50 according estimated CATE scores (sorted), 2nd subgroup splits sample 60/40, …, 5th subgroup splits sample 90/10, 6th subgroup splits sample 100/0. validation curves show ATE first group split, .e., 50%, 60%, 70%, …, 100%. 6th subgroup technically split keep equivalent overall ATE (gray dashed reference line). functions use prop.cutoff automatically discard 0 supplied 0/100 split make sense 0% subgroup plot validation curves, warning message given. argument higher.y controls direction sorted CATE scores, .e., whether split lowest highest CATE scores. toy example, higher.y = FALSE split lowest CATE scores first group subgroup represents higher responders treatment coded 1. prop.multi = c(0, 1/3, 2/3, 1) means specify 3-category mutually exclusive subgroup, split 33/33/33 according estimated CATE scores. argument higher.y controls direction sorted CATE scores, .e., split lowest highest CATE scores. toy example, higher.y = FALSE split lowest CATE scores. Contrary prop.cutoff, prop.multi must include 0 1 remind us mutual exclusiveness. functions use prop.multi automatically attach 0 /1 supplied warning message given. Now show examples different cutoffs reflected results. new prop.cutoff 11 values opposed 6 original example, number rows ATE results changed accordingly number columns stays still use 5 CV iterations.  validation curves depend prop.cutoff now smoother one presented main example contain 10 subgroups instead 5. ABC statistic affected change prop.cutoff calculation ABC statistics depends minimum maximum prop.cutoff vector always calculated based 100 evenly-spaced cutoffs created range. See theoretical details ABC calculation Theoretical details section.  results mutually exclusive subgroups, number rows ATE results increases 3 4 comparison original example prop.multi now defines 4 mutually exclusive subgroups. method, box plot now 4 boxes 4 mutually exclusive subgroups. Examples recommend next example, prop.cutoff includes 0.01, close 0. Consequently, scoring methods may run convergence issues first subgroup includes small number patients. can lead highly unstable ATE estimates, shown first CV iteration contrast regression output_catecv3$ate.contrastReg$ate.est.valid.high.cv. Moreover, validation curves become useless due extreme ATE estimates.  general recommendations choice prop.cutoff prop.multi: recommend including 0 prop.cutoff invalid value. functions automatically remove 0 prop.cutoff output warning message. recommend choosing values close 0 either generate small subgroups may lead numerical instability, e.g., 1/99 split specified 0.01 example corresponding ATE training data contrast regression. situation, either validation curves dominated unstable ATE estimates, making plot useless example, validation curves plotted numerical instability due extreme split leads missing values, case warning printed example . general, recommend specifying proportions prop.cutoff (e.g., 2 3) validation curves look jagged. validation curves smoother proportions spread range proportions. computation issue, however, choosing many values prop.cutoff prop.multi can time consuming. recommended start smaller length can increase length needed.","code":"# An example of 11 nested binary subgroups and a 4-category mutually exclusive subgroup output_catecv2 <- catecv(response = \"count\",                          data = countExample,                          score.method = c(\"poisson\", \"contrastReg\", \"negBin\"),                          cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses + offset(log(years)),                          ps.model = trt ~ age + previous_treatment,                          higher.y = FALSE,                          prop.cutoff = seq(0.5, 1, length = 11), # NEW                          prop.multi = c(0, 1/4, 2/4, 3/4, 1),    # NEW                          initial.predictor.method = \"poisson\",                           cv.n = 5,                           seed = 999,                          plot.gbmperf = FALSE,                          verbose = 0) #> Warning in prop.multi == c(0, 1): longer object length is not a multiple of #> shorter object length #> Warning in data.preproc(fun = \"crossv\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. print(output_catecv2$ate.contrastReg$ate.est.train.high.cv)  #>                cv1       cv2       cv3       cv4       cv5 #> prop0.5  0.5915071 0.6428854 0.5744973 0.6406698 0.5924975 #> prop0.55 0.6139446 0.6935608 0.6003164 0.6519496 0.6531537 #> prop0.6  0.6722855 0.7114461 0.6591966 0.6871502 0.7186517 #> prop0.65 0.6958967 0.7839030 0.7306405 0.7265152 0.7519433 #> prop0.7  0.7371734 0.8399117 0.7806273 0.7779180 0.7539283 #> prop0.75 0.7795305 0.8320732 0.8003894 0.8266780 0.7999920 #> prop0.8  0.8034239 0.9082507 0.8218952 0.8269917 0.8117300 #> prop0.85 0.8585330 0.9649914 0.8763313 0.8949641 0.8512447 #> prop0.9  0.9027108 1.0257463 0.9595834 0.9049020 0.9452626 #> prop0.95 0.9607169 1.0002418 0.9968210 0.9784077 0.9816699 #> prop1    1.0599740 1.0520675 1.0577453 1.0641114 1.0677619 # Dimension is now 11 rows (nested binary subgroups) by 5 columns (CV iterations) plot(output_catecv2) print(output_catecv2$ate.contrastReg$ate.est.train.group.cv)  #>                cv1       cv2       cv3       cv4       cv5 #> prop0.25 1.8605588 1.7135347 1.8864599 1.6231411 1.8095445 #> prop0.5  1.2881059 1.3353842 1.3960644 1.4225390 1.3873281 #> prop0.75 0.8863431 1.0140060 0.8214955 1.0732422 0.8013989 #> prop1    0.4352059 0.3988016 0.4113767 0.4230607 0.4559544 # Dimension is now 4 rows (multi-category mutually exclusive subgroups) by 5 columns (CV iterations)  boxplot(output_catecv2) # An example of very few nested binary subgroups output_catecv3 <- catecv(response = \"count\",                          data = countExample,                          score.method = c(\"poisson\", \"contrastReg\", \"negBin\"),                          cate.model = y ~ age + female + previous_treatment                                       + previous_cost + previous_number_relapses                                        + offset(log(years)),                          ps.model = trt ~ age + previous_treatment,                           initial.predictor.method = \"poisson\",                           higher.y = FALSE,                          prop.cutoff = c(0, 0.01, 0.30, 0.75, 1), # NEW                          cv.n = 5,                           seed = 999,                          plot.gbmperf = FALSE,                          verbose = 1) #> Warning in data.preproc(fun = \"crossv\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #> Warning in data.preproc(fun = \"crossv\", cate.model = cate.model, ps.model = #> ps.model, : The first element of prop.cutoff cannot be 0 and has been removed. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:17:38 2022  #>    |                                                                               |==============                                                        |  20% #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:17:44 2022  #>    |                                                                               |============================                                          |  40% #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:17:53 2022  #>    |                                                                               |==========================================                            |  60% #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:18:03 2022  #>    |                                                                               |========================================================              |  80% #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:18:14 2022  #>    |                                                                               |======================================================================| 100% #> Total runtime : 48.27 secs output_catecv3$ate.contrastReg$ate.est.valid.high.cv #>                cv1       cv2          cv3          cv4       cv5 #> prop0.01 0.5746485        NA 6.858623e+04 1.901224e+06        NA #> prop0.3  0.6944399 0.6252387 6.104046e-01 5.625166e-01 0.5828618 #> prop0.75 1.1424118 0.8042944 8.929894e-01 7.984435e-01 0.8409132 #> prop1    1.0812603 1.0978549 1.053193e+00 1.072635e+00 1.0689638 plot(output_catecv3)"},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"initial-predictor-method-1","dir":"Articles","previous_headings":"Additional examples for survival outcomes","what":"Initial predictor method","title":"Additional examples","text":"choose two /contrast regression scoring method, option specify initial outcome regression estimates (\\(\\hat\\mu_r^k\\) \\(r = 0,1\\) treatment \\(k\\) cross validation fold) calculated. See Theoretical details section background initial predictors used two contrast regression. list 3 options: generalized linear model, strong assumption binomial distribution, fast ensemble method, typically tree-based, assume time--event outcome Gaussian distributed, slow ensemble method, tree-based, non-parametric, can slow main example used logistic regression can try 2 non-linear flexible options. , use catecv() example code can applied catefit() well. Note boosting randomForest methods tree-based, parameters tree depth number trees can specified arguments tree.depth, n.trees.rf, n.trees.boosting. Generally speaking, “logistic” initial predictor method fastest “boosting” slowest among 3 methods, “randomForest” somewhere longer computational time number trees tree depth increase.","code":"# An example of using GBM as the initial predictor method tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  catecv(response = \"survival\",        data = survivalExample,        score.method = c(\"poisson\", \"boosting\", \"randomForest\", \"twoReg\", \"contrastReg\"),        cate.model = survival::Surv(y, d) ~ age + female + previous_cost + previous_number_relapses,        ps.model = trt ~ age + previous_treatment,        ipcw.model = NULL,        followup.time = NULL,        tau0 = tau0,        surv.min = 0.025,        higher.y = TRUE,        prop.cutoff = seq(0.6, 1, length = 5),        prop.multi = c(0, 0.5, 0.6, 1),        cv.n = 5,        initial.predictor.method = \"boosting\", # NEW        tree.depth = 3,                        # NEW        seed = 999,        plot.gbmperf = FALSE,        verbose = 0)  # An example of using random forest as the initial predictor method catecv(response = \"survival\",        data = survivalExample,        score.method = c(\"poisson\", \"boosting\", \"randomForest\", \"twoReg\", \"contrastReg\"),        cate.model = survival::Surv(y, d) ~ age + female + previous_cost + previous_number_relapses,        ps.model = trt ~ age + previous_treatment,        ipcw.model = NULL,        followup.time = NULL,        tau0 = tau0,        surv.min = 0.025,        higher.y = TRUE,        prop.cutoff = seq(0.6, 1, length = 5),        prop.multi = c(0, 0.5, 0.6, 1),        cv.n = 5,        initial.predictor.method = \"randomForest\", # NEW        n.trees.rf = 500,                          # NEW        seed = 999,        plot.gbmperf = FALSE,        verbose = 0)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"subgroup-proportion-1","dir":"Articles","previous_headings":"Additional examples for survival outcomes","what":"Subgroup proportion","title":"Additional examples","text":"precmed results depend subgroups determined sorted CATE scores. nested binary subgroups (cutoffs specified prop.cutoff) mutually exclusive subgroups (cutoffs specified prop.multi). main example , used certain values prop.cutoff prop.multi provided explanations ATE results. recap: prop.cutoff = seq(0.6, 1, length = 5) means 5 sets nested binary subgroups first subgroup set split 60/40 according estimated CATE scores (sorted), 2nd subgroup set split 70/30, …, 6th subgroup set split 100/0. validation curves show results first group split, .e., 60%, 70%, …, 100%. 5th subgroup set technically split keep equivalent overall ATE (gray dashed reference line). precmed automatically discard 0 supplied 0/100 split make sense 0% subgroup plot validation curves, warning message given. Argument higher.y controls direction sorted CATE scores, .e., whether split lowest highest CATE scores. toy example, higher.y = TRUE split lowest CATE scores. prop.multi = c(0, 0.5, 0.6, 1) means specify 3-category mutually exclusive subgroup, split 50/10/40 according estimated CATE scores. Argument higher.y controls direction sorted CATE scores, .e., split lowest highest CATE scores. toy example, higher.y = TRUE split lowest CATE scores. Contrary prop.cutoff, prop.multi must include 0 1 remind us mutual exclusiveness. precmed automatically attach 0 /1 supplied warning message given. Now show examples different cutoffs reflected results. new prop.cutoff 9 values opposed 5 original example, number rows ATE results changed accordingly number columns remains 5.  validation curves depend prop.cutoff line segments one presented main example contain 9 sets subgroups instead 5 sets (although obvious example). ABC statistic affected calculation ABC statistics depends minimum maximum prop.cutoff vector 100 evenly-spaced subgroup cutoffs created range. highest proportion cutoff 1 main example 0.9 now 0.95. See theoretical details ABC calculation Theoretical details section.  results mutually exclusive subgroups, number rows ATE results increases 3 4 comparison original example prop.multi now defines 4 mutually exclusive subgroups. methods, box plot now 4 boxes 4 mutually exclusive subgroups. Examples recommend example, prop.cutoff includes 0.01, close 0. Consequently, scoring methods may run convergence issues first subgroup includes small number patients. can lead highly unstable ATE estimates, shown first CV iteration contrast regression output_catecv3$ate.contrastReg$ate.est.valid.high.cv. Moreover, validation curves become useless due extreme ATE estimates.  general recommendations choice prop.cutoff prop.multi: recommend including 0 prop.cutoff invalid value. precmed automatically removes 0 prop.cutoff outputs warning message. recommend choosing values close 0 either generate small subgroups may lead numerical instability, e.g., 10/90 split specified 0.1 example. situation, either validation curves plotted range unstable ATE estimates make useless validation curves plotted numerical instability due extreme split leads missing infinite values, case warning error printed example . general, recommend specifying proportions prop.cutoff (e.g., 2 3) validation curves look jagged. validation curves smoother proportions spread range proportions. computation issue, however, choosing many values prop.cutoff prop.multi can time consuming. recommended start smaller length can increase length needed.","code":"# An example of 9 nested binary subgroups and a 4-category mutually exclusive subgroup tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  output_catecv2 <- catecv(response = \"survival\",                          data = survivalExample,                          score.method = c(\"randomForest\", \"contrastReg\"),                                           cate.model = survival::Surv(y, d) ~ age + female                                                         + previous_cost + previous_number_relapses,                 ps.model = trt ~ age + previous_treatment,                 initial.predictor.method = \"logistic\",                 ipcw.model = NULL,                 followup.time = NULL,                 tau0 = tau0,                 surv.min = 0.025,                 higher.y = TRUE,                 prop.cutoff = seq(0.6, 1, length = 9), # NEW                 prop.multi = c(0, 0.4, 0.5, 0.6, 1),   # NEW                 cv.n = 5,                 seed = 999,                 plot.gbmperf = FALSE,                 verbose = 0) #> Warning in prop.multi == c(0, 1): longer object length is not a multiple of #> shorter object length #> Warning in data.preproc.surv(fun = \"crossv\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. print(output_catecv2$ate.contrastReg$ate.est.train.high.cv)  #>                cv1       cv2       cv3       cv4       cv5 #> prop0.6  0.5286488 0.5344877 0.5325352 0.5246205 0.5338395 #> prop0.65 0.5791944 0.5829187 0.6151744 0.5762170 0.5955160 #> prop0.7  0.6168472 0.6682790 0.6440506 0.6333903 0.6438643 #> prop0.75 0.7017728 0.7330868 0.7038570 0.6943269 0.7105475 #> prop0.8  0.7696228 0.8005505 0.7752939 0.7763984 0.7873444 #> prop0.85 0.8374886 0.8700290 0.8403268 0.8512221 0.8544261 #> prop0.9  0.9110024 0.9351850 0.9030097 0.9108305 0.9137251 #> prop0.95 0.9951218 1.0190440 0.9862585 0.9967722 0.9920313 #> prop1    1.0534514 1.1042633 1.0646558 1.0830122 1.0690691 # Dimension is 9 (nested binary subgroups) by 5 (CV iterations) plot(output_catecv2) print(output_catecv2$ate.contrastReg$ate.est.train.group.cv)  #>               cv1       cv2       cv3       cv4      cv5 #> prop0.4 6.2068924 6.6101517 6.7424201 6.5030289 7.027033 #> prop0.5 1.4458427 1.4142659 1.4728371 1.4372399 1.381593 #> prop0.6 0.9080483 1.2062367 1.0115264 0.9270653 1.259874 #> prop1   0.3746892 0.4068091 0.3454113 0.3465889 0.377679 # Dimension is now 4 (multi-category mutually exclusive subgroups) by 3 (CV iterations)  boxplot(output_catecv2) #> Warning: Removed 4 rows containing non-finite values (`stat_boxplot()`). # An example of very few nested binary subgroups output_catecv3 <- catecv(response = \"survival\",                          data = survivalExample,                          score.method = c(\"contrastReg\"),                          cate.model = survival::Surv(y, d) ~ age + female + previous_cost + previous_number_relapses,                          ps.model = trt ~ age + previous_treatment,                          initial.predictor.method = \"logistic\",                          ipcw.model = NULL,                          followup.time = NULL,                          tau0 = tau0,                          surv.min = 0.025,                          higher.y = TRUE,                          prop.cutoff = c(0, 0.1, 0.75, 1), # NEW                          prop.multi = c(0, 0.5, 0.6, 1),                          cv.n = 5,                          seed = 999,                          plot.gbmperf = FALSE,                          verbose = 1) #> Warning in data.preproc.surv(fun = \"crossv\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #> Warning in data.preproc.surv(fun = \"crossv\", cate.model = cate.model, ps.model = #> ps.model, : The first element of prop.cutoff cannot be 0 and has been removed. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:21:11 2022  #>    |                                                                               |==============                                                        |  20% #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:21:19 2022  #>    |                                                                               |============================                                          |  40% #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:21:27 2022  #>    |                                                                               |==========================================                            |  60% #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:21:35 2022  #>    |                                                                               |========================================================              |  80% #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:21:43 2022  #>    |                                                                               |======================================================================| 100% #> Total runtime : 39.95 secs output_catecv3$ate.contrastReg$ate.est.valid.high.cv #>                cv1       cv2       cv3       cv4       cv5 #> prop0.1         NA        NA        NA        NA        NA #> prop0.75 0.7251659 0.5735622 0.9376515 0.6359857 0.7093587 #> prop1    1.1465914 1.0179736 1.1351233 1.0311785 1.1141329 plot(output_catecv3)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"ipcw-model-and-method","dir":"Articles","previous_headings":"Additional examples for survival outcomes","what":"IPCW model and method","title":"Additional examples","text":"default IPCW model uses covariates outcome model cate.model plus treatment. default IPCW method Cox regression Breslow estimator baseline survivor function coxph() function survival package. Different variables different method can specified IPCW model. example , changed covariates number symptoms number relapses pre-index period specified Weibull accelerated failure time (AFT) regression model using location-scale parameterization. survreg() function survival package used fit AFT model.","code":"# An example of a different IPCW model with different covariates from default output_catecv4 <- catecv(response = \"survival\",                          data = survivalExample,                          score.method = c(\"poisson\", \"contrastReg\"),                          cate.model = survival::Surv(y, d) ~ age + female + previous_cost + previous_number_relapses,                          ps.model = trt ~ age + previous_treatment,                          initial.predictor.method = \"logistic\",                          ipcw.model = ~ previous_number_symptoms + previous_number_relapses, # NEW                          ipcw.method = \"aft (weibull)\", # NEW                          followup.time = NULL,                          tau0 = tau0,                          surv.min = 0.025,                          higher.y = TRUE,                          prop.cutoff = seq(0.6, 1, length = 5),                           prop.multi = c(0, 0.5, 0.6, 1),                          cv.n = 5,                          seed = 999,                          plot.gbmperf = FALSE,                          verbose = 0)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"truncation-and-follow-up-time","dir":"Articles","previous_headings":"Additional examples for survival outcomes","what":"Truncation and follow-up time","title":"Additional examples","text":"argument tau0 specifies truncation time RMTL. default maximum survival time data can changed specific truncation time mind. Similarly, maximum follow-time argument followup.time can changed default, unknown potential censoring time. study setup usually can shed light values use two time parameters. main example, used minimum 95th percentile survival time either treatment group tau0. show setting different values truncation time.","code":"# An example of a different IPCW model with different covariates from default output_catecv5 <- catecv(response = \"survival\",                          data = survivalExample,                          score.method = c(\"poisson\", \"contrastReg\"),                          cate.model = survival::Surv(y, d) ~ age + female + previous_cost + previous_number_relapses,                          ps.model = trt ~ age + previous_treatment,                          initial.predictor.method = \"logistic\",                          ipcw.model = ~ previous_number_symptoms + previous_number_relapses,                          ipcw.method = \"aft (weibull)\",                          followup.time = NULL,                          tau0 = NULL, # NEW                          higher.y = TRUE,                          cv.n = 5,                          surv.min = 0.025,                          prop.cutoff = seq(0.6, 1, length = 5),                          prop.multi = c(0, 0.5, 0.6, 1),                          seed = 999,                          plot.gbmperf = FALSE,                          verbose = 0) #> Warning in data.preproc.surv(fun = \"crossv\", cate.model = cate.model, ps.model #> = ps.model, : No value supplied for tau0. Default sets tau0 to the maximum #> survival time. #> Warning in data.preproc.surv(fun = \"crossv\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. plot(output_catecv5)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Additional-examples.html","id":"other-precmed-vignettes-in-this-serie","dir":"Articles","previous_headings":"","what":"Other precmed vignettes in this serie","title":"Additional examples","text":"1. Examples count outcome2. Examples survival outcome3. Additional examples4. Theoretical details","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"load-required-packages","dir":"Articles","previous_headings":"Applying precmed to count outcome data","what":"Load required packages","title":"Examples for count outcome","text":"","code":"library(precmed) library(dplyr) library(ggplot2)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"example-dataset","dir":"Articles","previous_headings":"Applying precmed to count outcome data","what":"Example dataset","title":"Examples for count outcome","text":"consider simulated dataset based real-world claims data patients multiple sclerosis. dataset countExample includes 4,000 patients information following 9 variables. variables baseline patient characteristics like age, gender, previous treatment. use y count outcome variable, number relapses follow-. use years offset variable, number years follow-. use trt treatment variable, 2 drugs (drug0 drug1). avoid multicollinearity issues, continuous variable age centered 48 years old medical costs year prior treatment initiation previous_cost centered 13,824 USD scaled standard deviation 20,172 USD. final dataset countExample looked like :","code":"#> 'data.frame':    4000 obs. of  9 variables: #>  $ age                     : num [1:4000, 1] -21.22 -2.22 -10.22 6.78 4.78 ... #>   ..- attr(*, \"scaled:center\")= num 46.2 #>  $ female                  : int  0 1 1 0 1 0 1 0 1 1 ... #>  $ previous_treatment      : Factor w/ 3 levels \"drugA\",\"drugB\",..: 1 1 1 1 3 3 3 3 3 1 ... #>  $ previous_cost           : num [1:4000, 1] 0.451 -0.194 -0.534 -0.337 -0.271 ... #>   ..- attr(*, \"scaled:center\")= num 13824 #>   ..- attr(*, \"scaled:scale\")= num 20172 #>  $ previous_number_symptoms: Factor w/ 3 levels \"0\",\"1\",\">=2\": 2 2 2 2 2 2 2 3 2 1 ... #>  $ previous_number_relapses: int  0 0 1 1 0 0 0 0 1 1 ... #>  $ trt                     : Factor w/ 2 levels \"drug0\",\"drug1\": 2 1 1 2 2 1 2 2 2 2 ... #>  $ y                       : int  0 0 0 0 1 0 0 0 0 0 ... #>  $ years                   : num  0.2847 0.6105 2.653 0.0383 2.2697 ..."},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"estimation-of-the-ate-with-atefit","dir":"Articles","previous_headings":"Applying precmed to count outcome data","what":"Estimation of the ATE with atefit()","title":"Examples for count outcome","text":"First, one might interested effect drug (trt) number relapses follow-(y). Lets test using simple regression. see simple linear model drug 1 scores 0.02 points higher compared drug 0. indicates drug 0 superior drug 1 lower outcomes preferred (number relapses). Now want estimate Average Treatment Effect (ATE) correct several covariates like age previous treatment might influence relation treatment outcome. atefit() function allows estimating ATE terms rate ratio. rate ratio estimator doubly robust, meaning estimator consistent propensity score (PS) model (argument ps.model) outcome model (argument cate.model) correctly specified. function also provides standard error, confidence intervals, p-values based bootstrap. mandatory arguments atefit() : response: “count” example use data count outcome (e.g., number relapses)) data: name data set. (countExample) cate.model: formula describing outcome model fitted. outcome must appear left-hand side. example, choose specify outcome model linear combination following covariates: age, sex, previous treatment, medical costs year prior treatment initiation, number relapses year prior treatment initiation. Non-linear interaction terms also included. outcome model offset log(years) account varying exposure times across patients. Note treatment variable supplied cate.model since outcome model. ps.model: formula describing propensity score (PS) model fitted. treatment must appear left-hand side covariates (age previous treatment example) right-hand side. variable trt must supplied numeric variable taking 2 values, 1 active treatment 0 control comparator. case, function stop error trt takes 2 distinct values automatically transform trt numeric variable. example, trt (factor variable taking values “drug0” “drug1”) transformed warning message left user (see output ): Variable trt recoded 0/1 drug0->0 drug1->1. data RCT, suffices specify ps.model = trt ~ 1. Note PS model used estimation 2 doubly robust methods (two contrast regressions). Let’s calculate ATE effect treatment y build outcome model contains variables PS model age previous_treatment. verbose = 1, function outputs progress bar console. output atefit() shows point estimate, standard error (“SE”), lower (“CI.lower”) upper (“CI.upper”) bound 95% confidence interval, p-value (“pvalue”) log rate ratio ($log.rate.ratio) well point estimate rate 2 treatment groups ($rate0 $rate1). example, log rate ratio 0.06 95% confidence interval (-0.26, 0.38) displayed output. user can retrieve rate ratio facilitate interpretation: rate ratio 1.07 along 95% confidence interval (0.48, 2.35) suggest drug 0 superior drug 1 ratio greater 1 lower outcomes preferred, superiority statistically significant given p-value 0.7 output ($log.rate.ratio$pvalue). Using plot(output_atefit), histograms generated point estimates across n.boot bootstrap iterations log rate ratio. red vertical line added histogram mean bootstrap estimates.  Histograms bootstrap log rate ratio estimators 500 bootstrap iterations.","code":"output_lm <- lm(y ~ trt, countExample) output_lm #>  #> Call: #> lm(formula = y ~ trt, data = countExample) #>  #> Coefficients: #> (Intercept)     trtdrug1   #>     0.32665      0.02045 output_atefit <- atefit(response = \"count\",                         data = countExample,                         cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses + offset(log(years)),                         ps.model = trt ~ age + previous_treatment,                         n.boot = 50,                          seed = 999,                         verbose = 0) #> Warning in data.preproc(fun = \"drinf\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. output_atefit #> Average treatment effect: #>  #>                  estimate        SE   CI.lower  CI.upper    pvalue #> log.rate.ratio 0.06311746 0.1624482 -0.2552752 0.3815101 0.6976173 #>  #> Estimated event rates: #>  #>        estimate #> rate1 0.2860635 #> rate0 0.2685660 #> Warning in print.atefit(x): Variable trt was recoded to 0/1 with drug0->0 and drug1->1. rate.ratio <- exp(output_atefit$log.rate.ratio$estimate) rate.ratio #> [1] 1.065152 CI.rate.ratio <- exp(output_atefit$log.rate.ratio$estimate + c(-1, 1) * qnorm(0.975) * sqrt(output_atefit$log.rate.ratio$SE)) CI.rate.ratio #> [1] 0.4834326 2.3468602"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"estimation-of-the-cate-score-with-catefit","dir":"Articles","previous_headings":"Applying precmed to count outcome data","what":"Estimation of the CATE score with catefit()","title":"Examples for count outcome","text":"Now calculated ATE know effect treatments average, effect might patients. Thus, might worthwhile check subgroups respond differently treatments. can calculate Conditional Average Treatment Effect (CATE) score calculates ATE different subgroups data. internal validation needed (get back later), can use catefit() function model directly entire data set estimate CATE score. catefit() function define score.method. arguments specifies precision medicine (PM) method used calculate CATE scores. total 5 scoring methods implemented: poisson fits Poisson model separately treatment group. boosting uses gradient boosted regression models (GBM) separately treatment group. twoReg implements doubly robust two regressions estimator @yadlowsky2020estimation. contrastReg implements doubly robust contrast regression estimator @yadlowsky2020estimation. negBin fits negative binomial regressions treatment group. method recommended overdispersion data. selected PS method fits data (multiple methods), can run catefit() function variables atefit() function. mandatory arguments : response, data, score.method, cate.model, ps.model. user can also specify non-mandatory arguments fit data problem hand. Please see Function description section details. run errors warnings data, might helpful go descriptions see need alter default values. toy example, keep default values remaining arguments. method specified score.method following sets results catefit(): score contains log-transformed estimated CATE scores subject. CATE score linear combination variables specified cate.model argument. outcome, lower CATE scores desirable higher.y = FALSE vice versa. subject one CATE score length output 4,000 toy example. show CATE scores estimated contrast regression first 6 subjects data. coefficients contains estimated coefficients CATE score scoring method. data frame covariates (including intercept) rows scoring methods columns. toy example, 5 covariates cate.model (including categorical variable 3 distinct factors) 7 rows estimated coefficients within column. Since contrast regression one scoring methods specified example, see contrast regression additional column standard errors estimated coefficients. Boosting estimate coefficients (directly predicts score) coefficient result method. can define estimated CATE scores contrast regression like shown . user can use information study influence covariate. \\[ \\begin{aligned} \\widehat{CATE} = -0.60 & - 0.04 \\times \\text{age} \\\\ & + 0.77 \\times \\text{female (vs male)} \\\\ & + 0.75 \\times \\text{previous treatment drug B (vs drug )} \\\\ & - 0.21 \\times \\text{previous treatment drug C (vs drug )} \\\\ & - 0.02 \\times \\text{previous medical costs} \\\\ & + 0.04 \\times \\text{previous number relapses} \\end{aligned} \\] ate contains estimated ATEs nested subgroup high responders drug 1 defined prop.cutoff. subgroups defined based estimated CATE scores specified scoring method. example, show estimated ATEs subgroups identified CATE scores contrast regression. example, estimated ATE subgroup subjects constructed based 50% (“prop0.5”) lowest CATE scores estimated contrast regression 0.62. encouraged summarize visualize outputs whichever way fits particular situation outside package’s functions. example, possible plot densities CATE scores ggplot(). subjects extremely low CATE scores samples fall -1 1 triple modes around -0.5, 0, 0.8.","code":"t0 <- Sys.time() output_catefit <- catefit(response = \"count\",                           data = countExample,                           score.method = c(\"poisson\", \"boosting\", \"twoReg\", \"contrastReg\", \"negBin\"),                           cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses + offset(log(years)),                           ps.model = trt ~ age + previous_treatment,                           initial.predictor.method = \"poisson\",                           higher.y = FALSE,                            seed = 999) #> Warning in data.preproc(fun = \"catefit\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. t1 <- Sys.time() t1 - t0 #> Time difference of 16.83866 secs length(output_catefit$score.contrastReg) #> [1] 4000 head(output_catefit$score.contrastReg) #> [1]  0.1499685  0.2620096  0.5860160 -0.8024144 -0.1906713 -0.4043656 output_catefit$coefficients #>                              poisson      twoReg contrastReg SE_contrastReg #> (Intercept)              -0.58185218 -0.57207204 -0.59736822     0.37228114 #> age                      -0.01117701 -0.04008509 -0.03578803     0.01382166 #> female                    0.58829733  0.73775319  0.77478198     0.36574103 #> previous_treatmentdrugB   0.73724361  0.64060449  0.74664939     0.35878718 #> previous_treatmentdrugC   0.15545985 -0.25803279 -0.20421285     0.26463665 #> previous_cost            -0.13035642 -0.08485511 -0.02671264     0.15747560 #> previous_number_relapses -0.05339112  0.06098503  0.02863769     0.16914400 #>                               negBin #> (Intercept)              -0.59232437 #> age                      -0.01410487 #> female                    0.59602219 #> previous_treatmentdrugB   0.76032497 #> previous_treatmentdrugC   0.13262969 #> previous_cost            -0.13952096 #> previous_number_relapses -0.05034136 output_catefit$ate.contrastReg #>   prop0.5   prop0.6   prop0.7   prop0.8   prop0.9     prop1  #> 0.6233165 0.6624837 0.7904911 0.8451963 0.9372587 1.0640579 dataplot <- data.frame(score = factor(rep(c(\"Boosting\", \"Naive Poisson\", \"Two regressions\", \"Contrast regression\", \"Negative Binomial\"), each = length(output_catefit$score.boosting))),                         value = c(output_catefit$score.boosting, output_catefit$score.poisson, output_catefit$score.twoReg, output_catefit$score.contrastReg, output_catefit$score.negBin))  dataplot %>%    ggplot(aes(x = value, fill = score)) +    geom_density(alpha = 0.5) +   theme_classic() +    labs(x = \"Estimated CATE score\", y = \"Density\", fill = \"Method\")"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"internal-validation-via-catecv","dir":"Articles","previous_headings":"Applying precmed to count outcome data","what":"Internal validation via catecv()","title":"Examples for count outcome","text":"catecv() function provides estimation catefit() via cross-validation (CV). catecv() function internal CV applied reduce optimism choosing CATE estimation method captures treatment effect heterogeneity. CV applied repeating following steps cv.n times: Split data training validation set according train.prop argument. training validation sets must balanced respect covariate distributions doubly robust rate ratio estimates (see error.max argument). Estimate CATE score training set specified scoring method. Predict CATE score validation set using scoring model fitted training set. Build nested subgroups treatment responders training validation sets, separately, estimate ATE within nested subgroup. element prop.cutoff argument (e.g., prop.cutoff[] = 0.6), take following steps: Identify high responders observations 60% (.e., prop.cutoff[]x100%) highest (higher.y = TRUE) lowest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup high responders using doubly robust estimator. Conversely, identify low responders observations 40% (.e., 1 - prop.cutoff[]x100%) lowest (higher.y = TRUE) highest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup low responders using doubly robust estimator. abc = TRUE, calculate area ATE series ATEs nested subgroups high responders validation set. (information abc score, see Validation curves ABC statistics) Build mutually exclusive subgroups treatment responders training validation sets, separately, estimate ATE within subgroup. Mutually exclusive subgroups built splitting estimated CATE scores according prop.multi. Oke, now can use catecv() function run internal validation compare different scoring methods. mandatory arguments similar atefit() catefit(): mandatory arguments : response, data, score.method, cate.model, ps.model. toy example selected poisson, contrastReg negBin limit run time. also specified following non-mandatory arguments fit data problem hand: initial.predictor.method, higher.y, cv.n, seed, plot.gbmperf verbose. initial.predictor.method specifies predictions outcome estimated two regressions contrast regression. Flexible models can used GBM (“boosting”) generalized additive models (“gam”). methods computationally intensive choose “poisson” obtain predictions Poisson regression, reduces computational time expense stricter parametric assumptions less flexibility. higher.y set FALSE lower number relapses desirable example. Hence, telling function subgroups high responders drug1 vs drug0 lower number relapses (see section Validation curves ABC statistics illustration). situation, higher outcomes may favorable, example, walking steps study physical activity. important argument match y outcome affect subgroups defined CATE scores performance metrics. perform 5 CV iterations specifying cv.n = 5. Typically, CV iterations desirable although associated longer computational times. set random seed seed = 999 reproduce results. avoid generating boosting performance plots specifying plot.gbmperf = FALSE. verbose = 1, progress messages printed R console errors warnings printed. current CV iteration printed, followed steps CV procedure (splitting data, training models, validating models) warnings errors occurred steps (none example). timestamp progress bar also displayed upon completion CV iteration. contrastReg selected one methods score.method, additional line output message indicate whether algorithm converged. many non-mandatory arguments catecv() can accept. Please see Additional examples vignette examples Function description section details. run errors warnings data, might helpful go descriptions see need alter default values. toy example, keep default values remaining arguments. output catecv() object class “precmed” named output_catecv. carries relevant information use next step workflow selects method (among specified argument score.method) capturing highest level treatment effect heterogeneity. output, described , used functions abc(), plot() boxplot(). method specified argument score.method, following 3 groups outputs generated: high, low group. use results contrastReg example. 1. ATEs nested subgroups high responders output stores ATEs - ratio annualized relapse rate drug1 vs drug0 example - nested subgroups patients high responders drug 1 training ($ate.est.train.high.cv) validation ($ate.est.valid.high.cv) sets across CV iterations. count outcomes, higher.y = TRUE, higher CATE scores correspond high responders drug1. higher.y = FALSE, lower CATE scores correspond high responders drug1. Note different survival outcomes. direction CATE scores depends higher.y outcome type. output matrix columns corresponding CV iterations, labeled 1 cv.n, rows corresponding nested subgroups. nested subgroups patients defined argument prop.cutoff. , use default seq(0.5, 1, length = 6) defines 6 nested subgroups 50%, 60%, 70%, 80%, 90% 100% lowest (highest higher.y = TRUE) CATE scores estimated contrast regression. rows output labeled reflect user-specified proportions used build subgroups. example, training set first CV iterations (first column labeled “cv1”), subgroup defined 50% lowest CATE scores (first row labeled “prop0.5”) estimated RR 0.592. contrast, subgroup defined patients (last row labeled “prop1”) estimated RR 1.06. 2. ATEs nested subgroups low responders output stores ATEs nested subgroups low responders drug1 training ($ate.est.train.low.cv) validation ($ate.est.valid.low.cv) sets across CV iterations. count outcomes, higher.y = TRUE, lower CATE scores correspond low responders drug1. higher.y = FALSE, higher CATE scores correspond low responders drug1. , different survival outcomes. direction CATE scores depends higher.y outcome type. outputs also matrices columns corresponding CV iterations rows corresponding nested subgroups. output low responders brings additional information user. gives ATEs complement nested subgroup high responders. example, complement subgroup high responders defined patients 60% lowest (highest higher.y = TRUE) estimated CATE scores subgroup low responders defined patients 40% highest (lowest higher.y = TRUE) estimated CATE scores, labeled “prop0.4”. training set first CV iterations, estimated RR 0.672 60% high responders drug 1 1.716 40% low responders. 3. ATEs mutually exclusive subgroups output stores ATEs mutually exclusive multi-category subgroups patients training ($ate.est.train.group.cv) validation ($ate.est.valid.group.cv) sets across CV iterations. output matrix columns corresponding CV iterations rows corresponding mutually exclusive subgroups. previous 2 outputs focus binary subgroups (high low responders). , mutually exclusive subgroups can 2 defined argument prop.multi. use default c(0, 1/3, 2/3, 1) defines 3 subgroups patients 33% lowest, 33% middle 33% highest estimated CATE scores higher.y = FALSE (example), 33% highest, 33% middle 33% lowest estimated CATE scores higher.y = FALSE. Taking first column example, first CV iteration calculated 1.864 RR subgroup 33% lowest estimated CATE scores, 1.063 RR subgroup 33% middle estimated CATE scores, 0.487 RR subgroup 33% highest estimated CATE scores.","code":"output_catecv <- catecv(response = \"count\",                         data = countExample,                         score.method = c(\"poisson\", \"contrastReg\", \"negBin\"),                         cate.model = y ~ age + female + previous_treatment + previous_cost + previous_number_relapses + offset(log(years)),                         ps.model = trt ~ age + previous_treatment,                          initial.predictor.method = \"poisson\",                         higher.y = FALSE,                         cv.n = 5,                          seed = 999,                         plot.gbmperf = FALSE,                         verbose = 1) #> Warning in data.preproc(fun = \"crossv\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:23:34 2022  #>    |                                                                               |==============                                                        |  20% #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:23:41 2022  #>    |                                                                               |============================                                          |  40% #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:23:52 2022  #>    |                                                                               |==========================================                            |  60% #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:24:03 2022  #>    |                                                                               |========================================================              |  80% #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>   convergence TRUE  #>    Mon Dec 12 15:24:14 2022  #>    |                                                                               |======================================================================| 100% #> Total runtime : 53.82 secs output_catecv$ate.contrastReg$ate.est.train.high.cv #>               cv1       cv2       cv3       cv4       cv5 #> prop0.5 0.5915071 0.6428854 0.5744973 0.6406698 0.5924975 #> prop0.6 0.6722855 0.7114461 0.6591966 0.6871502 0.7186517 #> prop0.7 0.7371734 0.8399117 0.7806273 0.7779180 0.7539283 #> prop0.8 0.8034239 0.9082507 0.8218952 0.8269917 0.8117300 #> prop0.9 0.9027108 1.0257463 0.9595834 0.9049020 0.9452626 #> prop1   1.0599740 1.0520675 1.0577453 1.0641114 1.0677619 output_catecv$ate.contrastReg$ate.est.valid.high.cv #>               cv1       cv2       cv3       cv4       cv5 #> prop0.5 0.7448829 0.6271739 0.8552290 0.5565145 0.5514821 #> prop0.6 0.7404875 0.7224230 0.8308576 0.5906053 0.6909427 #> prop0.7 0.9166009 0.7876447 0.8468713 0.8076085 0.7944857 #> prop0.8 1.1280003 0.8535919 0.9563156 0.9041068 0.8734434 #> prop0.9 1.1300157 0.8417894 0.9364762 0.9264986 0.9791587 #> prop1   1.0812603 1.0978549 1.0531927 1.0726353 1.0689638 output_catecv$ate.contrastReg$ate.est.train.low.cv #>              cv1      cv2      cv3      cv4      cv5 #> prop0.5 1.616081 1.556901 1.657101 1.542445 1.623386 #> prop0.4 1.715570 1.575580 1.727447 1.615714 1.594635 #> prop0.3 1.865026 1.529785 1.629855 1.648721 1.737306 #> prop0.2 1.919854 1.572316 1.963560 1.845068 2.122016 #> prop0.1 2.093288 1.254235 1.522567 2.118723 2.074404 output_catecv$ate.contrastReg$ate.est.train.group.cv #>                cv1      cv2       cv3       cv4       cv5 #> prop0.33 1.8635694 1.487886 1.7151928 1.6904282 1.6561713 #> prop0.67 1.0633686 1.502770 1.0504965 1.1763982 1.0960883 #> prop1    0.4867885 0.470482 0.4762452 0.4816721 0.5361898 output_catecv$ate.contrastReg$ate.est.valid.group.cv #>                cv1       cv2       cv3       cv4       cv5 #> prop0.33 1.4220392 1.9876476 1.3647971 1.6091552 1.9901237 #> prop0.67 0.7328152 0.7720613 1.0883491 0.9727634 0.9083542 #> prop1    0.8122051 0.6583514 0.6702625 0.5232875 0.6028634"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"comparison-of-methods-with-abc","dir":"Articles","previous_headings":"Applying precmed to count outcome data","what":"Comparison of methods with abc()","title":"Examples for count outcome","text":"ABC statistics calculated abc() scoring method specified catecv() cv.n CV iterations using output object output_catecv catecv(). ABC corresponds area curve formed ATEs subgroups high responders validation set (e.g., output_catecv$ate.contrastReg$ate.est.valid.cv contrast regression) horizontal line representing ATE validation set. higher ABC value means method captures treatment effect heterogeneity. See Validation curves ABC statistics section detailed illustration relationship higher.y, abc, validation curves. output matrix columns corresponding CV iterations rows corresponding scoring methods specified score.method. example, CV iteration 1, negative binomial (“negBin”) ABC 0.145, highest CV iteration, meaning negative binomial offers best performance first CV iteration. user can combine ABC method across iterations: example, negative binomial also offers best overall performance highest average ABC, followed closely Poisson.","code":"output_abc <- abc(x = output_catecv) output_abc #>                    cv1       cv2        cv3        cv4       cv5 #> poisson     0.13758995 0.2236276 0.06938081 0.09647510 0.1304204 #> contrastReg 0.07300565 0.1605130 0.06858134 0.14825053 0.1309099 #> negBin      0.14517127 0.2203584 0.08899030 0.09382214 0.1395976 average_abc <- apply(output_abc, 1, mean) average_abc #>     poisson contrastReg      negBin  #>   0.1314988   0.1162521   0.1375879"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"visualization-of-the-validation-curves-with-plot","dir":"Articles","previous_headings":"Applying precmed to count outcome data","what":"Visualization of the validation curves with plot()","title":"Examples for count outcome","text":"ATEs nested subgroups high responders drug1 (e.g., output_catecv$ate.contrastReg$ate.est.train.high.cv output_catecv$ate.contrastReg$ate.est.valid.high.cv contrast regression) can visualized side--side line plot, training results left validation results right. x-axis determined prop.cutoff y-axis estimated ATEs averaged cv.n CV iterations specified cv.= NULL. estimated ATE expressed RR drug1 versus drug0 toy example. default, function retrieves name treatment variable (trt) original labels (drug0 drug1) specify meaningful y-axis label. Otherwise, possible customize y-axis label via ylab, example, using Rate ratio drug1 vs drug0 subgroup. Steeper slopes indicate treatment effect heterogeneity drug1 drug0. higher.y = FALSE example, slopes increasing left (prop.cutoff = 0.5) right (prop.cutoff = 1) treatment effect heterogeneity present. method steepest slope validation results selected captures treatment effect heterogeneity generalizing well unseen data.  toy example, methods performing well training data per steep, increasing slopes left plot. Moreover, methods generalize well validation data, indicated monotonous increasing curves validation data (right plot). dashed gray line ATE entire data set, lines merge reference line subgroup size 100% data (prop.cutoff = 1). explanation validation curves, see Function description section. plot’s legend includes ABC statistics validation set. user can choose mute ABC annotations specifying show.abc = FALSE.  user can choose plot validation curves one CV iteration instead average CV iterations. following example, plot validation curves second CV iteration specifying cv.= 2 grayscale specifying grayscale = TRUE.  abc(), user can also choose use median (instead mean [default]) ATEs across CV iterations specifying argument combine = “median” plot().","code":"plot(x = output_catecv) plot(x = output_catecv,       show.abc = FALSE,       ylab = c(\"Rate ratio of drug1 vs drug0 in each subgroup\")) plot(x = output_catecv,       cv.i = 2,       grayscale = TRUE,       ylab = c(\"Rate ratio of drug1 vs drug0 in each subgroup\"))"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"visualization-of-the-ate-in-subgroups-with-boxplot","dir":"Articles","previous_headings":"Applying precmed to count outcome data","what":"Visualization of the ATE in subgroups with boxplot()","title":"Examples for count outcome","text":"ATEs multi-category subgroups mutually exclusive can visualized box plots, one box plot scoring method. validation results visualized . x-axis determined prop.multi y-axis estimated ATEs subgroup. specify ylab argument accordingly. subgroups correspond row ate.est.valid.group.cv result output_catecv, example subgroups patient 33% lowest (0-33%), middle 33% (33-66%), highest 33% (66-100%) estimated CATE scores. box plot shows distribution ATEs cv.n CV iterations, instead summary statistics like mean median plot().  toy example, can see two regressions method highest ABC performs best validation curves previous sections. Two regression decreasing RR go subgroup 33% lowest CATE scores (0-33%) subgroup 33% highest CATE scores (66-100%), implying evidence heterogeneous treatment effect CATE scores estimated two regressions can distinguish treatment heterogeneity data. comparison, 3 methods seem struggle validation data. Even tough show different subgroups, can see box plots correspond 2 metrics. Note y-axis can different scales different scoring methods.  Although provided 3 different metrics summarize visualize catecv() outputs, user encouraged choose way data wrangling fits particular situation.","code":"boxplot(x = output_catecv,         ylab = \"Rate ratio of drug1 vs drug0 in each subgroup\")"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Count-examples.html","id":"other-precmed-vignettes-in-this-serie","dir":"Articles","previous_headings":"","what":"Other precmed vignettes in this serie","title":"Examples for count outcome","text":"1. Examples count outcome2. Examples survival outcome3. Additional examples4. Theoretical details","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"load-required-packages","dir":"Articles","previous_headings":"Examples with survival outcome of the entire workflow","what":"Load required packages","title":"Examples for survival outcome","text":"","code":"library(precmed) library(dplyr) library(ggplot2)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"load-data-set-example-data-with-survival-outcome","dir":"Articles","previous_headings":"Examples with survival outcome of the entire workflow","what":"Load data set (Example data with survival outcome)","title":"Examples for survival outcome","text":"show functionalities precmed package survival outcomes first need data. examples use simulated data located survivalExample data set. data set survivalExample simulated based real-world claims data multiple sclerosis 4,000 observations 9 variables. variables baseline patient characteristics like age, gender, previous treatment. use y survival outcome, number days first relapse censoring, whichever comes first. use d event indicator, \\(1\\) represents event \\(0\\) represents censoring. censoring rate 84%. use trt treatment variable, 2 drugs (drug0 drug1). avoid multicollinearity issues, continuous variable age centered 48 years old medical costs year prior treatment initiation previous_cost centered 14,362 USD scaled standard deviation 24,266 USD. final dataset survivalExample looked like :","code":"#> 'data.frame':    4000 obs. of  9 variables: #>  $ age                     : num [1:4000, 1] -26.83 -2.83 -12.83 -20.83 6.17 ... #>   ..- attr(*, \"scaled:center\")= num 45.8 #>  $ female                  : int  1 1 1 0 0 1 1 1 1 1 ... #>  $ previous_treatment      : Factor w/ 3 levels \"drugA\",\"drugB\",..: 3 1 3 1 3 1 3 3 3 1 ... #>  $ previous_cost           : num [1:4000, 1] -0.341 -0.239 -0.171 -0.392 -0.518 ... #>   ..- attr(*, \"scaled:center\")= num 14362 #>   ..- attr(*, \"scaled:scale\")= num 24266 #>  $ previous_number_symptoms: Factor w/ 3 levels \"0\",\"1\",\">=2\": 2 2 2 3 3 2 3 2 2 2 ... #>  $ previous_number_relapses: int  0 1 2 0 1 0 0 2 0 0 ... #>  $ trt                     : Factor w/ 2 levels \"drug0\",\"drug1\": 1 1 1 1 2 1 2 2 2 2 ... #>  $ y                       : num  102.1 51.3 104.9 61.5 35.6 ... #>  $ d                       : num  0 0 0 0 0 0 0 0 0 1 ..."},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"estimation-of-the-ate-with-atefit","dir":"Articles","previous_headings":"Examples with survival outcome of the entire workflow","what":"Estimation of the ATE with atefit()","title":"Examples for survival outcome","text":"First, one might interested effect drug (trt) number days first relapse censoring (y). Lets test using Cox regression. see Cox regression see drug1 resulted hazard ratio (HR) 3.04 compared drug 0. indicates drug 0 superior drug 1 drug 1 increases risk relapse. Now want estimate Average Treatment Effect (ATE) correct several covariates like age previous treatment might influence relation treatment outcome. atefit() function allows estimating ATE terms restricted mean time lost (RMTL) HR (hazard ratio). RMTL estimator doubly robust, meaning estimator consistent PS model (argument ps.model) outcome model (argument cate.model) correctly specified. estimator also depends estimation Inverse Probability Censoring Weights (IPCW). HR estimator based Cox regression model. function also provides standard error, confidence intervals, p-values based bootstrap. mandatory arguments atefit() : response argument specifies type outcome data. survival outcomes, response = “survival”. informs function necessary arguments methods use. argument data indicates data frame outcome, treatment covariates specified either cate.model ps.model fetched. score.method argument specifies precision medicine (PM) methods used calculate CATE scores. total 5 scoring methods implemented: poisson fits Poisson model separately treatment group. boosting uses gradient boosted regression models (GBM) separately treatment group. randomForest fits random forest model treatment group. twoReg implements doubly robust two regressions estimator @yadlowsky2020estimation. contrastReg implements doubly robust contrast regression estimator @yadlowsky2020estimation. argument cate.model specifies CATE model formula, survival object survival package, Surv(y, d), supplied left-hand side explanatory covariates supplied right-hand side. example , chose specify CATE linear combination following covariates: age, sex, medical costs year prior treatment initiation, number relapses year prior treatment initiation. Non-linear interaction terms also included. Note treatment variable supplied cate.model since outcome model. ps.model argument specifies PS model formula, treatment variable trt left-hand side covariates (age previous treatment example) right-hand side. variable trt must supplied numeric variable taking 2 values, “1” active treatment “0” control comparator. case, catecv() stop error trt takes 2 distinct values automatically transform trt numeric variable. example, trt (factor variable taking values “drug0” “drug1”) transformed warning message left user (see output ): Variable trt recoded 0/1 drug0->0 drug1->1. data RCT, suffices specify ps.model = trt ~ 1. Note PS model used estimation 2 doubly robust methods (two contrast regressions). tau0: truncation time defining restricted mean time lost. outcome y skewed towards 0, use 95% upper limit. Let’s calculate ATE effect treatment y build outcome model contains variables PS model age previous_treatment. verbose = 1, function outputs progress bar console. output atefit() shows point estimate, standard error (“SE”), lower (“CI.lower”) upper (“CI.upper”) bound 95% confidence interval, p-value (“pvalue”) 4 estimands: restricted mean survival time drug 1 ($rmst1) restricted mean survival time drug 0 ($rmst0) log RMTL ratio ($log.rmtl.ratio), log ratio tau0 - $rmst1 divided tau0 - $rmst0 log HR ($log.hazard.ratio). example, log RMTL ratio 0.07 95% confidence interval (0, 0.14) displayed output. RMTL ratio along 95% confidence interval suggest drug 0 superior drug 1 ratio significantly greater 1. check estimated RMST, also see estimated rmst1 lower compared rmst0, indicating patients received drug0 longer mean survival time compared drug1. output atefit() expressed terms treatment 0 vs 1, RMTL hazard ratios expressed ratio treatment coded 1 treatment coded 0. treatment variable coded 0/1 data set, function returns warning output_atefit$warning indicates key used recode treatment variable 0/1 variable. Using plot(output_atefit), histograms generated point estimates across n.boot bootstrap iterations 4 estimands (rmst1, rmst0, log.rmtl.ratio, log.hazard.ratio). red vertical line added histogram mean bootstrap estimates.  Histograms bootstrap estimators 4 estimands 500 bootstrap","code":"library(survival) output_cox <- coxph(Surv(y, d) ~ trt, data = survivalExample) summary(output_cox) #> Call: #> coxph(formula = Surv(y, d) ~ trt, data = survivalExample) #>  #>   n= 4000, number of events= 648  #>  #>             coef exp(coef) se(coef)     z Pr(>|z|)     #> trtdrug1 1.11311   3.04381  0.09233 12.06   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #>          exp(coef) exp(-coef) lower .95 upper .95 #> trtdrug1     3.044     0.3285      2.54     3.648 #>  #> Concordance= 0.639  (se = 0.009 ) #> Likelihood ratio test= 170.1  on 1 df,   p=<2e-16 #> Wald test            = 145.3  on 1 df,   p=<2e-16 #> Score (logrank) test = 160.9  on 1 df,   p=<2e-16 #define tau0 tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  #run atefit output_atefit <- atefit(response = \"survival\",                         data = survivalExample,                         cate.model = survival::Surv(y, d) ~ age + female + previous_cost + previous_number_relapses,                         ps.model = trt ~ age + previous_treatment,                         tau0 = tau0) #> Warning in data.preproc.surv(fun = \"drinf\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. output_atefit #> Average treatment effect: #>  #>                   estimate         SE    CI.lower  CI.upper    pvalue #> log.rmtl.ratio   0.0701553 0.03466997 0.002203406 0.1381072 0.0430198 #> log.hazard.ratio 2.7133243 0.19735131 2.326522845 3.1001257 0.0000000 #>  #> Estimated RMST: #>  #>       estimate       SE CI.lower CI.upper pvalue #> rmst1 172.8609 6.961022 159.2176 186.5043      0 #> rmst0 196.5603 8.977587 178.9645 214.1560      0 #> Warning in print.atefit(x): Variable trt was recoded to 0/1 with drug0->0 and drug1->1. output_atefit$warning #> [1] \"Variable trt was recoded to 0/1 with drug0->0 and drug1->1.\\n\""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"estimation-of-the-cate-score-with-catefit","dir":"Articles","previous_headings":"Examples with survival outcome of the entire workflow","what":"Estimation of the CATE score with catefit()","title":"Examples for survival outcome","text":"Now calculated ATE know effect treatments average, effect might patients. Thus, might worthwhile check subgroups respond differently treatments. can calculate Conditional Average Treatment Effect (CATE) score calculates ATE different subgroups data. internal validation needed (get back later), can use catefit() function model directly entire data set estimate CATE score. catefit() function define score.method. arguments specifies precision medicine (PM) method used calculate CATE scores. total 5 scoring methods implemented: mandatory arguments catefit() : response: “survival” example use data survival outcome (e.g., number days first relapse censoring)) data: name data set. (survivalExample) score.method: argument specifies precision medicine (PM) methods used calculate CATE scores. total 5 scoring methods implemented: poisson fits Poisson model separately treatment group. boosting uses gradient boosted regression models (GBM) separately treatment group. randomForest fits random forest model treatment group. twoReg implements doubly robust two regressions estimator @yadlowsky2020estimation. contrastReg implements doubly robust contrast regression estimator @yadlowsky2020estimation. cate.model: formula describing outcome model fitted. outcome must appear left-hand side. example, choose specify outcome model linear combination following covariates: age, sex, medical costs year prior treatment initiation, number relapses year prior treatment initiation. Non-linear interaction terms also included. Note treatment variable supplied cate.model since outcome model. ps.model: formula describing propensity score (PS) model fitted. treatment must appear left-hand side covariates (age previous treatment example) right-hand side. variable trt must supplied numeric variable taking 2 values, 1 active treatment 0 control comparator. case, function stop error trt takes 2 distinct values automatically transform trt numeric variable. example, trt (factor variable taking values “drug0” “drug1”) transformed warning message left user (see output ): Variable trt recoded 0/1 drug0->0 drug1->1. data RCT, suffices specify ps.model = trt ~ 1. Note PS model used estimation 2 doubly robust methods (two contrast regressions). also specified following non-mandatory arguments fit data problem hand: initial.predictor.method, tau0, higher.y, seed, plot.gbmperf. initial.predictor.method specifies predictions outcome estimated two regressions contrast regression. Flexible models can used GBM (“boosting”), random forests (“randomForest”) logistic regression (“logistic”). chose “logistic” relatively faster boosting methods random forest. tau0 truncation time defining restricted mean time lost (RMTL). outcome y skewed towards 0, use 95% upper limit. higher.y set TRUE relapse negative event longer time first relapse desirable example. Hence, telling function subgroups high responders drug1 vs drug0 later onset first relapse. situation, higher outcomes may favorable time positive event, e.g., time discharge time improved disability. important argument match nature y outcome affect subgroups defined CATE scores performance metrics. set random seed seed = 999 reproduce results. avoided generating boosting performance plots specifying plot.gbmperf = FALSE. Please see Function description section details. run errors warnings data, might helpful go descriptions see need alter default values. toy example, keep default values remaining arguments. toy example selected randomForest contrastReg limit run time. method specified score.method following sets results catefit(): score contains log-transformed estimated CATE scores subject. CATE score linear combination variables specified cate.model argument. outcome, lower CATE scores desirable higher.y = FALSE vice versa. example, survival outcome time first relapse, negative event, higher values indicate later onset first relapse. Hence, specify higher.y = TRUE example. subject 1 CATE score length output 4,000 toy example. show CATE scores estimated contrast regression first 6 subjects data. coefficients contains estimated coefficients CATE score scoring method. data frame covariates (including intercept) rows scoring methods columns. toy example, 4 covariates cate.model, plus intercept, 5 rows estimated coefficients within column. Boosting method estimate coefficients (directly predicts score) coefficient results . can define estimated CATE scores contrast regression like shown . user can use information study influence covariate. \\[ \\begin{aligned} \\widehat{CATE} = 0.25 & - 0.19 \\times \\text{age} \\\\ & + 0.14 \\times \\text{female (vs male)} \\\\ & + 0.56 \\times \\text{previous medical costs} \\\\ & + 0.37 \\times \\text{previous number relapses} \\end{aligned} \\] ate contains estimated ATEs nested subgroup high responders drug 1 defined prop.cutoff. subgroups defined based estimated CATE scores specified scoring method. example, show estimated ATEs subgroups identified CATE scores contrast regression. example, estimated ATE subgroup subjects constructed based 50% (“prop0.5”) lowest CATE scores estimated contrast regression 0.41. encouraged summarize visualize outputs whichever way fits particular situation outside package’s functions. example, possible plot densities CATE scores ggplot. subjects extremely high estimated CATE scores samples fall -10 10.","code":"tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  output_catefit <- catefit(response = \"survival\",                           data = survivalExample,                           score.method = c( \"randomForest\", \"contrastReg\"),                           cate.model = survival::Surv(y, d) ~ age + female + previous_cost + previous_number_relapses,                           ps.model = trt ~ age + previous_treatment,                           initial.predictor.method = \"logistic\",                           tau0 = tau0,                            higher.y = TRUE,                           seed = 999,                           plot.gbmperf = FALSE) #> Warning in data.preproc.surv(fun = \"catefit\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. length(output_catefit$score.contrastReg) #> [1] 4000 head(output_catefit$score.contrastReg) #> [1]  5.3273340  1.1661594  3.4869179  4.0157912 -0.8475816  2.4217492 output_catefit$coefficients #>                          contrastReg #> (Intercept)                0.2526763 #> age                       -0.1912056 #> female                     0.1359512 #> previous_cost              0.5629853 #> previous_number_relapses   0.3703522 output_catefit$ate.contrastReg #>   prop0.5   prop0.6   prop0.7   prop0.8   prop0.9     prop1  #> 0.4105682 0.5114925 0.6269751 0.7800895 0.9145661 1.0726748 dataplot <- data.frame(score = factor(rep(c(\"Random Forest\", \"Contrast regression\"),                                            each = length(output_catefit$score.randomForest))),                         value = c(output_catefit$score.randomForest,output_catefit$score.contrastReg))  dataplot %>%    ggplot(aes(x = value, fill = score)) +    geom_density(alpha = 0.5) +   theme_classic() +    labs(x = \"Estimated CATE score\", y = \"Density\", fill = \"Method\") #> Warning: Removed 5 rows containing non-finite values (`stat_density()`)."},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"internal-validation-via-catecv","dir":"Articles","previous_headings":"Examples with survival outcome of the entire workflow","what":"Internal validation via catecv()","title":"Examples for survival outcome","text":"catecv() function provides estimation catefit() via cross-validation (CV). catecv() function internal CV applied reduce optimism choosing CATE estimation method captures treatment effect heterogeneity. CV applied repeating following steps cv.n times: Split data training validation set according train.prop argument. training validation sets must balanced respect covariate distributions doubly robust rate ratio estimates (see error.max argument). Estimate CATE score training set specified scoring method. Predict CATE score validation set using scoring model fitted training set. Build nested subgroups treatment responders training validation sets, separately, estimate ATE within nested subgroup. element prop.cutoff argument (e.g., prop.cutoff[] = 0.6), take following steps: Identify high responders observations 60% (.e., prop.cutoff[]x100%) highest (higher.y = TRUE) lowest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup high responders using doubly robust estimator. Conversely, identify low responders observations 40% (.e., 1 - prop.cutoff[]x100%) lowest (higher.y = TRUE) highest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup low responders using doubly robust estimator. abc = TRUE, calculate area ATE series ATEs nested subgroups high responders validation set. (information abc score, see Validation curves ABC statistics) Build mutually exclusive subgroups treatment responders training validation sets, separately, estimate ATE within subgroup. Mutually exclusive subgroups built splitting estimated CATE scores according prop.multi. Oke, now can use catecv() function run internal validation compare different scoring methods. mandatory arguments similar atefit() catefit(): mandatory arguments : response, data, score.method, cate.model, ps.model. See details arguments. toy example selected randomForest contrastReg limit run time. also specified following non-mandatory arguments fit data problem hand: initial.predictor.method, ipcw.model, verbose, followup.time, tau0, higher.y, cv.n, surv.min, seed, plot.gbmperf. initial.predictor.method specifies predictions outcome estimated two regressions contrast regression. Flexible models can used GBM (“boosting”), random forests (“randomForest”) logistic regression (“logistic”). chose “logistic” relatively faster boosting methods random forest. followup.time specifies maximum follow-time data. set default NULL, indicates unknown potential censoring time. tau0 truncation time defining restricted mean time lost (RMTL). outcome y skewed towards 0, use 95% upper limit. higher.y set TRUE relapse negative event longer time first relapse desirable example. Hence, telling function subgroups high responders drug1 vs drug0 later onset first relapse. situation, higher outcomes may favorable time positive event, e.g., time discharge time improved disability. important argument match nature y outcome affect subgroups defined CATE scores performance metrics. surv.min truncates censoring probability estimated IPCW model lower limit prevent extremely small censoring probabilities. recommended choose small positive value close 0. chose 0.025 example, corresponds default value. performed 5 CV iterations specifying cv.n = 5. Typically, CV iterations desirable although associated longer computational times. set random seed seed = 999 reproduce results. avoided generating boosting performance plots specifying plot.gbmperf = FALSE. verbose = 1, progress messages printed R console errors warnings printed. current CV iteration printed, followed steps CV procedure (splitting data, training models, validating models). timestamp progress bar also displayed upon completion CV iteration. contrastReg selected one methods score.method, additional line output message indicate whether algorithm converged. many non-mandatory arguments catecv() can accept. Please see Additional examples vignette examples Function description Function description details. run errors warnings data, might helpful go descriptions see need alter default values. toy example, keep default values remaining arguments. output catecv() object class “precmed” named output_catecv. carries relevant information use next step workflow selects method (among specified argument score.method) capturing highest level treatment effect heterogeneity. output, described , used functions abc(), plot() boxplot(). method specified argument score.method, following 3 groups outputs generated: high, low group. use results randomForest example. 1. ATEs nested subgroups high responders output stores ATEs - ratio RMTL drug1 vs drug0 example - nested subgroups patients high responders drug 1 training ($ate.est.train.high.cv) validation ($ate.est.valid.high.cv) sets across CV iterations. higher.y = TRUE survival outcomes, case example, lower CATE scores correspond high responders drug1. higher.y = FALSE survival outcomes, higher CATE scores correspond high responders drug1. Note different count outcomes. direction CATE scores depends higher.y outcome type. output matrix columns corresponding CV iterations, labeled 1 cv.n, rows corresponding nested subgroups. nested subgroups patients defined argument prop.cutoff. , use seq(0.6, 1, length = 5) defines nested subgroups 60%, 70%, 80%, 90% 100% lowest (highest higher.y = FALSE) CATE scores estimated random forest. rows output labeled reflect user-specified proportions used build subgroups. example, training set 4th CV iteration (4th column labeled “cv4”), subgroup defined 80% lowest CATE scores (4th row labeled “prop0.8”) estimated RMTL ratio 0.753. contrast, subgroup defined patients (last row labeled “prop1”) 4th CV iteration estimated RMTL ratio 1.083. 2. ATEs nested subgroups low responders output stores ATEs nested subgroups low responders drug1 training ($ate.est.train.low.cv) validation ($ate.est.valid.low.cv) sets across CV iterations. higher.y = TRUE survival outcomes, higher CATE scores correspond low responders drug1. higher.y = FALSE survival outcomes, lower CATE scores correspond low responders drug1. , different count outcomes. direction CATE scores depends higher.y outcome type. outputs also matrices columns corresponding CV iterations rows corresponding nested subgroups. output low responders brings additional information user. gives ATEs complement nested subgroup high responders. example, complement subgroup high responders defined patients 60% lowest (highest higher.y = FALSE) estimated CATE scores subgroup low responders defined patients 40% highest (lowest higher.y = TRUE) estimated CATE scores, labeled “prop0.4”. training set first CV iterations, estimated RMTL ratio 0.62 60% high responders drug 1 38.212 40% low responders. 2 last rows missing infinite values can due many reasons. record errors warnings keep element cv output. example, can use following code check specific errors warnings first CV iteration ($cv1) using random forest method ($randomForest) estimating ATE training sample low responder groups ($est.train.low.cv). looks like event observation 10% subgroup, possibly due small sample size, also relates convergence issue warning. Additionally, warning 20% subgroup ($warnings$'prop0.2') suggested non-convergence Cox procedure corresponding estimated ATE interpreted caution. 3. ATEs mutually exclusive multi-category subgroups output stores ATEs mutually exclusive multi-category subgroups patients training ($ate.est.train.group.cv) validation ($ate.est.valid.group.cv) sets across CV iterations. output matrix columns corresponding CV iterations rows corresponding mutually exclusive subgroups. previous 2 outputs focus binary subgroups (high low responders). , mutually exclusive subgroups can 2 defined argument prop.multi. use c(0, 0.5, 0.6, 1) defines 3 subgroups patients 50% lowest, 10% middle 40% highest estimated CATE scores higher.y = TRUE (example), 40% highest, 10% middle 50% lowest estimated CATE scores higher.y = FALSE. Taking first column example, first CV iteration calculated 3.415 RMTL ratio subgroup 50% lowest estimated CATE scores, 1.29 RMTL ratio subgroup middle 10% estimated CATE scores, 0.291 RMTL ratio subgroup 40% highest estimated CATE scores. Use output_catecv$`errors/warnings`$randomForest$est.train.group.cv learn errors warnings generated outputs.","code":"tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  output_catecv <- catecv(response = \"survival\",                         data = survivalExample,                         score.method = c(\"randomForest\", \"contrastReg\"),                         cate.model = survival::Surv(y, d) ~ age + female +                                      previous_cost + previous_number_relapses,                         ps.model = trt ~ age + previous_treatment,                         initial.predictor.method = \"logistic\",                         followup.time = NULL,                         tau0 = tau0,                         higher.y = TRUE,                         surv.min = 0.025,                         prop.cutoff = seq(0.6, 1, length = 5),                         prop.multi = c(0, 0.5, 0.6, 1),                         cv.n = 5,                         seed = 999,                         plot.gbmperf = FALSE,                         verbose = 1) #> Warning in data.preproc.surv(fun = \"crossv\", cate.model = cate.model, ps.model = ps.model, : Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:29:02 2022  #>    |                                                                               |==============                                                        |  20% #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:29:32 2022  #>    |                                                                               |============================                                          |  40% #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:30:02 2022  #>    |                                                                               |==========================================                            |  60% #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:30:32 2022  #>    |                                                                               |========================================================              |  80% #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>   Contrast regression converged. #>    Mon Dec 12 15:31:01 2022  #>    |                                                                               |======================================================================| 100% #> Total runtime : 2.49 mins output_catecv$ate.randomForest$ate.est.train.high.cv #>               cv1       cv2       cv3       cv4       cv5 #> prop0.6 0.4753124 0.4917526 0.4876323 0.5089093 0.5584117 #> prop0.7 0.6196242 0.6655303 0.6163124 0.6550763 0.6209161 #> prop0.8 0.7339630 0.7765458 0.7329931 0.7527532 0.7377974 #> prop0.9 0.8926423 0.9379673 0.8957898 0.9183219 0.8988051 #> prop1   1.0534514 1.1042633 1.0646558 1.0830122 1.0690691 output_catecv$ate.randomForest$ate.est.valid.high.cv #>               cv1       cv2       cv3       cv4       cv5 #> prop0.6 0.5081771 0.5282781 0.4875482 0.5879925 0.5056018 #> prop0.7 0.6209561 0.5433708 0.6375556 0.5917497 0.6089569 #> prop0.8 0.7970265 0.7169490 0.7944385 0.7349855 0.7500680 #> prop0.9 0.9830217 0.8543862 0.9462473 0.8868964 0.9248308 #> prop1   1.1465914 1.0194984 1.0968389 1.0526779 1.1027499 output_catecv$ate.randomForest$ate.est.train.low.cv #>               cv1       cv2      cv3       cv4       cv5 #> prop0.4  7.475048  6.763305  9.56552  7.574093  7.307854 #> prop0.3 38.211815 53.883349 96.68014 46.428207 46.385038 #> prop0.2       Inf        NA      Inf       Inf       Inf #> prop0.1        NA        NA       NA        NA        NA output_catecv$`errors/warnings`$randomForest$est.train.low.cv$cv1 #> $errors #> $errors$`prop 0.1` #> [1] \"Error in dimnames(means) <- list(time, vname) : 'dimnames' applied to non-array\" #>  #>  #> $warnings #> $warnings$`prop 0.2` #> [1] \"Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter) : Ran out of iterations and did not converge\" #> [2] \"Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter) : one or more coefficients may be infinite\"   #> [3] \"Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter) : Ran out of iterations and did not converge\" #>  #> $warnings$`prop 0.1` #> [1] \"Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter) : Ran out of iterations and did not converge\" #> [2] \"Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter) : Ran out of iterations and did not converge\" output_catecv$`errors/warnings`$randomForest$est.valid.low.cv$cv1 #> $errors #> $errors$`prop 0.2` #> [1] \"Error in coxph(Surv(y, d) ~ x) : No (non-missing) observations\" #>  #> $errors$`prop 0.1` #> [1] \"Error in coxph(Surv(y, d) ~ x) : No (non-missing) observations\" #>  #>  #> $warnings #> $warnings$`prop 0.4` #> [1] \"Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter) : Ran out of iterations and did not converge\" #>  #> $warnings$`prop 0.3` #> [1] \"Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter) : Ran out of iterations and did not converge\"                          #> [2] \"Warning in coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter), coxph.fit(X, Y, istrat, offset, init, control, weights = weights, method = method, rname, nocenter = nocenter) : Loglik converged before variable  4 ; coefficient may be infinite. \" #>  #> $warnings$`prop 0.2` #> [1] \"Warning in max(event[who2]) : glm.fit: algorithm did not converge\"             #> [2] \"Warning in max(event[who2]) : no non-missing arguments to max; returning -Inf\" #>  #> $warnings$`prop 0.1` #> [1] \"Warning in max(event[who2]) : no non-missing arguments to max; returning -Inf\" output_catecv$ate.randomForest$ate.est.train.group.cv #>               cv1       cv2       cv3       cv4       cv5 #> prop0.5 3.4151485 3.5654842 3.7254944 3.6552745 3.6690400 #> prop0.6 1.2898656 1.0877241 1.0683353 1.1623681 0.9201879 #> prop1   0.2910105 0.4227029 0.2707232 0.2805186        NA output_catecv$ate.randomForest$ate.est.valid.group.cv #>               cv1      cv2       cv3       cv4      cv5 #> prop0.5 4.7844569 3.439306 3.4420698 4.0713342 3.500151 #> prop0.6 0.8403764 1.197367 4.9331418 0.8511804 1.343130 #> prop1          NA       NA 0.3243074        NA       NA"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"comparison-of-methods-with-abc","dir":"Articles","previous_headings":"Examples with survival outcome of the entire workflow","what":"Comparison of methods with abc()","title":"Examples for survival outcome","text":"ABC statistics calculated abc() scoring method specified catecv() cv.n CV iterations using output object output_catecv catecv(). ABC corresponds area curve formed ATEs subgroups high responders validation set (e.g., output_catecv$ate.randomForest$ate.est.valid.cv random forest) horizontal line representing ATE validation set. higher ABC value means method captures treatment effect heterogeneity. output matrix columns corresponding CV iterations rows corresponding scoring methods specified score.method. example, random forest CV iteration 1 ABC 0.153, highest CV iteration, meaning random forest offers best performance first CV iteration. user can combine ABC method across iterations: example, random forest also offers best overall performance highest average ABC, followed closely contrast regression.","code":"output_abc <- abc(x = output_catecv) output_abc #>                    cv1       cv2       cv3       cv4       cv5 #> randomForest 0.1533033 0.1450798 0.1392829 0.1458115 0.1532764 #> contrastReg  0.1416306 0.1304287 0.1366230 0.1304199 0.1519283 average_abc <- apply(output_abc, 1, mean) average_abc #> randomForest  contrastReg  #>    0.1473508    0.1382061"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"visualization-of-the-validation-curves-with-plot","dir":"Articles","previous_headings":"Examples with survival outcome of the entire workflow","what":"Visualization of the validation curves with plot()","title":"Examples for survival outcome","text":"ATEs nested subgroups high responders drug1 (e.g., output_catecv$ate.randomForest$ate.est.train.high.cv output_catecv$ate.randomForest$ate.est.valid.high.cv random forest) can visualized side--side line plot, training results left validation results right. x-axis determined prop.cutoff y-axis estimated ATEs averaged cv.n CV iterations specified cv.= NULL (default). estimated ATE expressed RMTL ratio drug1 versus drug0 toy example. default, function retrieves name treatment variable (trt) original labels (drug0 drug1) specify meaningful y-axis label. Otherwise, possible customize y-axis label via ylab, example, specifying ylab = “RMTL ratio drug1 vs drug0 subgroup”. Steeper slopes indicate treatment effect heterogeneity drug1 drug0. higher.y = TRUE example, slopes increasing left (prop.cutoff = 0.6) right (prop.cutoff = 1) treatment effect heterogeneity present (see section Validation curves ABC statistics illustration). method steepest slope validation results selected captures treatment effect heterogeneity generalizing well unseen data.  toy example, methods performing well training data per steep, increasing slopes left plot. Moreover, methods generalize well validation data, indicated monotonous increasing curves validation data (right plot). dashed gray line ATE entire data set, lines merge reference line subgroup size 100% data (prop.cutoff = 1). explanation validation curves, see function description. plot’s legend includes ABC statistics validation set. user can choose mute ABC annotations specifying show.abc = FALSE.  user can choose plot validation curves 1 CV iteration instead average CV iterations. following example, plot validation curves second CV iteration specifying cv.= 2 grayscale specifying grayscale = TRUE.  user can also choose use median (instead mean [default]) ATEs across CV iterations specifying argument combine = “median” plot().","code":"plot(x = output_catecv) plot(x = output_catecv,       show.abc = FALSE,       ylab = c(\"RMTL ratio of drug1 vs drug0 in each subgroup\")) plot(x = output_catecv,       cv.i = 2,       grayscale = TRUE,       ylab = c(\"RMTL ratio of drug1 vs drug0 in each subgroup\"))"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"visualization-of-the-ate-in-subgroups-with-boxplot","dir":"Articles","previous_headings":"Examples with survival outcome of the entire workflow","what":"Visualization of the ATE in subgroups with boxplot()","title":"Examples for survival outcome","text":"ATEs multi-category subgroups mutually exclusive can visualized box plots, 1 box plot scoring method. validation results visualized . x-axis determined prop.multi y-axis estimated ATEs subgroup. specify ylab argument accordingly. subgroups correspond row ate.est.valid.group.cv result output_catecv, example subgroups patient 50% lowest (0-50%), middle 10% (50-60%), highest 40% (60-100%) estimated CATE scores. Notice groups equally spaced terms percentiles. box plot shows distribution ATEs cv.n CV iterations, instead summary statistics like mean median plot().  toy example, can see random forest contrast regression methods 2 highest ABC perform best validation curves previous sections. distinctive decreasing RMT ratio go subgroup 50% lowest CATE scores (red) subgroup 40% highest CATE scores (blue). implies evidence heterogeneous treatment effect CATE scores estimated random forest contrast regression can capture . also relatively smaller variation boxes thinner. comparison, 3 methods also present increasing trend box plots, observe larger variation RMTL ratio, especially boosting. can see box plots correspond 2 outputs, abc() plot(). Note y-axis can different scales different scoring methods.  far provided 3 different metrics summarize, visualize, evaluate catecv() outputs. user encouraged choose way data wrangling fits particular situation.","code":"boxplot(x = output_catecv,         ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") #> Warning: Removed 4 rows containing non-finite values (`stat_boxplot()`)."},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Survival-examples.html","id":"other-precmed-vignettes-in-this-serie","dir":"Articles","previous_headings":"","what":"Other precmed vignettes in this serie","title":"Examples for survival outcome","text":"1. Examples count outcome2. Examples survival outcome3. Additional examples4. Theoretical details","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"theoretical-details---count-outcomes","dir":"Articles","previous_headings":"","what":"Theoretical details - Count outcomes","title":"Theoretical details","text":"CATE score represents individual-level treatment effect expressed rate ratio count outcomes. can estimated boosting, Poisson regression, negative binomial regression, doubly robust estimator two regressions (Yadlowsky et al. 2020) applied separately treatment group doubly robust estimator contrast regression (Yadlowsky et al. 2020) applied entire data set. Assume following data recorded \\(n\\) observations: \\(R\\) binary treatment taking value 0 1. \\(\\boldsymbol{X}\\) vector \\(p\\) baseline covariates. \\(Y\\) count outcome. \\(T\\) exposure time \\(Y\\) recorded. can vary across observations. objective estimate ratio-based CATE score defined \\[CATE(\\boldsymbol{x})=\\text{log}\\left(\\frac{\\mathbb{E}[Y^{(1)}|\\boldsymbol{X}=\\boldsymbol{x},T=1]}{\\mathbb{E}[Y^{(0)}|\\boldsymbol{X}=\\boldsymbol{x},T=1]}\\right)\\] \\(Y^{(r)}\\) potential outcome patient received treatment \\(r \\\\{0,1\\}\\). \\(CATE(\\boldsymbol{x})\\) interpreted individualized log-rate ratio treatment 1 treatment 0 conditional baseline covariates. package offers 5 methods estimate CATE score: Poisson regression, negative binomial regression, boosting, two regressions, contrast regression.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"poisson","dir":"Articles","previous_headings":"Theoretical details - Count outcomes","what":"Poisson","title":"Theoretical details","text":"Estimate conditional mean outcome given baseline covariates log-transformed exposure time offset separately treatment group (.e., \\(\\text{log}(\\mathbb{E}[Y^{(r)}|\\boldsymbol{x},t])=\\beta_r \\boldsymbol{\\tilde x}\\) \\(r \\\\{0,1\\}\\) \\(\\boldsymbol{\\tilde x}\\) \\(x\\) intercept) Poisson regression. Denote prediction one time unit \\(\\hat Y^{(r)}(\\boldsymbol{x},1)=\\text{exp}(\\hat \\beta_r \\boldsymbol{\\tilde x})\\). CATE score Poisson plug-estimator \\[\\hat{CATE}_{Poisson}(\\boldsymbol{x})=\\text{log}\\left(\\frac{\\hat Y^{(1)}(\\boldsymbol{x},1)}{\\hat Y^{(0)}(\\boldsymbol{x},1)}\\right)\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"negative-binomial","dir":"Articles","previous_headings":"Theoretical details - Count outcomes","what":"Negative binomial","title":"Theoretical details","text":"Follow step Poisson replace Poisson regression negative binomial regression step 1.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"boosting","dir":"Articles","previous_headings":"Theoretical details - Count outcomes","what":"Boosting","title":"Theoretical details","text":"Estimate conditional mean outcome given baseline covariates log-transformed exposure time offset separately treatment group (.e., \\(\\mathbb{E}[Y^{(r)}|\\boldsymbol{x},t]\\) \\(r \\\\{0,1\\}\\)) Poisson-based gradient boosting regression method. Denote prediction one time unit \\(\\hat Y^{(r)}(\\boldsymbol{x},1)\\). base learners regression trees depth specified argument tree.depth catecvcount() catefitcount(). Default 2. number trees boosting selected via cross-validation maximum number trees specificed argument n.trees catecvcount() catefitcount(). Default 200. CATE score boosting plug-estimator \\[\\hat{CATE}_{boosting}(\\boldsymbol{x})=\\text{log}\\left(\\frac{\\hat Y^{(1)}(\\boldsymbol{x},1)}{\\hat Y^{(0)}(\\boldsymbol{x},1)}\\right)\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"two-regressions","dir":"Articles","previous_headings":"Theoretical details - Count outcomes","what":"Two regressions","title":"Theoretical details","text":"Randomly separate data \\(D\\) \\(K\\) (Kfold) non-overlapping parts approximately equal sizes, \\(D_1, \\dots, D_K\\). fold \\(k=1,\\dots,K\\), separately treatment group \\(r \\\\{0,1\\}\\): 2.1 Estimate conditional mean outcome given baseline covariates log-transformed exposure time offset Poisson-based gradient boosting regression method based observations without kth fold, \\(D_{-k}\\), denote prediction \\(\\hat Y_{-k}^{(r)}(\\boldsymbol{x},t)\\). initial nonparametric prediction potential outcome. 2.2 Estimate PS based \\(D_{-k}\\). Denote estimated PS \\(\\hat \\pi_{-k}(\\boldsymbol{x})\\) estimate weights \\(\\hat W(r)=r\\frac{R}{\\hat \\pi_{-k}(\\boldsymbol{x})}+(1-r)\\frac{(1-R)}{1-\\hat \\pi_{-k}(\\boldsymbol{x})}\\) \\(R\\) denoting treatment received. 2.3 Solve following weighted estimating equation fitting Poisson regression \\(Y\\) response, \\(\\text{log}(\\hat Y^{(r)}(\\boldsymbol{x},1))\\) \\(x\\) covariates, \\(\\text{log}(T)\\) offset, \\(\\hat W(r)\\) weight: \\[S(\\alpha_{rk}, \\boldsymbol{\\gamma_{rk}})=\\sum_{\\D_{-k}} \\hat W(r) \\pmatrix{\\text{log}\\left(\\hat Y^{(r)}(\\boldsymbol{x},1)\\right)\\\\\\boldsymbol{\\tilde x}}\\left(Y - \\text{exp}\\left(\\alpha_{rk}\\text{log}\\left(\\hat Y^{(r)}(\\boldsymbol{x},1)\\right)+\\boldsymbol{\\gamma_{rk}^T\\boldsymbol{\\tilde x}}\\right)\\times T\\right)=0\\] \\(\\) denotes individual observations. Denote roots \\((\\hat \\alpha_{rk}, \\boldsymbol{\\hat\\gamma_{rk}})\\). Solve following doubly robust estimating equation fitting Poisson regression \\(\\text{exp}\\left(\\hat\\alpha_{rk}\\text{log}\\left(\\hat Y^{(r)}(\\boldsymbol{x},1)\\right)+\\boldsymbol{\\hat\\gamma_{rk}^T\\boldsymbol{\\tilde x}}\\right)\\) response, \\(\\boldsymbol{x}\\) covariates, offset weight: \\[S(\\boldsymbol{\\beta_r})=\\sum_{k=1}^K \\sum_{\\D_{-k}}\\boldsymbol{\\tilde x}\\left(\\text{exp}\\left(\\hat\\alpha_{rk}\\text{log}\\left(\\hat Y^{(r)}(\\boldsymbol{x},1)\\right)+\\boldsymbol{\\hat\\gamma_{rk}^T\\boldsymbol{\\tilde x}}\\right)-\\text{exp}(\\boldsymbol{\\beta_r^T\\tilde x})\\right)=0\\] Denote estimator \\(\\boldsymbol{\\hat \\beta_r}\\). Repeat steps 1-3 \\(B\\) bootstrap samples denote estimator \\(\\boldsymbol{\\hat \\beta_{rb}}\\) \\(b\\) sample. final estimator \\(\\boldsymbol{\\hat \\beta_r}\\) mean \\(\\boldsymbol{\\hat \\beta_{rb}}\\). CATE score two regressions \\[\\hat{CATE}_{tworeg}(\\boldsymbol{x})=(\\boldsymbol{\\hat \\beta_1} - \\boldsymbol{\\hat \\beta_0})^T\\boldsymbol{\\tilde x}\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"contrast-regression","dir":"Articles","previous_headings":"Theoretical details - Count outcomes","what":"Contrast regression","title":"Theoretical details","text":"Randomly separate data \\(D\\) \\(K\\) (Kfold) non-overlapping parts approximately equal sizes, \\(D_1, \\dots, D_K\\). fold \\(k=1,\\dots,K\\), separately treatment group \\(r \\\\{0,1\\}\\): 2.1 Estimate conditional mean outcome given baseline covariates log-transformed exposure time offset Poisson-based gradient boosting regression method based observations without kth fold, \\(D_{-k}\\), denote prediction \\(\\hat Y_{-k}^{(r)}(\\boldsymbol{x},t)\\). initial nonparametric prediction potential outcome. 2.2 Estimate PS based \\(D_{-k}\\). Denote estimated PS \\(\\hat \\pi_{-k}(\\boldsymbol{x})\\). Solve following doubly robust estimating equation Newton-Raphson method using L2-norm score method former fails converge: \\[\\begin{aligned} S(\\boldsymbol{\\delta})&=\\sum_{k=1}^K \\sum_{\\D_{-k}} \\boldsymbol{\\tilde x}\\Bigg[\\frac{R\\left\\{\\frac{Y}{T}-\\frac{1}{2}\\left(\\hat Y_{-k}^{(0)}(\\boldsymbol{ x})\\text{exp}(\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x}) + \\hat Y_{-k}^{(1)}(\\boldsymbol{x})\\right)\\right\\}(1-\\hat\\pi_{-k}(\\boldsymbol{x}))}{\\text{exp}(\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x})\\hat\\pi_{-k}(\\boldsymbol{x})+1-\\hat\\pi_{-k}(\\boldsymbol{x})}\\\\ &+\\frac{(1-R)\\left\\{\\frac{Y}{T}-\\frac{1}{2}\\left(\\hat Y_{-k}^{(0)}(\\boldsymbol{ x}) + \\hat Y_{-k}^{(1)}(\\boldsymbol{x})\\text{exp}(-\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x})\\right)\\right\\}\\text{exp}(\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x})\\hat\\pi_{-k}(\\boldsymbol{x})}{\\text{exp}(\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x})\\hat\\pi_{-k}(\\boldsymbol{x})+1-\\hat\\pi_{-k}(\\boldsymbol{x})}\\Bigg]=0 \\end{aligned}\\] Denote estimator \\(\\boldsymbol{\\hat\\delta}\\). Repeat steps 1-3 \\(B\\) bootstrap samples denote estimator \\(\\boldsymbol{\\hat \\delta_b}\\) \\(b\\) sample. final estimator \\(\\boldsymbol{\\hat \\delta}\\) mean \\(\\boldsymbol{\\hat \\delta_b}\\). CATE score contrast regression \\[\\hat{CATE}_{contrastreg}(\\boldsymbol{x})=\\boldsymbol{\\hat \\delta^T\\tilde x}\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"validation-curves-and-the-abc-statistics","dir":"Articles","previous_headings":"Theoretical details - Count outcomes","what":"Validation curves and the ABC statistics","title":"Theoretical details","text":"ABC statistic represents area validation curve ATE described (Zhao et al. 2013). single CV iteration, implemented training validation sets separately following: Step 1. Calculate ATE training validation sets. Step 2. Calculate ATE 100 nested subgroups based estimated CATE score derive corresponding validation curve. Subgroups defined 100 equally-spaced proportions min(prop.cutoff) max(prop.cutoff) ensure enough data points available build validation curve. Step 3. ABC calculated auc() MESS R package using natural cubic spline interpolation, calculates area horizontal line y-intercept ATE calculated step 1 range [min(prop.cutoff),max(prop.cutoff)] (y) validation curve calculated step 2 (x). function plot() allows user combine validation curves 2 CV iterations (.e., cv.n > 1). 2 ways combine validation curves: option combine=“median” takes median ATEs across CV iterations step 1 median ATEs 100 nested subgroups step 2. option combine=“mean” takes mean ATEs across CV iterations step 1 mean ATEs 100 nested subgroups step 2. either case, ABC calculations carried step 3 resulting x y. figure explains ABC calculated simple schema. ABC calculations larger positive ABC values always indicate treatment effect heterogeneity. implemented considering separately cases larger smaller outcomes preferred. larger count outcomes preferred (higher.y = TRUE, e.g., positive events like number motor developmental milestones reached), validation curve ATE line decreasing towards line synonym treatment effect heterogeneity (top left figure). However, sections validation curve ATE line indicate inability capture treatment effect heterogeneity (bottom left figure). Hence, ABC defined subtracting areas ATE line (red) areas ATE line (green) larger positive ABC preferred. smaller count outcomes preferred (higher.y = FALSE, e.g., negative events like number relapses), validation curve ATE line increasing towards line synonym treatment effect heterogeneity (top right figure). However, sections validation curve ATE line indicate inability capture treatment effect heterogeneity (bottom right figure). Hence, ABC defined subtracting areas ATE line (red) areas ATE line (green) larger positive ABC preferred.  ABC calculation examples relation higher.y argument catecv() catefit(). Validation curves represented blue line dashed line ATE","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"theoretical-details---survival-outcomes","dir":"Articles","previous_headings":"","what":"Theoretical details - Survival outcomes","title":"Theoretical details","text":"CATE score represents individual-level treatment effect survival data, estimated random forest, boosting, Poisson regression, doubly robust estimator (two regressions, (Yadlowsky et al. 2020)) applied separately treatment group doubly robust estimators (contrast regression, (Yadlowsky et al. 2020)) applied entire data set. Assume following data recorded \\(n\\) observations: \\(R\\) binary treatment taking value 0 1. \\(\\boldsymbol{X}\\) vector \\(p\\) baseline covariates. \\(T\\) survival time. \\(C\\) censoring time. \\(Y\\) minimum \\(T\\) \\(C\\). \\(\\delta\\) indicator taking value 1 \\(Y = T\\) 0 otherwise. \\(\\tau\\) truncation time restricted mean time lost. objective estimate ratio-based CATE score defined \\[CATE(\\boldsymbol{x})=\\text{log}\\left(\\frac{\\mathbb{E}[\\tau - (T^{(1)} \\wedge\\tau)|\\boldsymbol{X}=\\boldsymbol{x}]}{\\mathbb{E}[\\tau - (T^{(0)} \\wedge\\tau)|\\boldsymbol{X}=\\boldsymbol{x}]}\\right)\\] \\(T^{(r)}\\) potential survival time patient received treatment \\(r \\\\{0,1\\}\\). \\(CATE(\\boldsymbol{x})\\) interpreted individualized logarithm restricted mean time lost (RMTL) ratio treatment 1 treatment 0 conditional baseline covariates. package offers 5 methods estimate CATE score: Poisson regression, random forest, boosting, two regressions, contrast regression.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"poisson-1","dir":"Articles","previous_headings":"Theoretical details - Survival outcomes","what":"Poisson","title":"Theoretical details","text":"Estimate conditional mean RMTL given baseline covariates separately treatment group (.e., \\(\\text{log}(\\mathbb{E}[\\tau - T\\wedge\\tau|\\boldsymbol{x}, r])=\\beta_r \\boldsymbol{\\tilde x}\\) \\(r \\\\{0,1\\}\\) \\(\\boldsymbol{\\tilde x}\\) \\(x\\) intercept) Poisson regression weighted IPCW. Denote prediction \\(\\hat Y^{(r)}(\\boldsymbol{x})=\\text{exp}(\\hat \\beta_r \\boldsymbol{\\tilde x})\\). CATE score Poisson plug-estimator \\[\\widehat{CATE}_{Poisson}(\\boldsymbol{x})=\\text{log}\\left(\\frac{\\hat Y^{(1)}(\\boldsymbol{x})}{\\hat Y^{(0)}(\\boldsymbol{x})}\\right) = (\\hat \\beta_1 - \\hat \\beta_0) \\boldsymbol{\\tilde x}\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"boosting-1","dir":"Articles","previous_headings":"Theoretical details - Survival outcomes","what":"Boosting","title":"Theoretical details","text":"Estimate conditional mean RMTL given baseline covariates separately treatment group (.e., \\(\\mathbb{E}[Y^{(r)}|\\boldsymbol{x}]\\) \\(r \\\\{0,1\\}\\)) Poisson-based gradient boosting regression method weighted IPCW. Denote prediction \\(\\hat Y^{(r)}(\\boldsymbol{x})\\). number trees specificed argument n.trees.boosting. Default 200. depth trees specified argument tree.depth. Default 2. CATE score boosting plug-estimator \\[\\widehat{CATE}_{boosting}(\\boldsymbol{x})=\\text{log}\\left(\\frac{\\hat Y^{(1)}(\\boldsymbol{x})}{\\hat Y^{(0)}(\\boldsymbol{x})}\\right)\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"random-forest","dir":"Articles","previous_headings":"Theoretical details - Survival outcomes","what":"Random forest","title":"Theoretical details","text":"Estimate conditional mean RMTL given baseline covariates separately treatment group (.e., \\(\\mathbb{E}[Y^{(r)}|\\boldsymbol{x}]\\) \\(r \\\\{0,1\\}\\)) survival random forest. Denote prediction \\(\\hat Y^{(r)}(\\boldsymbol{x})\\). number trees boosting selected via CV maximum number trees specificed argument n.trees.rf. Default 1,000. base learners regression trees depth specified argument tree.depth. Default 2. CATE score boosting plug-estimator \\[\\widehat{CATE}_{boosting}(\\boldsymbol{x})=\\text{log}\\left(\\frac{\\hat Y^{(1)}(\\boldsymbol{x})}{\\hat Y^{(0)}(\\boldsymbol{x})}\\right)\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"two-regressions-1","dir":"Articles","previous_headings":"Theoretical details - Survival outcomes","what":"Two regressions","title":"Theoretical details","text":"Randomly separate data \\(D\\) \\(K\\) (Kfold) non-overlapping parts approximately equal sizes, \\(D_1, \\dots, D_K\\). fold \\(k=1,\\dots,K\\), separately treatment arm \\(r \\\\{0,1\\}\\): 2.1 Estimate conditional mean RMTL given baseline covariates Poisson-based gradient boosting regression method (initial.predictor.method = \"boosting\") based observations without kth fold, \\(D_{-k}\\), denote prediction \\(\\hat Y_{-k}^{(r)}(\\boldsymbol{x})\\). initial nonparametric prediction potential outcome. methods can used generate initial prediction (see initial.predictor.method argument). 2.2 Estimate propensity score model based \\(D_{-k}\\). Denote estimated PS \\(\\hat \\pi_{-k}(\\boldsymbol{x})\\) estimate weights \\(\\hat W_{-k}(r)=r\\frac{R}{\\hat \\pi_{-k}(\\boldsymbol{x})}+(1-r)\\frac{(1-R)}{1-\\hat \\pi_{-k}(\\boldsymbol{x})}\\) \\(R\\) denoting treatment received. 2.3 Estimate IPCW: \\[\\hat L(r,y) = \\frac{\\delta+(1-\\delta)(y^{(r)}\\geq\\tau)}{\\hat K_{C^{(r)}}(T \\wedge \\tau|x)}\\] \\(\\hat K_{C^{(r)}}(T \\wedge \\tau|x)\\) consistent estimator survival function censoring time given covariate \\(x\\), example, using Cox model Breslow estimator cumulative baseline hazard function (ipcw.method = \"breslow\"). 2.4 Solve following weighted estimating equation fitting Poisson regression \\(\\tau - (T\\wedge\\tau)\\) response, \\(\\text{log}(\\hat Y_{-k}^{(r)}(\\boldsymbol{x}))\\) \\(x\\) covariates, \\(\\hat K(r,y)\\times\\hat W_{-k}(r)\\) weight: \\[S(\\alpha_{rk}, \\boldsymbol{\\gamma_{rk}})=\\sum_{\\D_{-k}} \\hat K(r,y) \\hat W_{-k}(r) \\left((\\tau- T\\wedge\\tau) - \\text{exp}\\left(\\alpha_{rk}\\text{log} \\left(\\hat Y_{-k}^{(r)}(\\boldsymbol{x})\\right)+\\boldsymbol{\\gamma_{rk}^T}\\boldsymbol{\\tilde x}\\right)\\right)=0\\] Solve following doubly robust estimating equation fitting Poisson regression \\(\\text{exp}\\left(\\hat\\alpha_{rk}\\text{log}\\left(\\hat Y_{-k}^{(r)}(\\boldsymbol{x})\\right)+\\boldsymbol{\\hat\\gamma_{rk}^T\\boldsymbol{\\tilde x}}\\right)\\) response, \\(\\boldsymbol{x}\\) covariates, offset weight: \\[S(\\boldsymbol{\\beta_r})=\\sum_{k=1}^K \\sum_{\\D_{k}}\\boldsymbol{\\tilde x}\\left(\\text{exp}\\left(\\hat\\alpha_{rk}\\text{log}\\left(\\hat Y_{-k}^{(r)}(\\boldsymbol{x})\\right)+\\boldsymbol{\\hat\\gamma_{rk}^T\\boldsymbol{\\tilde x}}\\right)-\\text{exp}(\\boldsymbol{\\beta_r^T\\tilde x})\\right)=0\\] Denote estimator \\(\\boldsymbol{\\hat \\beta_r}\\). Repeat steps 1-3 \\(B\\) bootstrap samples (B) denote estimator \\(\\boldsymbol{\\hat \\beta_{rb}}\\) \\(b\\) sample. final estimator \\(\\boldsymbol{\\hat \\beta_r}\\) mean \\(\\boldsymbol{\\hat \\beta_{rb}}\\). CATE score two regression \\[\\widehat{CATE}_{tworeg}(\\boldsymbol{x})=(\\boldsymbol{\\hat \\beta_1} - \\boldsymbol{\\hat \\beta_0})^T\\boldsymbol{\\tilde x}\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"contrast-regression-1","dir":"Articles","previous_headings":"Theoretical details - Survival outcomes","what":"Contrast regression","title":"Theoretical details","text":"Randomly separate data \\(D\\) \\(K\\) (Kfold) non-overlapping parts approximately equal sizes, \\(D_1, \\dots, D_K\\). fold \\(k=1,\\dots,K\\), separately treatment arm \\(r \\\\{0,1\\}\\): 2.1 Estimate conditional mean RMTL given baseline covariates Poisson-based gradient boosting regression method (initial.predictor.method = \"boosting\") based observations without kth fold, \\(D_{-k}\\), denote prediction \\(\\hat Y_{-k}^{(r)}(\\boldsymbol{x})\\). initial nonparametric prediction potential outcome. methods can used generate initial prediction (see initial.predictor.method argument). 2.2 Estimate propensity score model based \\(D_{-k}\\). Denote estimated PS \\(\\hat \\pi_{-k}(\\boldsymbol{x})\\). 2.3 Estimate IPCW: \\[\\hat L(r,y) = \\frac{\\delta+(1-\\delta)(y^{(r)}\\geq\\tau)}{\\hat K_{C^{(r)}}(T \\wedge \\tau|x)}\\] \\(\\hat K_{C^{(r)}}(T \\wedge \\tau|x)\\) consistent estimator survival function censoring time given covariate \\(x\\), example, using Cox model Breslow estimator cumulative baseline hazard function (ipcw.method = \"breslow\"). Solve following doubly robust estimating equation Newton-Raphson method using L2-norm score method former fails converge: \\[\\begin{aligned} S(\\boldsymbol{\\delta})&=\\sum_{k=1}^K \\sum_{\\D_{k}} \\hat L(r,y) \\boldsymbol{\\tilde x}\\Bigg[\\frac{R\\left\\{(\\tau - T\\wedge\\tau)-\\text{exp}(\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x})\\hat Y_{-k}^{(0)}(\\boldsymbol{x})\\right\\}(1-\\hat\\pi_{-k}(\\boldsymbol{x}))}{\\text{exp}(\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x})\\hat\\pi_{-k}(\\boldsymbol{x})+1-\\hat\\pi_{-k}(\\boldsymbol{x})}\\\\ &-\\frac{(1-R)\\left\\{(\\tau - T\\wedge\\tau)-\\hat Y_{-k}^{(0)}(\\boldsymbol{ x}) \\right\\}\\text{exp}(\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x})\\hat\\pi_{-k}(\\boldsymbol{x})}{\\text{exp}(\\boldsymbol{\\delta^T}\\boldsymbol{\\tilde x})\\hat\\pi_{-k}(\\boldsymbol{x})+1-\\hat\\pi_{-k}(\\boldsymbol{x})}\\Bigg]=0 \\end{aligned}\\] Denote estimator \\(\\boldsymbol{\\hat\\delta}\\). Repeat steps 1-3 \\(B\\) bootstrap samples (B) denote estimator \\(\\boldsymbol{\\hat \\delta_b}\\) \\(b\\) sample. final estimator \\(\\boldsymbol{\\hat \\delta}\\) mean \\(\\boldsymbol{\\hat \\delta_b}\\). CATE score contrast regression \\[\\widehat{CATE}_{contrastreg}(\\boldsymbol{x})=\\boldsymbol{\\hat \\delta^T\\tilde x}\\]","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"validation-curves-and-the-abc-statistics-1","dir":"Articles","previous_headings":"Theoretical details - Survival outcomes","what":"Validation curves and the ABC statistics","title":"Theoretical details","text":"ABC statistic represents area validation curve ATE described (Zhao et al. 2013). single CV iteration certain CATE score method, implemented following training validation sets separately: Step 1. Calculate ATE training validation sets. Step 2. Calculate ATE 100 nested subgroups derive corresponding validation curve. Subgroups defined 100 equally-spaced proportions min(prop.cutoff) max(prop.cutoff) ensure enough data points available build validation curve. Step 3. ABC calculated auc() MESS R package using natural cubic spline interpolation, calculates area horizontal line y-intercept ATE calculated step 1 (y) validation curve calculated step 2 (x) range [min(prop.cutoff), max(prop.cutoff)]. function plot() allows user combining validation curves 2 CV iterations (.e., cv.n > 1). 2 ways combine validation curves: option combine =\"median\" takes median ATEs across CV iterations step 1 median ATEs 100 nested subgroups step 2. option combine =\"mean\" takes mean ATEs across CV iterations step 1 mean ATEs 100 nested subgroups step 2. either case, ABC calculations carried step 3 resulting x y. figure explains ABC calculated simple schema. ABC calculations larger positive ABC values always indicate treatment effect heterogeneity. implemented considering separately cases larger smaller outcomes preferred. smaller survival outcomes preferred (higher.y = FALSE, e.g., time positive event like recovery), validation curve ATE line decreases towards synonym treatment effect heterogeneity (top left figure). However, sections validation curve ATE line indicate inability capture treatment effect heterogeneity (bottom left figure). Hence, ABC defined subtracting areas ATE line areas ATE line larger positive ABC preferred. larger survival outcomes preferred (higher.y = TRUE, e.g., time negative event like symptom onset), validation curve (blue) ATE line (dashed) increases towards synonym treatment effect heterogeneity (top right figure). However, sections validation curve ATE line indicate inability capture treatment effect heterogeneity (bottom right figure). Hence, ABC defined subtracting areas ATE line (red) areas ATE line (green) larger positive ABC preferred.  ABC calculation examples relation higher.y argument catecv() catefit(). Validation curves represented blue line dashed line ATE.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/Theoretical-details.html","id":"other-precmed-vignettes-in-this-serie","dir":"Articles","previous_headings":"","what":"Other precmed vignettes in this serie","title":"Theoretical details","text":"1. Examples count outcome2. Examples survival outcome3. Additional examples4. Theoretical details","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/precmed.html","id":"general-introduction","dir":"Articles","previous_headings":"","what":"General introduction","title":"A general introduction","text":"precmed developed help researchers implementation precision medicine R. key objective precision medicine determine optimal treatment separately patient instead applying common treatment patients. Personalizing treatment decisions becomes particularly relevant treatment response differs across patients, patients different preferences benefits harms. package offers statistical methods develop validate prediction models estimating individualized treatment effects. treatment effects also known conditional average treatment effects (CATEs) describe different subgroups patients respond treatment. Presently, precmed focuses personalization two competitive treatments using randomized data clinical trial (Zhao et al. 2013) using real-world data (RWD) non-randomized study (Yadlowsky et al. 2020).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/precmed.html","id":"how-to-install","dir":"Articles","previous_headings":"General introduction","what":"How to install?","title":"A general introduction","text":"precmed package can installed CRAN follows: latest version can installed GitHub follows:","code":"install.packages(\"precmed\") install.packages(\"devtools\") devtools::install_github(repo = \"smartdata-analysis-and-statistics/precmed\")"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/precmed.html","id":"package-capabilities","dir":"Articles","previous_headings":"","what":"Package capabilities","title":"A general introduction","text":"precmed package contains functions Estimate average treatment effect (ATE) count survival outcome data using atefit() Estimate conditional average treatment effect (CATE) using catefit() Development Cross-validation CATE using catecv() Plot proportion subjects estimated treatment effect less \\(c\\) range values \\(c\\) (Zhao et al. 2013). Compute area average treatment difference curve competing models CATE using abc() (Zhao et al. 2013)","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/precmed.html","id":"recommended-workflow","dir":"Articles","previous_headings":"","what":"Recommended workflow","title":"A general introduction","text":"recommend following workflow develop model estimating CATE order identify treatment effect heterogeneity: Compare five modelling approaches (e.g., Poisson regression, boosting) estimating CATE using cross-validation catecv(). Compare steepness validation curves validation samples across methods using plot(). Two side--side plots generated, visualizing estimated average treatment effects series nested subgroups. left side curve shown training set, right side curve shown validation set. line plots represents one scoring method (e.g., boosting, randomForest) specified argument score.method. area curves (ABC) using abc() quantifies model’s ability capture treatment effect heterogeneity. Higher ABC values preferable indicate treatment effect heterogeneity captured scoring method. Compare distribution estimated ATE across different levels CATE score percentiles using boxplot(). Apply best modelling approach original data new external dataset using catefit(). Optional. Use atefit() estimate ATE 2 treatment groups doubly robust estimator estimate variability ATE bootstrap approach. vignettes, adopt different workflow gradually expose user simple complex methods.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/precmed.html","id":"user-input","dir":"Articles","previous_headings":"Recommended workflow","what":"User input","title":"A general introduction","text":"applying catefit() catecv(), user (least) input: response: type outcome/response (either count survival) data: data frame individual patient data score.method: methods estimate CATE (e.g., boosting, poisson, twoReg, contrastReg) cate.model: formula describing outcome model (e.g., outcome ~ age + gender + previous_treatment) ps.model: formula describing propensity score model adjust confounding (e.g., treatment ~ age + previous_treatment)","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/articles/precmed.html","id":"overview-of-the-vignettes","dir":"Articles","previous_headings":"","what":"Overview of the vignettes","title":"A general introduction","text":"1. General introduction2. Examples count outcome3. Examples survival outcome4. Additional examples5. Theoretical details","code":""},{"path":[]},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lu Tian. Author. Xiaotong Jiang. Author. Gabrielle Simoneau. Author. Biogen  MA  Inc.. Copyright holder. Thomas Debray. Contributor, maintainer. Stan Wijn. Contributor. Joana Caldas. Contributor.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Tian L, Jiang X, Simoneau G (2022). precmed: Precision Medicine. R package version 1.0.0.9000, https://smartdata-analysis--statistics.github.io/precmed/.","code":"@Manual{,   title = {precmed: Precision Medicine},   author = {Lu Tian and Xiaotong Jiang and Gabrielle Simoneau},   year = {2022},   note = {R package version 1.0.0.9000},   url = {https://smartdata-analysis-and-statistics.github.io/precmed/}, }"},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Precision Medicine","text":"precmed developed help researchers implementation precision medicine R. key objective precision medicine determine optimal treatment separately patient instead applying common treatment patients. Personalizing treatment decisions becomes particularly relevant treatment response differs across patients, patients different preferences benefits harms. package offers statistical methods develop validate prediction models estimating individualized treatment effects. treatment effects also known conditional average treatment effects (CATEs) describe different subgroups patients respond treatment. Presently, precmed focuses personalization two competitive treatments using randomized data clinical trial (Zhao et al. 2013) using real-world data (RWD) non-randomized study (Yadlowsky et al. 2020).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Precision Medicine","text":"precmed package can installed CRAN follows: latest version can installed GitHub follows:","code":"install.packages(\"precmed\") install.packages(\"devtools\") devtools::install_github(repo = \"smartdata-analysis-and-statistics/precmed\")"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/index.html","id":"package-capabilities","dir":"","previous_headings":"","what":"Package capabilities","title":"Precision Medicine","text":"main functions precmed package : info: https://smartdata-analysis--statistics.github.io/precmed/","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/index.html","id":"recommended-workflow","dir":"","previous_headings":"","what":"Recommended workflow","title":"Precision Medicine","text":"recommend following workflow develop model estimating CATE order identify treatment effect heterogeneity: Compare five modelling approaches (e.g., Poisson regression, boosting) estimating CATE using cross-validation catecv. Compare steepness validation curves validation samples across methods using plot(). Two side--side plots generated, visualizing estimated average treatment effects series nested subgroups. left side curve shown training set, right side curve shown validation set. line plots represents one scoring method (e.g., boosting, randomForest) specified argument score.method. area curves (ABC) using abc quantifies model’s ability capture treatment effect heterogeneity. Higher ABC values preferable indicate treatment effect heterogeneity captured scoring method. Compare distribution estimated ATE across different levels CATE score percentiles using boxplot(). Apply best modelling approach original data new external dataset using catefit(). Optional. Use atefit() estimate ATE 2 treatment groups doubly robust estimator estimate variability ATE bootstrap approach. vignettes, adopt different workflow gradually expose user simple complex methods.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/index.html","id":"user-input","dir":"","previous_headings":"","what":"User input","title":"Precision Medicine","text":"applying catefit() catecv(), user (least) input: response: type outcome/response (either count survival) data: data frame individual patient data score.method: methods estimate CATE (e.g., boosting, poisson, twoReg, contrastReg) cate.model: formula describing outcome model (e.g., outcome ~ age + gender + previous_treatment) ps.model: formula describing propensity score model adjust confounding (e.g., treatment ~ age + previous_treatment)","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"Precision Medicine","text":"Examples count outcome entire workflow Examples survival outcome entire workflow Additional examples precmed package Theoretical details","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the area between curves from the ","title":"Compute the area between curves from the ","text":"Compute area curves (ABC) scoring method \"precmed\" object. run results catecv() obtained.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the area between curves from the ","text":"","code":"abc(x)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the area between curves from the ","text":"x object class \"precmed\".","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the area between curves from the ","text":"Returns matrix numeric values number columns equal number cross-validation iteration number rows equal number scoring methods x.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the area between curves from the ","text":"ABC area validation curve overall ATE validation set. calculated scoring method separately. Higher ABC values preferable indicate treatment effect heterogeneity captured scoring method. Negative values ABC possible segments validation curve cross overall ATE line. ABC calculated auc() MESS package natural cubic spline interpolation. calculation ABC always based validation curves based 100 proportions equally spaced min(prop.cutoff) max(prop.cutoff). ABC metric help users select best scoring method terms capturing treatment effect heterogeneity data. used complement visual inspection validation curves validation set plot().","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the area between curves from the ","text":"Zhao, L., Tian, L., Cai, T., Claggett, B., & Wei, L. J. (2013). Effectively selecting target population future comparative study. Journal American Statistical Association, 108(502), 527-539.","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the area between curves from the ","text":"","code":"# \\donttest{ # Count outcome cv_count <- catecv(response = \"count\",                    data = countExample,                    score.method = \"poisson\",                    cate.model = y ~ age + female + previous_treatment +                                 previous_cost + previous_number_relapses +                                 offset(log(years)),                    ps.model = trt ~ age + previous_treatment,                    higher.y = FALSE, cv.n = 5, verbose = 1) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>  #> Total runtime : 36.13 secs   # ABC of the validation curves for each method and each CV iteration abc(cv_count) #>                cv1       cv2        cv3       cv4       cv5 #> poisson 0.06699602 0.1302821 0.04595802 0.1514754 0.1624266  # Survival outcome library(survival) cv_surv <- catecv(response = \"survival\",                   data = survivalExample,                   score.method = c(\"poisson\", \"randomForest\"),                   cate.model = Surv(y, d) ~ age + female + previous_cost +                                previous_number_relapses,                   ps.model = trt ~ age + previous_treatment,                   higher.y = FALSE,                   cv.n = 5) #> Warning: No value supplied for tau0. Default sets tau0 to the maximum survival time. #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.  # ABC of the validation curves for each method and each CV iteration abc(cv_surv) #>                    cv1       cv2       cv3       cv4       cv5 #> poisson      0.1899122 0.1911272 0.1670675 0.2002257 0.1687870 #> randomForest 0.1867659 0.1840971 0.1637781 0.1915414 0.1649163  # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.precmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the area between curves from the ","title":"Compute the area between curves from the ","text":"Compute area curves (ABC) scoring method \"precmed\" object. run results catecv() obtained.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.precmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the area between curves from the ","text":"","code":"# S3 method for precmed abc(x)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.precmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the area between curves from the ","text":"x object class \"precmed\".","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.precmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the area between curves from the ","text":"Returns matrix numeric values number columns equal number cross-validation iteration number rows equal number scoring methods x.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.precmed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute the area between curves from the ","text":"ABC area validation curve overall ATE validation set. calculated scoring method separately. Higher ABC values preferable indicate treatment effect heterogeneity captured scoring method. Negative values ABC possible segments validation curve cross overall ATE line. ABC calculated auc() MESS package natural cubic spline interpolation. calculation ABC always based validation curves based 100 proportions equally spaced min(prop.cutoff) max(prop.cutoff). ABC metric help users select best scoring method terms capturing treatment effect heterogeneity data. used complement visual inspection validation curves validation set plot().","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.precmed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute the area between curves from the ","text":"Zhao, L., Tian, L., Cai, T., Claggett, B., & Wei, L. J. (2013). Effectively selecting target population future comparative study. Journal American Statistical Association, 108(502), 527-539.","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/abc.precmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the area between curves from the ","text":"","code":"# \\donttest{ # Count outcome cv_count <- catecv(response = \"count\",                    data = countExample,                    score.method = \"poisson\",                    cate.model = y ~ age + female + previous_treatment +                                 previous_cost + previous_number_relapses +                                 offset(log(years)),                    ps.model = trt ~ age + previous_treatment,                    higher.y = FALSE, cv.n = 5, verbose = 1) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>  #> Total runtime : 19.3 secs   # ABC of the validation curves for each method and each CV iteration abc(cv_count) #>               cv1       cv2        cv3       cv4       cv5 #> poisson 0.1170984 0.1252604 0.09354729 0.1320252 0.1409233  # Survival outcome library(survival) cv_surv <- catecv(response = \"survival\",                   data = survivalExample,                   score.method = c(\"poisson\", \"randomForest\"),                   cate.model = Surv(y, d) ~ age + female + previous_cost +                                previous_number_relapses,                   ps.model = trt ~ age + previous_treatment,                   higher.y = FALSE,                   cv.n = 5) #> Warning: No value supplied for tau0. Default sets tau0 to the maximum survival time. #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.  # ABC of the validation curves for each method and each CV iteration abc(cv_surv) #>                    cv1       cv2       cv3       cv4       cv5 #> poisson      0.1830866 0.1895677 0.1566144 0.1812596 0.1616214 #> randomForest 0.1799391 0.1870554 0.1547334 0.1737235 0.1587918  # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/arg.checks.common.html","id":null,"dir":"Reference","previous_headings":"","what":"Check arguments that are common to all types of outcome\nUSed inside arg.checks() — arg.checks.common","title":"Check arguments that are common to all types of outcome\nUSed inside arg.checks() — arg.checks.common","text":"Check arguments common types outcome USed inside arg.checks()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/arg.checks.common.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check arguments that are common to all types of outcome\nUSed inside arg.checks() — arg.checks.common","text":"","code":"arg.checks.common(   fun,   ps.method,   minPS,   maxPS,   higher.y = NULL,   abc = NULL,   prop.cutoff = NULL,   prop.multi = NULL,   B = NULL,   Kfold = NULL,   plot.gbmperf = NULL,   tree.depth = NULL,   n.trees.boosting = NULL,   error.maxNR = NULL,   max.iterNR = NULL,   tune = NULL,   train.prop = NULL,   cv.n = NULL,   error.max = NULL,   max.iter = NULL,   n.boot = NULL,   plot.boot = NULL )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/arg.checks.common.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check arguments that are common to all types of outcome\nUSed inside arg.checks() — arg.checks.common","text":"fun function argument check needed; \"pm\" pmcount(), \"cv\" cvcount(), \"drinf\" drcount.inference(). default. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. n.boot numeric value indicating number bootstrap samples used. relevant inference = TRUE. Default 500. plot.boot logic value indicating whether histograms bootstrapped log(rate ratio) produced every n.boot/10-th iteration whether final histogram outputted. Default FALSE.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/arg.checks.common.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check arguments that are common to all types of outcome\nUSed inside arg.checks() — arg.checks.common","text":"Nothing. stop arguments incorrect.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/arg.checks.html","id":null,"dir":"Reference","previous_headings":"","what":"Check arguments\nCatered to all types of outcome\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","title":"Check arguments\nCatered to all types of outcome\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","text":"Check arguments Catered types outcome Apply beginning pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), drsurv.inference()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/arg.checks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check arguments\nCatered to all types of outcome\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","text":"","code":"arg.checks(   fun,   response,   data,   followup.time = NULL,   tau0 = NULL,   surv.min = NULL,   ipcw.method = NULL,   ps.method,   minPS,   maxPS,   higher.y = NULL,   score.method = NULL,   abc = NULL,   prop.cutoff = NULL,   prop.multi = NULL,   train.prop = NULL,   cv.n = NULL,   error.max = NULL,   max.iter = NULL,   initial.predictor.method = NULL,   tree.depth = NULL,   n.trees.rf = NULL,   n.trees.boosting = NULL,   B = NULL,   Kfold = NULL,   plot.gbmperf = NULL,   error.maxNR = NULL,   max.iterNR = NULL,   tune = NULL,   n.boot = NULL,   plot.boot = NULL,   interactions = NULL )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/arg.checks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check arguments\nCatered to all types of outcome\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","text":"fun function argument check needed; \"catefit\" catefitcount() catefitsurv(), \"crossv\" catecvcount() catecvsurv(), \"drinf\" drcount.inference() drsurv.inference(). default. response type response. Always 'survival' function. data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). followup.time Follow-time, interpreted potential censoring time. potential censoring time known, followup.time name corresponding column data. Otherwise, set followup.time == NULL. tau0 truncation time defining restricted mean time lost. surv.min Lower truncation limit probability censored (positive close 0). ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. Default specifies 5 methods. abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'randomForest', 'boosting' 'logistic' (fastest). Default 'randomForest'. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 150. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). n.boot numeric value indicating number bootstrap samples used. relevant inference = TRUE. Default 500. plot.boot logic value indicating whether histograms bootstrapped log(rate ratio) produced every n.boot/10-th iteration whether final histogram outputted. Default FALSE. interactions logical value indicating whether outcome model assume interactions x trt. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/arg.checks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check arguments\nCatered to all types of outcome\nApply at the beginning of pmcount(), cvcount(), drcount.inference(), catefitsurv(), catecvsurv(), and drsurv.inference() — arg.checks","text":"Nothing. stop arguments incorrect.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"Doubly robust estimator average treatment effect two treatments, rate ratio count outcomes, restricted mean time lost ratio survival outcomes mean difference continuous outcome. Bootstrap used inference.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"","code":"atefit(   response,   data,   cate.model,   ps.model,   ps.method = \"glm\",   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   surv.min = 0.025,   interactions = TRUE,   n.boot = 500,   seed = NULL,   verbose = 0 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"response string describing type outcome data. Allowed values include \"count\" (see catecvcount()), \"survival\" (see catecvsurv()) \"continuous\" (see catecvmean()). data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). cate.model formula describing outcome model fitted. outcome must appear left-hand side. survival outcomes, Surv object must used describe outcome. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. applies survival outcomes. Default NULL, corresponds specifying IPCW covariates outcome model cate.model, plus treatment. ipcw.method character value censoring model. applies survival outcomes. Allowed values : 'breslow' (Cox regression Breslow estimator t baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. applies survival outcomes. Default NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. applies survival outcomes. Default NULL, corresponds setting truncation time maximum survival time data. surv.min Lower truncation limit probability censored. must positive value chosen close 0. applies survival outcomes. Default 0.025. interactions logical value indicating whether outcome model assume interactions x trt. Applies count outcomes. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE. n.boot numeric value indicating number bootstrap samples used. Default 500. seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating whether intermediate progress messages histograms printed. 1 indicates messages printed 0 otherwise. Default 0.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"count response, see description outputs atefitcount(). survival response, see description outputs atefitsurv().","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"count response, see details atefitcount(). survival response, see details atefitsurv().","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly robust estimator of and inference for the average treatment effect for count, survival and continuous data — atefit","text":"","code":"# Count outcome output <- atefit(response = \"count\",                  data = countExample,                  cate.model = y ~ age + female + previous_treatment +                               previous_cost + previous_number_relapses +                               offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  n.boot = 50,                  seed = 999) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>  output #> Average treatment effect: #>  #>                  estimate        SE   CI.lower  CI.upper    pvalue #> log.rate.ratio 0.06311746 0.1624482 -0.2552752 0.3815101 0.6976173 #>  #> Estimated event rates: #>  #>        estimate #> rate1 0.2860635 #> rate0 0.2685660 #>  #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. plot(output)   # \\donttest{  # Survival outcome tau0 <- with(survivalExample,                  min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  output2 <- atefit(response = \"survival\",                   data = survivalExample,                   cate.model = survival::Surv(y, d) ~ age + female +                         previous_cost + previous_number_relapses,                         ps.model = trt ~ age + previous_treatment,                   tau0 = tau0,                   seed = 999) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>  output2 #> Average treatment effect: #>  #>                   estimate         SE    CI.lower CI.upper     pvalue #> log.rmtl.ratio   0.0701553 0.03420455 0.003115612 0.137195 0.04026192 #> log.hazard.ratio 2.7133243 0.20390310 2.313681567 3.112967 0.00000000 #>  #> Estimated RMST: #>  #>       estimate       SE CI.lower CI.upper pvalue #> rmst1 172.8609 6.774625 159.5829 186.1389      0 #> rmst0 196.5603 8.904742 179.1073 214.0132      0 #>  #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. plot(output2)   # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of and inference for the average treatment effect\nfor count data — atefitcount","title":"Doubly robust estimator of and inference for the average treatment effect\nfor count data — atefitcount","text":"Doubly robust estimator average treatment effect two treatments, rate ratio count outcomes. Bootstrap used inference.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of and inference for the average treatment effect\nfor count data — atefitcount","text":"","code":"atefitcount(   data,   cate.model,   ps.model,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   interactions = TRUE,   n.boot = 500,   seed = NULL,   verbose = 0 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of and inference for the average treatment effect\nfor count data — atefitcount","text":"data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0 1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value 0 1 estimated propensity scores truncated. Default 0.01. maxPS numerical value 0 1 estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. interactions logical value indicating whether outcome model assume treatment-covariate interaction x. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE. n.boot numeric value indicating number bootstrap samples used. Default 500. seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating whether intermediate progress messages printed. 1 indicates messages printed 0 otherwise. Default 0.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of and inference for the average treatment effect\nfor count data — atefitcount","text":"Return item class atefit following elements: log.rate.ratio:  vector numeric values estimated   ATE (expressed log rate ratio trt=1 trt=0),   bootstrap standard error, lower upper limits 95% confidence   interval, p-value. rate0:  numeric value estimated rate group   trt=0. rate1:  numeric value estimated rate group   trt=1. trt.boot:  Estimated log rate ratios bootstrap   sample. warning:  warning message produced treatment   variable coded 0 1. key map original coding   variable 0-1 coding displayed warning facilitate   interpretation remaining output.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitcount.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly robust estimator of and inference for the average treatment effect\nfor count data — atefitcount","text":"helper function estimates average treatment effect (ATE) two treatment groups given dataset. ATE estimated doubly robust estimator accounts imbalances covariate distributions two treatment groups inverse probability treatment weighting. count outcomes, estimated ATE estimated rate ratio treatment 1 versus treatment 0.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitcount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly robust estimator of and inference for the average treatment effect\nfor count data — atefitcount","text":"","code":"output <- atefitcount(data = countExample,                       cate.model = y ~ age + female + previous_treatment +                                    previous_cost + previous_number_relapses +                                    offset(log(years)),                       ps.model = trt ~ age + previous_treatment,                       verbose = 1, n.boot = 50, seed = 999) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0%   |                                                                               |=                                                                     |   2%   |                                                                               |===                                                                   |   4%   |                                                                               |====                                                                  |   6%   |                                                                               |======                                                                |   8%   |                                                                               |=======                                                               |  10%   |                                                                               |=========                                                             |  12%   |                                                                               |==========                                                            |  14%   |                                                                               |===========                                                           |  16%   |                                                                               |=============                                                         |  18%   |                                                                               |==============                                                        |  20%   |                                                                               |================                                                      |  22%   |                                                                               |=================                                                     |  24%   |                                                                               |===================                                                   |  27%   |                                                                               |====================                                                  |  29%   |                                                                               |=====================                                                 |  31%   |                                                                               |=======================                                               |  33%   |                                                                               |========================                                              |  35%   |                                                                               |==========================                                            |  37%   |                                                                               |===========================                                           |  39%   |                                                                               |=============================                                         |  41%   |                                                                               |==============================                                        |  43%   |                                                                               |===============================                                       |  45%   |                                                                               |=================================                                     |  47%   |                                                                               |==================================                                    |  49%   |                                                                               |====================================                                  |  51%   |                                                                               |=====================================                                 |  53%   |                                                                               |=======================================                               |  55%   |                                                                               |========================================                              |  57%   |                                                                               |=========================================                             |  59%   |                                                                               |===========================================                           |  61%   |                                                                               |============================================                          |  63%   |                                                                               |==============================================                        |  65%   |                                                                               |===============================================                       |  67%   |                                                                               |=================================================                     |  69%   |                                                                               |==================================================                    |  71%   |                                                                               |===================================================                   |  73%   |                                                                               |=====================================================                 |  76%   |                                                                               |======================================================                |  78%   |                                                                               |========================================================              |  80%   |                                                                               |=========================================================             |  82%   |                                                                               |===========================================================           |  84%   |                                                                               |============================================================          |  86%   |                                                                               |=============================================================         |  88%   |                                                                               |===============================================================       |  90%   |                                                                               |================================================================      |  92%   |                                                                               |==================================================================    |  94%   |                                                                               |===================================================================   |  96%   |                                                                               |===================================================================== |  98%   |                                                                               |======================================================================| 100% output #> Average treatment effect: #>  #>                  estimate        SE   CI.lower  CI.upper    pvalue #> log.rate.ratio 0.06311746 0.1624482 -0.2552752 0.3815101 0.6976173 #>  #> Estimated event rates: #>  #>        estimate #> rate1 0.2860635 #> rate0 0.2685660 #>  #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. plot(output)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of and inference for the average treatment effect for\ncontinuous data — atefitmean","title":"Doubly robust estimator of and inference for the average treatment effect for\ncontinuous data — atefitmean","text":"Doubly robust estimator average treatment effect two treatments, rate ratio treatment 1 treatment 0 count outcomes. Bootstrap used inference.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of and inference for the average treatment effect for\ncontinuous data — atefitmean","text":"","code":"atefitmean(   data,   cate.model,   ps.model,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   interactions = TRUE,   n.boot = 500,   plot.boot = FALSE,   seed = NULL,   verbose = 0 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of and inference for the average treatment effect for\ncontinuous data — atefitmean","text":"data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value 0 1 estimated propensity scores truncated. Default 0.01. maxPS numerical value 0 1 estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. interactions logical value indicating whether outcome model fitted separately treatment arm variables cate.model, equivalent assuming treatment-covariate interaction variables cate.model. TRUE, outcome model fitted separately treatment arms least 10 patients received treatment option. Default TRUE. n.boot numeric value indicating number bootstrap samples used. Default 500. plot.boot logical value indicating whether histograms bootstrapped treatment effect estimates produced every n.boot/10-th iteration whether final histogram outputted. Default FALSE. seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating whether intermediate progress messages histograms printed. 1 indicates messages printed 0 otherwise. Default 0.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of and inference for the average treatment effect for\ncontinuous data — atefitmean","text":"Return list 8 elements: log.rate.ratio:  numeric value estimated log rate ratio. se.boot.log.rate.ratio:  numeric value bootstrap standard error log rate ratio. rate.ratio:  numeric value estimated rate ratio. rate.ratio0:  numeric value estimated rate group trt=0. rate.ratio1:  numeric value estimated rate group trt=1. rate.ratio.CIl:  numeric value lower limit 95% bootstrap confidence interval     estimated rate ratio. rate.ratio.CIu:  numeric value upper limit 95% bootstrap confidence interval     estimated rate ratio. pvalue:  numeric value p-value derived bootstrapped values     based Chi-squared distribution. warning:  warning message produced treatment variable coded 0/1. key   map original coding variable 0/1 key displayed warning facilitate   interpretation remaining output. plot:  plot.boot TRUE, histogram displaying distribution bootstrapped log rate ratios.   red vertical reference line histogram represents estimated log rate ratio.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitmean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly robust estimator of and inference for the average treatment effect for\ncontinuous data — atefitmean","text":"helper function estimates average treatment effect (ATE) two  treatment groups given dataset specified y, trt, x.cate, x.ps, time. ATE  estimated doubly robust estimator accounts imbalances covariate distributions  two treatment groups inverse probability treatment weighting.  count outcomes, estimated ATE estimated  rate ratio treatment 1 versus treatment 0. original log-transformed ATEs  returned, well rate either treatment group.  inference = TRUE, variability estimated rate ratio also calculated  using bootstrap. Additional variability outputs include standard error log rate ratio,  95% confidence interval rate ratio, p-value, histogram log rate ratio.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitmean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly robust estimator of and inference for the average treatment effect for\ncontinuous data — atefitmean","text":"","code":"# This module is not implemented yet!"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"Doubly robust estimator average treatment effect two treatments, restricted mean time lost ratio survival outcomes. Bootstrap used inference.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"","code":"atefitsurv(   data,   cate.model,   ps.model,   ps.method = \"glm\",   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   surv.min = 0.025,   n.boot = 500,   seed = NULL,   verbose = 0 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). cate.model formula describing outcome model fitted. outcome must appear left-hand side. survival outcomes, Surv object must used describe outcome. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. applies survival outcomes. Default NULL, corresponds specifying IPCW covariates outcome model cate.model, plus treatment. ipcw.method character value censoring model. applies survival outcomes. Allowed values : 'breslow' (Cox regression Breslow estimator t baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. applies survival outcomes. Default NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. applies survival outcomes. Default NULL, corresponds setting truncation time maximum survival time data. surv.min Lower truncation limit probability censored. must positive value chosen close 0. applies survival outcomes. Default 0.025. n.boot numeric value indicating number bootstrap samples used. Default 500. seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating whether intermediate progress messages printed. 1 indicates messages printed 0 otherwise. Default 0.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"Return object class atefit 6 elements: rmst1:  vector numeric values estimated RMST, bootstrap standard error,   lower upper limits 95% confidence interval, p-value group trt=1. rmst0:  vector numeric values estimated RMST, bootstrap standard error,   lower upper limits 95% confidence interval, p-value group trt=0. log.rmtl.ratio:  vector numeric values estimated log RMTL ratio   trt=1 trt=0, bootstrap standard error, lower upper limits 95% confidence   interval, p-value. log.hazard.ratio:  vector numeric values estimated adjusted log hazard ratio   trt=1 trt=0, bootstrap standard error, lower upper limits 95% confidence   interval, p-value. trt.boot:  Estimates rmst1, rmst0,   log.rmtl.ratio log.hazard.ratio bootstrap sample. warning:  warning message produced treatment variable coded 0/1.   key map original coding variable 0/1 key displayed warning facilitate   interpretation remaining output.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"helper function estimates average treatment effect (ATE) survival data two treatment groups given dataset. ATE estimated doubly robust estimator accounts imbalances covariate distributions two treatment groups inverse probability treatment censoring weighting. survival outcomes, estimated ATE estimated RMTL ratio treatment 1 versus treatment 0. log-transformed ATEs log-transformed adjusted hazard ratios returned, well estimated RMST either treatment group. variability estimated RMTL ratio calculated using bootstrap. Additional outputs include standard error log RMTL ratio, 95% confidence interval, p-value, histogram bootstrap estimates.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/atefitsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly robust estimator of and inference for the average treatment effect for survival data — atefitsurv","text":"","code":"# \\donttest{ library(survival) tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  output <- atefitsurv(data = survivalExample,                      cate.model = Surv(y, d) ~ age + female +                                   previous_cost + previous_number_relapses,                      ps.model = trt ~ age + previous_treatment,                      tau0 = tau0,                      n.boot = 50,                      seed = 999,                      verbose = 1) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0%   |                                                                               |=                                                                     |   2%   |                                                                               |===                                                                   |   4%   |                                                                               |====                                                                  |   6%   |                                                                               |======                                                                |   8%   |                                                                               |=======                                                               |  10%   |                                                                               |=========                                                             |  12%   |                                                                               |==========                                                            |  14%   |                                                                               |===========                                                           |  16%   |                                                                               |=============                                                         |  18%   |                                                                               |==============                                                        |  20%   |                                                                               |================                                                      |  22%   |                                                                               |=================                                                     |  24%   |                                                                               |===================                                                   |  27%   |                                                                               |====================                                                  |  29%   |                                                                               |=====================                                                 |  31%   |                                                                               |=======================                                               |  33%   |                                                                               |========================                                              |  35%   |                                                                               |==========================                                            |  37%   |                                                                               |===========================                                           |  39%   |                                                                               |=============================                                         |  41%   |                                                                               |==============================                                        |  43%   |                                                                               |===============================                                       |  45%   |                                                                               |=================================                                     |  47%   |                                                                               |==================================                                    |  49%   |                                                                               |====================================                                  |  51%   |                                                                               |=====================================                                 |  53%   |                                                                               |=======================================                               |  55%   |                                                                               |========================================                              |  57%   |                                                                               |=========================================                             |  59%   |                                                                               |===========================================                           |  61%   |                                                                               |============================================                          |  63%   |                                                                               |==============================================                        |  65%   |                                                                               |===============================================                       |  67%   |                                                                               |=================================================                     |  69%   |                                                                               |==================================================                    |  71%   |                                                                               |===================================================                   |  73%   |                                                                               |=====================================================                 |  76%   |                                                                               |======================================================                |  78%   |                                                                               |========================================================              |  80%   |                                                                               |=========================================================             |  82%   |                                                                               |===========================================================           |  84%   |                                                                               |============================================================          |  86%   |                                                                               |=============================================================         |  88%   |                                                                               |===============================================================       |  90%   |                                                                               |================================================================      |  92%   |                                                                               |==================================================================    |  94%   |                                                                               |===================================================================   |  96%   |                                                                               |===================================================================== |  98%   |                                                                               |======================================================================| 100% output #> Average treatment effect: #>  #>                   estimate         SE    CI.lower  CI.upper     pvalue #> log.rmtl.ratio   0.0701553 0.03206484 0.007309376 0.1330012 0.02867542 #> log.hazard.ratio 2.7133243 0.20897752 2.303735883 3.1229127 0.00000000 #>  #> Estimated RMST: #>  #>       estimate       SE CI.lower CI.upper pvalue #> rmst1 172.8609 6.271374 160.5692 185.1526      0 #> rmst0 196.5603 7.753894 181.3629 211.7576      0 #>  #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. plot(output)  # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balance.split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split the given dataset into balanced training and validation sets\n(within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","title":"Split the given dataset into balanced training and validation sets\n(within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","text":"Split given dataset balanced training validation sets (within pre-specified tolerance) Balanced means 1) ratio treated controls maintained training validation sets                2) covariate distributions balanced training validation sets","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balance.split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split the given dataset into balanced training and validation sets\n(within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","text":"","code":"balance.split(   y,   trt,   x.cate,   x.ps,   time,   minPS = 0.01,   maxPS = 0.99,   train.prop = 3/4,   error.max = 0.1,   max.iter = 5000 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balance.split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split the given dataset into balanced training and validation sets\n(within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","text":"y Observed outcome; vector size n (observations) trt Treatment received; vector size n treatment coded 0/1 x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) time Log-transformed person-years follow-; vector size n minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balance.split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split the given dataset into balanced training and validation sets\n(within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balance.split","text":"list 10 objects, 5 training 5 validation y, trt, x.cate, x.ps, time:             y.train          - observed outcome training set; vector size m (observations training set)             trt.train        - treatment received training set; vector size m coded 0/1             x.cate.train     - baseline covariates outcome model training set; matrix dimension m p.cate x.ps.train       - baseline covariates (plus intercept) propensity score model training set; matrix dimension m p.ps + 1 time.train       - log-transformed person-years follow-training set; vector size m y.valid          - observed outcome validation set; vector size n-m trt.valid        - treatment received validation set; vector size n-m coded 0/1             x.cate.valid     - baseline covariates outcome model validation set; matrix dimension n-m p.cate x.ps.valid       - baseline covariates (plus intercept) propensity score model validation set; matrix dimension n-m p.ps + 1 time.valid       - log-transformed person-years follow-validation set; vector size n-m","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balancemean.split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","title":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","text":"Split given dataset balanced training validation sets (within pre-specified tolerance) Balanced means 1) ratio treated controls maintained training validation sets                2) covariate distributions balanced training validation sets","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balancemean.split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","text":"","code":"balancemean.split(   y,   trt,   x.cate,   x.ps,   minPS = 0.01,   maxPS = 0.99,   train.prop = 3/4,   error.max = 0.1,   max.iter = 5000 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balancemean.split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","text":"y Observed outcome; vector size n (observations) trt Treatment received; vector size n treatment coded 0/1 x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balancemean.split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split the given dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancemean.split","text":"list 10 objects, 5 training 5 validation y, trt, x.cate, x.ps, time:             y.train          - observed outcome training set; vector size m (observations training set)             trt.train        - treatment received training set; vector size m coded 0/1             x.cate.train     - baseline covariates outcome model training set; matrix dimension m p.cate x.ps.train       - baseline covariates (plus intercept) propensity score model training set; matrix dimension m p.ps + 1 y.valid          - observed outcome validation set; vector size n-m trt.valid        - treatment received validation set; vector size n-m coded 0/1             x.cate.valid     - baseline covariates outcome model validation set; matrix dimension n-m p.cate x.ps.valid       - baseline covariates (plus intercept) propensity score model validation set; matrix dimension n-m p.ps + 1 bestid.valid     - id validation set best split; vector size n-m","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balancesurv.split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","title":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","text":"Split given time--event dataset balanced training validation sets (within pre-specified tolerance) Balanced means 1) ratio treated controls maintained training validation sets                2) covariate distributions balanced training validation sets","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balancesurv.split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","text":"","code":"balancesurv.split(   y,   d,   trt,   x.cate,   x.ps,   x.ipcw,   yf = NULL,   train.prop = 3/4,   error.max = 0.1,   max.iter = 5000 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balancesurv.split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. trt Treatment received; vector size n treatment coded 0/1. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. unknown, set yf == NULL yf taken y function. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/balancesurv.split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split the given time-to-event dataset into balanced training and validation sets (within a pre-specified tolerance)\nBalanced means 1) The ratio of treated and controls is maintained in the training and validation sets\n               2) The covariate distributions are balanced between the training and validation sets — balancesurv.split","text":"list 14 objects, 7training 7 validation y, trt, x.cate, x.ps, x.ipcw, time, yf:             y.train          - observed survival censoring time training set; vector size m (observations training set)             d.train          - event indicator training set; vector size m coded 0/1             trt.train        - treatment received training set; vector size m coded 0/1             x.cate.train     - baseline covariates outcome model training set; matrix dimension m p.cate x.ps.train       - baseline covariates (plus intercept) propensity score model training set; matrix dimension m p.ps + 1 x.ipcw.train      - baseline covariates inverse probability censoring training set; matrix dimension m p.ipw yf.train         - follow-time training set; known, vector size m; unknown, yf == NULL y.valid          - observed survival censoring time validation set; vector size n-m d.valid          - event indicator validation set; vector size n-m coded 0/1             trt.valid        - treatment received validation set; vector size n-m coded 0/1             x.cate.valid     - baseline covariates outcome model validation set; matrix dimension n-m p.cate x.ps.valid       - baseline covariates (plus intercept) propensity score model validation set; matrix dimension n-m p.ps + 1 x.ipcw.valid      - baseline covariates inverse probability censoring validation set; matrix dimension n-m p.ipw yf.valid         - follow-time training set; known, vector size n-m; unknown, yf == NULL","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/boxplot.precmed.html","id":null,"dir":"Reference","previous_headings":"","what":"A set of box plots of estimated ATEs from the ","title":"A set of box plots of estimated ATEs from the ","text":"Provides box plots depict distributions estimated ATEs multi-category subgroup validation set across cross-validation iterations. subgroups mutually exclusive categorized CATE score percentiles (prop.multi specified catecv() catecvmean()). Box plots mutually exclusive subgroups constructed separately scoring method specified catecv(). run results catecv() catecvmean()) obtained.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/boxplot.precmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A set of box plots of estimated ATEs from the ","text":"","code":"# S3 method for precmed boxplot(   x,   ylab = NULL,   plot.hr = FALSE,   title = waiver(),   theme = theme_classic(),   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/boxplot.precmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A set of box plots of estimated ATEs from the ","text":"x object class \"precmed\". ylab character value y-axis label describe ATE . Default NULL, creates default y-axis label based available data. plot.hr logical value indicating whether hazard ratios plotted validation curves (TRUE). Otherwise, restricted mean time lost plotted (FALSE). argument applicable survival outcomes. Default FALSE. title text title theme Defaults theme_classic(). options include theme_grey(), theme_bw(), theme_light(), theme_dark(), theme_void() ... parameters","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/boxplot.precmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A set of box plots of estimated ATEs from the ","text":"Returns sets box plots, one set scoring method, multi-category subgroups. gray horizontal dashed line overall ATE included reference.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/boxplot.precmed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A set of box plots of estimated ATEs from the ","text":"boxplot() takes outputs catecv() generates box plots estimated ATEs multi-category subgroups validation set. box plots together overall ATE reference line can help compare scoring methods' ability distinguish subgroups patients different treatment effects. given scoring method, box plots showing increasing decreasing trends across multi-category subgroups indicate presence treatment effect heterogeneity (ability scoring method capture ). contrary, box plots relatively aligned across multi-category subgroups indicate absence treatment effect heterogeneity (inability scoring method capture ).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/boxplot.precmed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A set of box plots of estimated ATEs from the ","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/boxplot.precmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A set of box plots of estimated ATEs from the ","text":"","code":"# \\donttest{ # Count outcome eval_1 <- catecv(response = \"count\",                  data = countExample,                  score.method = \"poisson\",                  cate.model = y ~ age + female + previous_treatment +                                   previous_cost + previous_number_relapses +                                   offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  higher.y = FALSE,                  cv.n = 5) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.  boxplot(eval_1, ylab = \"Rate ratio of drug1 vs drug0 in each subgroup\")   # Survival outcome library(survival) tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95))) eval_2 <- catecv(response = \"survival\",                  data = survivalExample,                  score.method = c(\"poisson\", \"randomForest\"),                  cate.model = Surv(y, d) ~ age + female + previous_cost +                                            previous_number_relapses,                  ps.model = trt ~ age + previous_treatment,                  initial.predictor.method = \"randomForest\",                  ipcw.model = ~ age + previous_cost + previous_treatment,                  tau0 = tau0,                  higher.y = TRUE,                  cv.n = 5,                  seed = 999) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.  boxplot(eval_2, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") #> Warning: Removed 10 rows containing non-finite values (`stat_boxplot()`).  # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecv.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"Provides (doubly robust) estimation average treatment effect (ATE) count, survival continuous outcomes nested mutually exclusive subgroups patients defined estimated conditional average treatment effect (CATE) score via cross-validation (CV).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"","code":"catecv(   response,   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   init.model = NULL,   initial.predictor.method = NULL,   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   prop.multi = c(0, 1/3, 2/3, 1),   abc = TRUE,   train.prop = 3/4,   cv.n = 10,   error.max = 0.1,   max.iter = 5000,   surv.min = 0.025,   xvar.smooth.score = NULL,   xvar.smooth.init = NULL,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = TRUE,   verbose = 0 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"response string describing type outcome data. Allowed values include \"count\" (see catecvcount()), \"survival\" (see catecvsurv()) \"continuous\" (see catecvmean()) . data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'twoReg', 'contrastReg', 'poisson' (count survival outcomes ), 'randomForest' (survival, continuous outcomes ), negBin (count outcomes ), 'gam' (continuous outcomes ), 'gaussian' (continuous outcomes ). cate.model formula describing outcome model fitted. outcome must appear left-hand side. survival outcomes, Surv object must used describe outcome. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. initial.predictor.method character vector method used get initial outcome predictions conditional covariates specified cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'randomForest' (survival outcomes ), 'boosting', 'logistic' (survival outcomes , fast), 'poisson' (count outcomes , fast), 'gaussian' (continuous outcomes ) 'gam' (count continuous outcomes ). Default NULL, assigns 'boosting' count outcomes 'randomForest' survival outcomes. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. applies survival outcomes. Default NULL, corresponds specifying IPCW covariates outcome model cate.model, plus treatment. ipcw.method character value censoring model. applies survival outcomes. Allowed values : 'breslow' (Cox regression Breslow estimator t baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. applies survival outcomes. Default NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. applies survival outcomes. Default NULL, corresponds setting truncation time maximum survival time data. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. surv.min Lower truncation limit probability censored. must positive value chosen close 0. applies survival outcomes. Default 0.025. xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress bar run time. 2 means progress bar, run time, errors warnings. Default 0.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"count response, see description outputs catecvcount(). survival response, see description outputs catecvsurv(). continuous response, see description outputs catecvmean().","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"count response, see details catecvcount(). survival response, see details catecvsurv(). continuous response, see details catecvmean().","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of the conditional average treatment effect (CATE) score for count, survival or continuous outcomes — catecv","text":"","code":"# \\donttest{ cate_1 <- catecv(response = \"count\",                  data = countExample,                  score.method = \"poisson\",                  cate.model = y ~ age + female + previous_treatment +                               previous_cost + previous_number_relapses +                               offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  higher.y = FALSE, cv.n = 5, seed = 999, verbose = 1) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>  #> Total runtime : 17.96 secs   plot(cate_1, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\")  boxplot(cate_1, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\")  abc(cate_1) #>               cv1       cv2       cv3        cv4       cv5 #> poisson 0.1375899 0.1172791 0.1120313 0.06136285 0.1877103  # Survival outcome library(survival) tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  cate_2 <- catecv(response = \"survival\",                  data = survivalExample,                  score.method = c(\"poisson\", \"randomForest\"),                  cate.model = Surv(y, d) ~ age + female + previous_cost +                               previous_number_relapses,                  ps.model = trt ~ age + previous_treatment,                  initial.predictor.method = \"randomForest\",                  ipcw.model = ~ age + previous_cost + previous_treatment,                  tau0 = tau0,                  higher.y = TRUE,                  surv.min = 0.025,                  cv.n = 5,                  seed = 999) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.  plot(cate_2, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\")  boxplot(cate_2, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") #> Warning: Removed 10 rows containing non-finite values (`stat_boxplot()`).  abc(cate_2) #>                    cv1       cv2       cv3       cv4        cv5 #> poisson      0.2165482 0.2183456 0.1012403 0.2153617 0.09806659 #> randomForest 0.2251578 0.2014423 0.1480573 0.2431572 0.15568445   # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of the conditional average treatment effect (CATE) score\nfor count outcomes — catecvcount","title":"Cross-validation of the conditional average treatment effect (CATE) score\nfor count outcomes — catecvcount","text":"Provides doubly robust estimation average treatment effect (ATE) nested mutually exclusive subgroups patients defined estimated conditional average treatment effect (CATE) score via cross-validation (CV). CATE score can estimated 5 methods among following: Poisson regression, boosting, two regressions, contrast regression, negative binomial (see score.method).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of the conditional average treatment effect (CATE) score\nfor count outcomes — catecvcount","text":"","code":"catecvcount(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   initial.predictor.method = \"boosting\",   minPS = 0.01,   maxPS = 0.99,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   prop.multi = c(0, 1/3, 2/3, 1),   abc = TRUE,   train.prop = 3/4,   cv.n = 10,   error.max = 0.1,   max.iter = 5000,   xvar.smooth = NULL,   tree.depth = 2,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = TRUE,   verbose = 0,   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of the conditional average treatment effect (CATE) score\nfor count outcomes — catecvcount","text":"data data frame containing variables outcome propensity score model; data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0 1. data randomized trial, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'poisson' (fastest), 'boosting' 'gam'. Default 'boosting'. minPS numerical value 0 1 estimated propensity scores truncated. Default 0.01. maxPS numerical value 0 1 estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values 0 1 specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values 0 1 specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. train.prop numerical value 0 1 indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. xvar.smooth vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress bar run time. 2 means progress bar, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of the conditional average treatment effect (CATE) score\nfor count outcomes — catecvcount","text":"Returns list containing following components saved \"precmed\" object: ate.poisson: list results output score.method includes  'poisson': ate.est.train.high.cv: matrix numerical values     length(prop.cutoff) rows cv.n columns.     ith row/jth column cell contains estimated ATE nested subgroup high responders     defined CATE score (higher.y = TRUE) (higher.y = FALSE)     prop.cutoff[]x100% percentile estimated CATE score training set jth     cross-validation iteration. ate.est.train.low.cv: matrix numerical values     length(prop.cutoff) - 1 rows cv.n columns.     ith row/jth column cell contains estimated ATE nested subgroup low responders     defined CATE score (higher.y = TRUE) (higher.y = FALSE)     prop.cutoff[]x100% percentile estimated CATE score training set jth     cross-validation iteration. ate.est.valid.high.cv: ate.est.train.high.cv,     validation set. ate.est.valid.low.cv: ate.est.train.low.cv,     validation set. ate.est.train.group.cv: matrix numerical values     length(prop.multi) - 1 rows cv.n columns.     jth column contains estimated ATE length(prop.multi) - 1     mutually exclusive subgroups defined prop.multi training set jth     cross-validation iteration. ate.est.valid.group.cv: ate.est.train.group.cv,     validation set. abc.valid: vector numerical values length cv.n.     ith element returns ABC validation curve ith cross-validation     iteration. returned abc = TRUE. ate.boosting: list results similar ate.poisson output  score.method includes 'boosting'. ate.twoReg: list results similar ate.poisson output  score.method includes 'twoReg'. ate.contrastReg: list results similar ate.poisson output  score.method includes 'contrastReg'.  method additional element list results: converge.contrastReg.cv: vector logical value length cv.n.     ith element indicates whether algorithm converged ith cross-validation     iteration. ate.negBin: list results similar ate.poisson output  score.method includes 'negBin'. props: list 3 elements: prop.onlyhigh: original argument prop.cutoff,     reformatted necessary. prop.bi: original argument prop.cutoff,     similar prop.onlyhigh reformatted exclude 1. prop.multi: original argument prop.multi,     reformatted necessary include 0 1. overall.ate.valid: vector numerical values length cv.n.  ith element contains ATE validation set ith cross-validation  iteration, estimated doubly robust estimator. overall.ate.train: vector numerical values length cv.n.  ith element contains ATE training set ith cross-validation  iteration, estimated doubly robust estimator. fgam: formula used GAM initial.predictor.method = 'gam'. higher.y: original higher.y argument. abc: original abc argument. cv.n: original cv.n argument. response: type response. Always 'count' function. formulas:list 3 elements: (1) cate.model argument,  (2) ps.model argument (3) original labels left-hand side variable  ps.model (treatment) 0/1.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvcount.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of the conditional average treatment effect (CATE) score\nfor count outcomes — catecvcount","text":"CATE score represents individual-level treatment effect expressed rate ratio count outcomes. can estimated boosting, Poisson regression, negative binomial regression, doubly robust estimator two regressions (Yadlowsky, 2020) applied separately treatment group doubly robust estimator contrast regression (Yadlowsky, 2020) applied entire data set. Internal CV applied reduce optimism choosing CATE estimation method captures treatment effect heterogeneity. CV applied repeating following steps cv.n times: Split data training validation set according train.prop.  training validation sets must balanced respect covariate distributions  doubly robust rate ratio estimates (see error.max). Estimate CATE score training set specified scoring method. Predict CATE score validation set using scoring model fitted  training set. Build nested subgroups treatment responders training validation sets,  separately, estimate ATE within nested subgroup. element  prop.cutoff (e.g., prop.cutoff[] = 0.6), take following steps: Identify high responders observations 60%    (.e., prop.cutoff[]x100%) highest (higher.y = TRUE)    lowest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup high responders using doubly robust estimator. Conversely, identify low responders observations 40%    (.e., 1 - prop.cutoff[]x100%) lowest (higher.y = TRUE)    highest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup low responders using doubly robust estimator. abc = TRUE, calculate area ATE series ATEs  nested subgroups high responders validation set. Build mutually exclusive subgroups treatment responders training  validation sets, separately, estimate ATE within subgroup. Mutually exclusive  subgroups built splitting estimated CATE scores according prop.multi.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvcount.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of the conditional average treatment effect (CATE) score\nfor count outcomes — catecvcount","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvcount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of the conditional average treatment effect (CATE) score\nfor count outcomes — catecvcount","text":"","code":"# \\donttest{ catecv <- catecvcount(data = countExample,                       score.method = \"poisson\",                       cate.model = y ~ age + female + previous_treatment +                                    previous_cost + previous_number_relapses +                                    offset(log(years)),                       ps.model = trt ~ age + previous_treatment,                       higher.y = FALSE,                       cv.n = 5,                       seed = 999,                       plot.gbmperf = FALSE,                       verbose = 1) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>  #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>  #> Total runtime : 17.76 secs   plot(catecv, ylab = \"Rate ratio of drug1 vs drug0 in each subgroup\")  boxplot(catecv, ylab = \"Rate ratio of drug1 vs drug0 in each subgroup\")  abc(catecv) #>               cv1       cv2       cv3        cv4       cv5 #> poisson 0.1375899 0.1172791 0.1120313 0.06136285 0.1877103 # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"Provides doubly robust estimation average treatment effect (ATE) nested mutually exclusive subgroups patients defined estimated conditional average treatment effect (CATE) score via cross-validation (CV). CATE score can estimated 6 methods among following: Linear regression, boosting, two regressions, contrast regression, random forest generalized additive model (see score.method).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"","code":"catecvmean(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   init.model = NULL,   initial.predictor.method = \"boosting\",   minPS = 0.01,   maxPS = 0.99,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   prop.multi = c(0, 1/3, 2/3, 1),   abc = TRUE,   train.prop = 3/4,   cv.n = 10,   error.max = 0.1,   max.iter = 5000,   xvar.smooth.score = NULL,   xvar.smooth.init = NULL,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 6,   plot.gbmperf = TRUE,   error.maxNR = 0.001,   tune = c(0.5, 2),   seed = NULL,   verbose = 0,   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'poisson' (fastest), 'boosting' 'gam'. Default 'boosting'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress bar run time. 2 means progress bar, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"Returns list containing following components saved \"precmed\" object: ate.gaussian: list results output score.method includes  'gaussian': ate.est.train.high.cv: matrix numerical values     length(prop.cutoff) rows cv.n columns.     ith column/jth row cell contains estimated ATE nested subgroup high responders     defined CATE score (higher.y = TRUE) (higher.y = FALSE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. ate.est.train.low.cv: matrix numerical values     length(prop.cutoff) - 1 rows cv.n columns.     ith column/jth row cell contains estimated ATE nested subgroup low responders     defined CATE score (higher.y = TRUE) (higher.y = FALSE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. ate.est.valid.high.cv: ate.est.train.high.cv,     validation set. ate.est.valid.low.cv: ate.est.train.low.cv,     validation set. ate.est.train.group.cv: matrix numerical values     length(prop.multi) - 1 rows cv.n columns.     ith column contains estimated ATE length(prop.multi) - 1     mutually exclusive subgroups defined prop.multi training set ith     cross-validation iteration. ate.est.valid.group.cv: ate.est.train.group.cv,     validation set. abc.valid: vector numerical values length cv.n,     ith element returns ABC validation curve ith cross-validation     iteration. returned abc = TRUE. ate.boosting: list results similar ate.gaussian output  score.method includes 'boosting'. ate.twoReg: list results similar ate.gaussian output  score.method includes 'twoReg'. ate.contrastReg: list results similar ate.gaussian output  score.method includes 'contrastReg'. ate.randomForest: list results similar ate.gaussian output  score.method includes 'randomForest'. ate.gam: list results similar ate.gaussian output  score.method includes 'gam'. props: list 3 elements: prop.onlyhigh: original argument prop.cutoff,     reformatted necessary. prop.bi: original argument prop.cutoff,     similar prop.onlyhigh reformatted exclude 1. prop.multi: original argument prop.multi,     reformatted necessary. overall.ate.train: vector numerical values length cv.n.  ith element contains ATE training set ith cross-validation  iteration, estimated doubly robust estimator. overall.ate.valid: vector numerical values length cv.n.  ith element contains ATE validation set ith cross-validation  iteration, estimated doubly robust estimator. higher.y: original higher.y argument. abc: original abc argument. cv.n: original cv.n argument. response: type response. Always 'continuous' function. formulas:list 3 elements: (1) cate.model argument,  (2) ps.model argument (3) original labels left-hand side variable  ps.model (treatment) 0/1.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvmean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"CATE score represents individual-level treatment effect continuous data, estimated boosting, linear regression, random forest, generalized additive model doubly robust estimator (two regressions, Yadlowsky, 2020) applied separately treatment group doubly robust estimators (contrast regression, Yadlowsky, 2020) applied entire data set. Internal CV applied reduce optimism choosing CATE estimation method captures treatment effect heterogeneity. CV applied repeating following steps cv.n times: Split data training validation set according train.prop.  training validation sets must balanced respect covariate distributions  doubly robust rate ratio estimates (see error.max). Estimate CATE score training set specified scoring method. Predict CATE score validation set using scoring model fitted  training set. Build nested subgroups treatment responders training validation sets,  separately, estimate ATE within nested subgroup. element  prop.cutoff (e.g., prop.cutoff[] = 0.6), take following steps: Identify high responders observations 60%    (.e., prop.cutoff[]x100%) highest (higher.y = TRUE)    lowest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup high responders using doubly robust estimator. Conversely, identify low responders observations 40%    (.e., 1 - prop.cutoff[]x100%) lowest (higher.y = TRUE)    highest (higher.y = FALSE) estimated CATE scores. Estimate ATE subgroup low responders using doubly robust estimator. Build mutually exclusive subgroups treatment responders training  validation sets, separately, estimate ATE within subgroup. Mutually exclusive  subgroups built splitting estimated CATE scores according prop.multi. abc = TRUE, calculate area ATE series ATEs  nested subgroups high responders validation set.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvmean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvmean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of the conditional average treatment effect (CATE) score for continuous outcomes — catecvmean","text":"","code":"# Not implemented yet!"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"Provides doubly robust estimation average treatment effect (ATE) RMTL (restricted mean time lost) ratio nested mutually exclusive subgroups patients defined estimated conditional average treatment effect (CATE) score via cross-validation (CV). CATE score can estimated 5 methods among following: Random forest, boosting, poisson regression, two regressions, contrast regression (see score.method).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"","code":"catecvsurv(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   initial.predictor.method = \"randomForest\",   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   prop.multi = c(0, 1/3, 2/3, 1),   abc = TRUE,   train.prop = 3/4,   cv.n = 10,   error.max = 0.1,   max.iter = 5000,   surv.min = 0.025,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = TRUE,   verbose = 0 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'randomForest', 'boosting', 'poisson', 'twoReg', 'contrastReg'. cate.model standard Surv formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates specified cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'randomForest', 'boosting' 'logistic' (fastest). Default 'randomForest'. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. Default ipcw.model = NULL, corresponds specifying IPCW model covariates outcome model cate.model plus treatment. ipcw.method character value censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. Default followup.time = NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. Default NULL, corresponds setting truncation time maximum survival time data. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). abc logical value indicating whether area curves (ABC) calculated cross-validation iterations, score.method. Default TRUE. train.prop numerical value ((0, 1)) indicating proportion total data used training. Default 3/4. cv.n positive integer value indicating number cross-validation iterations. Default 10. error.max numerical value > 0 indicating tolerance (maximum value error) largest standardized absolute difference covariate distributions doubly robust estimated rate ratios training validation sets. used define balanced training-validation splitting. Default 0.1. max.iter positive integer value indicating maximum number iterations searching balanced training-validation split. Default 5,000. surv.min Lower truncation limit probability censored. must positive value chosen close 0. Default 0.025. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress bar run time. 2 means progress bar, run time, errors warnings. Default 0.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"Returns list containing following components saved \"precmed\" object: ate.randomForest: list ATE output measured RMTL ratio  score.method includes 'randomForest': ate.est.train.high.cv: matrix numerical values     length(prop.cutoff) rows cv.n columns.     ith column/jth row cell contains estimated ATE nested subgroup high responders     defined CATE score (higher.y = FALSE) (higher.y = TRUE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. ate.est.train.low.cv: matrix numerical values     length(prop.cutoff) - 1 rows cv.n columns.     TThe ith column/jth row cell contains estimated ATE nested subgroup low responders     defined CATE score (higher.y = FALSE) (higher.y = TRUE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. ate.est.valid.high.cv: ate.est.train.high.cv,     validation set. ate.est.valid.low.cv: ate.est.train.low.cv,     validation set. ate.est.train.group.cv: matrix numerical values     length(prop.multi) - 1 rows cv.n columns.     ith column contains estimated ATE length(prop.multi) - 1     mutually exclusive subgroups defined prop.multi training set ith     cross-validation iteration. ate.est.valid.group.cv: ate.est.train.group.cv,     validation set. abc.valid: vector numerical values length cv.n,     ith element returns ABC validation curve ith cross-validation     iteration. returned abc = TRUE. ate.boosting: list results similar ate.randomForest output  score.method includes 'boosting'. ate.poisson: list results similar ate.randomForest output  score.method includes 'poisson'. ate.twoReg: list results similar ate.randomForest output  score.method includes 'twoReg'. ate.contrastReg: list results similar ate.randomForest output  score.method includes 'contrastReg'.  method additional element list results: converge.contrastReg.cv: vector logical value length cv.n.     ith element indicates whether algorithm converged ith cross-validation     iteration. hr.randomForest: list adjusted hazard ratio score.method includes  'randomForest': hr.est.train.high.cv: matrix numerical values     length(prop.cutoff) rows cv.n columns.     ith column/jth row cell contains estimated HR nested subgroup high responders     defined CATE score (higher.y = FALSE) (higher.y = TRUE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. hr.est.train.low.cv: matrix numerical values     length(prop.cutoff) - 1 rows cv.n columns.     TThe ith column/jth row cell contains estimated HR nested subgroup low responders     defined CATE score (higher.y = FALSE) (higher.y = TRUE)     prop.cutoff[j]x100% percentile estimated CATE score training set ith     cross-validation iteration. hr.est.valid.high.cv: hr.est.train.high.cv,     validation set. hr.est.valid.low.cv: hr.est.train.low.cv,     validation set. hr.est.train.group.cv: matrix numerical values     length(prop.multi) - 1 rows cv.n columns.     ith column contains estimated HR length(prop.multi) - 1     mutually exclusive subgroups defined prop.multi training set ith     cross-validation iteration. hr.est.valid.group.cv: hr.est.train.group.cv,     validation set. hr.boosting: list results similar hr.randomForest output  score.method includes 'boosting'. hr.poisson: list results similar hr.randomForest output  score.method includes 'poisson'. hr.twoReg: list results similar hr.randomForest output  score.method includes 'twoReg'. hr.contrastReg: list results similar hr.randomForest output  score.method includes 'contrastReg'.  props: list 3 elements: prop.onlyhigh: original argument prop.cutoff,     reformatted necessary. prop.bi: original argument prop.cutoff,     similar prop.onlyhigh reformatted exclude 1. prop.multi: original argument prop.multi,     reformatted necessary include 0 1.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"CATE score represents individual-level treatment effect expressed restricted mean survival time (RMTL) ratio) survival outcomes. can estimated boosting, Poisson regression, random forest, doubly robust estimator two regressions (Yadlowsky, 2020) applied separately treatment group doubly robust estimator contrast regression (Yadlowsky, 2020) applied entire data set. Internal CV applied reduce optimism choosing CATE estimation method captures treatment effect heterogeneity. CV applied repeating following steps cv.n times: Split data training validation set according train.prop.  training validation sets must balanced respect covariate distributions  doubly robust RMTL ratio estimates (see error.max). Estimate CATE score training set specified scoring method. Predict CATE score validation set using scoring model fitted  training set. Build nested subgroups treatment responders training validation sets,  separately, estimate ATE within nested subgroup. element  prop.cutoff (e.g., prop.cutoff[] = 0.6), take following steps: Identify high responders observations 60%    (.e., prop.cutoff[]x100%) highest (higher.y = FALSE)    lowest (higher.y = TRUE) estimated CATE scores. Estimate ATE subgroup high responders using doubly robust estimator. Conversely, identify low responders observations 40%    (.e., 1 - prop.cutoff[]x100%) lowest (higher.y = FALSE)    highest (higher.y = TRUE) estimated CATE scores. Estimate ATE subgroup low responders using doubly robust estimator. abc = TRUE, calculate area ATE series ATEs  nested subgroups high responders validation set. Build mutually exclusive subgroups treatment responders training  validation sets, separately, estimate ATE within subgroup. Mutually exclusive  subgroups built splitting estimated CATE scores according prop.multi.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catecvsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation of the conditional average treatment effect (CATE) score for survival outcomes — catecvsurv","text":"","code":"# \\donttest{ library(survival)  tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  catecv <- catecvsurv(data = survivalExample,                      score.method = \"poisson\",                      cate.model = Surv(y, d) ~ age + female + previous_cost +                                                previous_number_relapses,                      ps.model = trt ~ age + previous_treatment,                      initial.predictor.method = \"logistic\",                      ipcw.model = ~ age + previous_cost + previous_treatment,                      tau0 = tau0,                      higher.y = TRUE,                      cv.n = 5, seed = 999, verbose = 1) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #>    |                                                                               |                                                                      |   0% #> cv = 1  #>   splitting the data.. #>   training.. #>   validating.. #>    Mon Dec 12 15:10:43 2022  #>    |                                                                               |==============                                                        |  20% #> cv = 2  #>   splitting the data.. #>   training.. #>   validating.. #>    Mon Dec 12 15:10:52 2022  #>    |                                                                               |============================                                          |  40% #> cv = 3  #>   splitting the data.. #>   training.. #>   validating.. #>    Mon Dec 12 15:11:02 2022  #>    |                                                                               |==========================================                            |  60% #> cv = 4  #>   splitting the data.. #>   training.. #>   validating.. #>    Mon Dec 12 15:11:12 2022  #>    |                                                                               |========================================================              |  80% #> cv = 5  #>   splitting the data.. #>   training.. #>   validating.. #>    Mon Dec 12 15:11:21 2022  #>    |                                                                               |======================================================================| 100% #> Total runtime : 48.05 secs   # Try: plot(catecv, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\")  boxplot(catecv, ylab = \"RMTL ratio of drug1 vs drug0 in each subgroup\") #> Warning: Removed 4 rows containing non-finite values (`stat_boxplot()`).  abc(catecv) #>               cv1       cv2       cv3       cv4        cv5 #> poisson 0.2165482 0.1988858 0.2184554 0.2111615 0.09635128 # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"Provides singly robust doubly robust estimation CATE score count, survival continuous data following scoring methods among following: Random forest (survival, continuous ), boosting, poisson regression (count, survival ), two regressions, contrast regression, negative binomial regression (count ), linear regression (continuous ), generalized additive model (continuous ).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"","code":"catefit(   response,   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   init.model = NULL,   initial.predictor.method = NULL,   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   surv.min = 0.025,   xvar.smooth.score = NULL,   xvar.smooth.init = NULL,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = TRUE,   verbose = 0,   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"response string describing type outcome data. Allowed values include \"count\" (see catecvcount()), \"survival\" (see catecvsurv()) \"continuous\" (see catecvmean()). data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'twoReg', 'contrastReg', 'poisson' (count survival outcomes ), 'randomForest' (survival, continuous outcomes ), negBin (count outcomes ), 'gam' (continuous outcomes ), 'gaussian' (continuous outcomes ). cate.model formula describing outcome model fitted. outcome must appear left-hand side. survival outcomes, Surv object must used describe outcome. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. initial.predictor.method character vector method used get initial outcome predictions conditional covariates specified cate.model. applies score.method includes 'twoReg' 'contrastReg'.Allowed values include one 'randomForest' (survival outcomes ), 'boosting', 'logistic' (survival outcomes , fast), 'poisson' (count outcomes , fast), 'gaussian' (continuous outcomes ) 'gam' (count continuous outcomes ). Default NULL, assigns 'boosting' count outcomes 'randomForest' survival outcomes. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. applies survival outcomes. Default NULL, corresponds specifying IPCW covariates outcome model cate.model, plus treatment. ipcw.method character value censoring model. applies survival outcomes. Allowed values : 'breslow' (Cox regression Breslow estimator t baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. applies survival outcomes. Default NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. applies survival outcomes. Default NULL, corresponds setting truncation time maximum survival time data. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). surv.min Lower truncation limit probability censored. must positive value chosen close 0. applies survival outcomes. Default 0.025. xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating whether intermediate progress messages histograms printed. 1 indicates messages printed 0 otherwise. Default 0. ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"count response, see description outputs catefitcount(). survival response, see description outputs catefitsurv().","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"count response, see details catefitcount(). survival response, see details catefitsurv().","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the conditional average treatment effect (CATE) score for count, survival and continuous data — catefit","text":"","code":"# Count outcome fit_1 <- catefit(response = \"count\",                  data = countExample,                  score.method = \"poisson\",                  cate.model = y ~ age + female + previous_treatment +                                   previous_cost + previous_number_relapses +                                   offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  higher.y = TRUE,                  seed = 999) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.  coef(fit_1) #>                              poisson #> (Intercept)              -0.58185218 #> age                      -0.01117701 #> female                    0.58829733 #> previous_treatmentdrugB   0.73724361 #> previous_treatmentdrugC   0.15545985 #> previous_cost            -0.13035642 #> previous_number_relapses -0.05339112  # \\donttest{ # Survival outcome library(survival) tau0 <- with(survivalExample,                  min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95)))  fit_2 <- catefit(response = \"survival\",                  data = survivalExample,                  score.method = c(\"poisson\", \"boosting\", \"randomForest\"),                  cate.model = Surv(y, d) ~ age + female + previous_cost +                                            previous_number_relapses,                  ps.model = trt ~ age + previous_treatment,                  initial.predictor.method = \"logistic\",                  ipcw.model = ~ age + previous_cost + previous_treatment,                  tau0 = tau0, higher.y = TRUE, seed = 999, n.cores = 1) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #> Loaded gbm 2.1.8.1 #> CV: 1  #> CV: 2  #> CV: 3  #> CV: 4  #> CV: 5   #> CV: 1  #> CV: 2  #> CV: 3  #> CV: 4  #> CV: 5    coef(fit_2) #>                              poisson #> (Intercept)               0.46109243 #> age                      -0.24335209 #> female                    0.12532711 #> previous_cost             0.89803249 #> previous_number_relapses -0.02470863  # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"Provides singly robust doubly robust estimation CATE score 5 scoring methods among following: Poisson regression, boosting, two regressions, contrast regression, negative binomial.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"","code":"catefitcount(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   initial.predictor.method = \"boosting\",   minPS = 0.01,   maxPS = 0.99,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   xvar.smooth = NULL,   tree.depth = 2,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   seed = NULL,   plot.gbmperf = FALSE,   verbose = 0,   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"data data frame containing variables outcome propensity score model; data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized trial, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'poisson' (fastest), 'boosting' 'gam'. Default 'boosting'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). xvar.smooth vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress run time. 2 means progress, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"Returns list containing following components: ate.poisson: vector numerical values length prop.cutoff  containing estimated ATE nested subgroups (defined prop.cutoff)  constructed based estimated CATE scores poisson regression.  provided score.method includes 'poisson'. ate.boosting: ate.poisson, nested subgroups based  estimated CATE scores boosting. provided score.method  includes 'boosting'. ate.twoReg: ate.poisson, nested subgroups based  estimated CATE scores two regressions.  provided score.method includes 'twoReg'. ate.contrastReg: ate.poisson, nested subgroups based  estimated CATE scores contrast regression.  provided score.method includes 'contrastReg'. ate.negBin: ate.poisson, nested subgroups based  estimated CATE scores negative binomial regression.  provided score.method includes 'negBin'. score.poisson: vector numerical values length n  (number observations data) containing estimated log-CATE scores  according Poisson regression. provided score.method  includes 'poisson'. score.boosting: score.poisson, estimated log-CATE score  according boosting. provided score.method includes  'boosting'. score.twoReg: score.poisson, estimated log-CATE score  according two regressions. provided score.method includes  'twoReg'. score.contrastReg: score.poisson, estimated log-CATE score  according contrast regression. provided score.method includes  'contrastReg'. score.negBin: score.poisson, estimated log-CATE score  according negative binomial regression. provided score.method  includes 'negBin'. fit: Additional details model fitting score.method  includes 'boosting' 'contrastReg': result.boosting: Details boosting model fitted observations    treatment = 0 ($fit0.boosting) observations treatment = 1 ($fit1.boosting).    provided score.method includes 'boosting'. result.contrastReg$sigma.contrastReg: Variance-covariance matrix    estimated log-CATE coefficients contrast regression.    provided score.method includes 'contrastReg'. coefficients: data frame coefficients estimated log-CATE  score score.method. data frame number rows equal number  covariates cate.model number columns equal length(score.method).  score.method includes 'contrastReg', data frame additional  column containing standard errors coefficients estimated contrast regression.  'boosting' coefficient results tree-based methods typically  express log-CATE linear combination coefficients covariates.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitcount.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"CATE score represents individual-level treatment effect, estimated either Poisson regression, boosting negative binomial regression applied separately treatment group two doubly robust estimators, two regressions contrast regression (Yadlowsky, 2020) applied entire dataset. catefitcount() provides coefficients CATE score scoring method requested score.method. Currently, contrast regression method allows inference CATE coefficients providing standard errors coefficients. coefficients can used learn effect size variable predict CATE score new observation. catefitcount() also provides predicted CATE score observation data set, scoring method. predictions allow ranking observations potentially high responders treatment potentially low standard responders. estimated ATE among nested subgroups high responders also provided scoring method. Note ATEs catefitcount() derived based CATE score estimated using data sample. Therefore, overfitting may issue. catecvcount() suitable inspect estimated ATEs across scoring methods implements internal cross validation reduce optimism.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitcount.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitcount.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the conditional average treatment effect (CATE) score for count data — catefitcount","text":"","code":"fit <- catefitcount(data = countExample,                     score.method = \"poisson\",                     cate.model = y ~ age + female + previous_treatment +                                  previous_cost + previous_number_relapses +                                  offset(log(years)),                     ps.model = trt ~ age + previous_treatment,                     higher.y = FALSE,                     seed = 999, verbose = 1) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1. #> Total runtime : 0.22 secs"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"Provides singly robust doubly robust estimation CATE score 6 scoring methods among following: Linear regression, boosting, two regressions, contrast regression, random forest generalized additive model.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"","code":"catefitmean(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   init.model = NULL,   initial.predictor.method = \"boosting\",   minPS = 0.01,   maxPS = 0.99,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   xvar.smooth.score = NULL,   xvar.smooth.init = NULL,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 6,   plot.gbmperf = FALSE,   error.maxNR = 0.001,   tune = c(0.5, 2),   seed = NULL,   verbose = 0,   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model specified ps.model). init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. initial.predictor.method character vector method used get initial outcome predictions conditional covariates init.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'gaussian' (fastest), 'boosting' 'gam'. Default 'boosting'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.rf positive integer specifying number trees. Used score.method = 'randomForest'. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress run time. 2 means progress, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"Returns list containing following components: ate.gaussian: vector numerical values length prop.cutoff  containing estimated ATE nested subgroups (defined prop.cutoff)  constructed based estimated CATE scores Poisson regression.  provided score.method includes 'gaussian'. ate.boosting: ate.gaussian, nested subgroups based  estimated CATE scores boosting. provided score.method  includes 'boosting'. ate.twoReg: ate.gaussian, nested subgroups based  estimated CATE scores two regressions.  provided score.method includes 'twoReg'. ate.contrastReg: ate.gaussian, nested subgroups based  estimated CATE scores contrast regression.  provided score.method includes 'contrastReg'. ate.randomForest: ate.gaussian, nested subgroups based  estimated CATE scores random forest.  provided score.method includes 'gam'. ate.gam: ate.gaussian, nested subgroups based  estimated CATE scores generalized additive model.  provided score.method includes 'gam'. score.gaussian: vector numerical values length n  (number observations data) containing estimated CATE scores  according linear regression. provided score.method  includes 'gaussian'. score.boosting: score.gaussian, estimated CATE score  according boosting. provided score.method includes  'boosting'. score.twoReg: score.gaussian, estimated CATE score  according two regressions. provided score.method includes  'twoReg'. score.contrastReg: score.gaussian, estimated CATE score  according contrast regression. provided score.method includes  'contrastReg'. score.randomForest: score.gaussian, estimated CATE score  according random forest. provided score.method  includes 'randomForest'. score.gam: score.gaussian, estimated CATE score  according generalized additive model. provided score.method  includes 'gam'. fit: Additional details model fitting score.method  includes 'boosting' 'contrastReg': result.boosting: Details boosting model fitted observations    treatment = 0 ($fit0.boosting) observations treatment = 1 ($fit1.boosting).    provided score.method includes 'boosting'. result.randomForest: Details boosting model fitted observations    treatment = 0 ($fit0.randomForest) observations treatment = 1 ($fit1.randomForest).    provided score.method includes 'randomForest'. result.gam: Details boosting model fitted observations    treatment = 0 ($fit0.gam) observations treatment = 1 ($fit1.gam).    provided score.method includes 'gam'. result.contrastReg$sigma.contrastReg: Variance-covariance matrix    estimated CATE coefficients contrast regression.    provided score.method includes 'contrastReg'. coefficients: data frame coefficients estimated CATE  score score.method. data frame number rows equal number  covariates cate.model number columns equal length(score.method).  score.method includes 'contrastReg', data frame additional  column containing standard errors coefficients estimated contrast regression.  'boosting', 'randomForest', 'gam' coefficient results methods  express CATE linear combination coefficients covariates.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitmean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"CATE score represents individual-level treatment effect, estimated either linear regression, boosting, random forest generalized additive model applied separately treatment group two doubly robust estimators, two regressions contrast regression (Yadlowsky, 2020) applied entire dataset. catefitmean() provides coefficients CATE score scoring method requested score.method. Currently, contrast regression method allows inference CATE coefficients providing standard errors coefficients. coefficients can used learn effect size variable predict CATE score new observation. catefitmean() also provides predicted CATE score observation data set, scoring method. predictions allow ranking observations potentially high responders treatment potentially low standard responders. estimated ATE among nested subgroups high responders also provided scoring method. Note ATEs catefitmean() derived based CATE score estimated using data sample. Therefore, overfitting may issue. catefitmean() suitable inspect estimated ATEs across scoring methods implements internal cross validation reduce optimism.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitmean.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the conditional average treatment effect (CATE) score for continuous data — catefitmean","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"Provides singly robust doubly robust estimation CATE score survival data 5 scoring methods among following: Random forest, boosting, poisson regression, two regressions, contrast regression.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"","code":"catefitsurv(   data,   score.method,   cate.model,   ps.model,   ps.method = \"glm\",   initial.predictor.method = \"randomForest\",   ipcw.model = NULL,   ipcw.method = \"breslow\",   minPS = 0.01,   maxPS = 0.99,   followup.time = NULL,   tau0 = NULL,   higher.y = TRUE,   prop.cutoff = seq(0.5, 1, length = 6),   surv.min = 0.025,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 3,   Kfold = 5,   plot.gbmperf = TRUE,   error.maxNR = 0.001,   max.iterNR = 100,   tune = c(0.5, 2),   seed = NULL,   verbose = 0,   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"data data frame containing variables outcome, propensity score, inverse probability censoring models (specified); data frame n rows (1 row per observation). score.method vector one multiple methods estimate CATE score. Allowed values : 'randomForest', 'boosting', 'poisson', 'twoReg', 'contrastReg'. cate.model standard Surv formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score (PS) model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data randomized controlled trial, specify ps.model = ~1 intercept-model. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates specified cate.model. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'randomForest', 'boosting' 'logistic' (fastest). Default 'randomForest'. ipcw.model formula describing inverse probability censoring weighting (IPCW) model fitted. left-hand side must empty. Default ipcw.model = NULL, corresponds specifying IPCW model covariates outcome model cate.model plus treatment. ipcw.method character value censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)' (accelerated failure time model different distributions y variable). Default 'breslow'. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. followup.time column name data specifying maximum follow-time, interpreted potential censoring time. Default followup.time = NULL, corresponds unknown potential censoring time. tau0 truncation time defining restricted mean time lost. Default NULL, corresponds setting truncation time maximum survival time data. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). surv.min Lower truncation limit probability censored. must positive value chosen close 0. Default 0.025. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 2. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. applies survival outcomes. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). seed optional integer specifying initial randomization seed reproducibility. Default NULL, corresponding seed. verbose integer value indicating kind intermediate progress messages printed. 0 means outputs. 1 means progress run time. 2 means progress, run time, errors warnings. Default 0. ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"Returns object class catefit containing following components: ate.randomForest: vector numerical values length prop.cutoff  containing estimated ATE RMTL ratio nested subgroups (defined prop.cutoff)  constructed based estimated CATE scores random forest method.  provided score.method includes 'randomForest'. ate.boosting: ate.randomForest, nested subgroups based  estimated CATE scores boosting. provided score.method  includes 'boosting'. ate.poisson: ate.randomForest, nested subgroups based  estimated CATE scores poisson regression.  provided score.method includes 'poisson'. ate.twoReg: ate.randomForest, nested subgroups based  estimated CATE scores two regressions.  provided score.method includes 'twoReg'. ate.contrastReg: ate.randomForest, nested subgroups based  estimated CATE scores contrast regression.  provided score.method includes 'contrastReg'. hr.randomForest: vector numerical values length prop.cutoff  containing adjusted hazard ratio nested subgroups (defined prop.cutoff)  constructed based estimated CATE scores random forest method.  provided score.method includes 'randomForest'. hr.boosting: hr.randomForest, nested subgroups based  estimated CATE scores boosting. provided score.method  includes 'boosting'. hr.poisson: hr.randomForest, nested subgroups based  estimated CATE scores poisson regression.  provided score.method includes 'poisson'. hr.twoReg: hr.randomForest, nested subgroups based  estimated CATE scores two regressions.  provided score.method includes 'twoReg'. hr.contrastReg: hr.randomForest, nested subgroups based  estimated CATE scores contrast regression.  provided score.method includes 'contrastReg'. score.randomForest: vector numerical values length n  (number observations data) containing estimated log-CATE scores  according random forest. provided score.method  includes 'randomForest'. score.boosting: score.randomForest, estimated log-CATE score  according boosting. provided score.method includes  'boosting'. score.poisson: score.randomForest, estimated log-CATE score  according Poisson regression. provided score.method  includes 'poisson'. score.twoReg: score.randomForest, estimated log-CATE score  according two regressions. provided score.method includes  'twoReg'. score.contrastReg: score.randomForest, estimated log-CATE score  according contrast regression. provided score.method includes  'contrastReg'. fit: Additional details model fitting score.method  includes 'randomForest', 'boosting' 'contrastReg': result.randomForest: Details random forest model fitted observations    treatment = 0 ($fit0.rf) observations treatment = 1 ($fit1.rf).    provided score.method includes 'randomForest'. result.boosting: Details boosting model fitted observations    treatment = 0, ($fit0.boosting) ($fit0.gam) observations treatment = 1,    ($fit1.boosting) ($fit1.gam).    provided score.method includes 'boosting'. result.contrastReg$converge.contrastReg: Whether contrast regression algorithm converged    . provided score.method includes 'contrastReg'. coefficients: data frame coefficients estimated log-CATE  score score.method. data frame number rows equal number  covariates cate.model number columns equal length(score.method).  score.method includes 'contrastReg', data frame additional  column containing standard errors coefficients estimated contrast regression.  'randomForest' 'boosting' coefficient results  tree-based methods typically express log-CATE linear combination coefficients  covariates. errors/warnings: nested list errors warnings wrapped  calculation ATE. Errors warnings organized score.method.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitsurv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"CATE score represents individual-level treatment effect survival data, estimated random forest, boosting, Poisson regression, doubly robust estimator (two regressions, Yadlowsky, 2020) applied separately treatment group doubly robust estimators (contrast regression, Yadlowsky, 2020) applied entire data set. catefitsurv() provides coefficients CATE score scoring method requested score.method. Currently, contrast regression method allows inference CATE coefficients providing standard errors coefficients. coefficients can used learn effect size variable predict CATE score new observation. catefitsurv() also provides predicted CATE score observation data set, scoring method. predictions allow ranking observations potentially high responders treatment potentially low standard responders. estimated ATE among nested subgroups high responders also provided scoring method. Note ATEs catefitsurv() derived based CATE score estimated using data sample. Therefore, overfitting may issue. catecvsurv() suitable inspect estimated ATEs across scoring methods implements internal cross validation reduce optimism.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitsurv.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/catefitsurv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of the conditional average treatment effect (CATE) score for survival data — catefitsurv","text":"","code":"# \\donttest{ library(survival)  tau0 <- with(survivalExample, min(quantile(y[trt == \"drug1\"], 0.95),                                quantile(y[trt == \"drug0\"], 0.95)))  fit <- catefitsurv(data = survivalExample,                    score.method = \"randomForest\",                    cate.model = Surv(y, d) ~ age + female + previous_cost +                                              previous_number_relapses,                    ps.model = trt ~ age + previous_treatment,                    ipcw.model = ~ age + previous_cost + previous_treatment,                    tau0 = tau0,                    seed = 999) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.  coef(fit) #> NULL # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/countExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data with count outcome — countExample","title":"Simulated data with count outcome — countExample","text":"dataset containing count outcome, length follow-6 baseline covariates","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/countExample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated data with count outcome — countExample","text":"","code":"data(countExample)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/countExample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data with count outcome — countExample","text":"dataframe 4000 rows (patients) 9 variables: age age baseline, centered 48 years old, years female sex, 0 male, 1 female previous_treatment previous treatment, \"drugA\", \"drugB\", \"drugC\" previous_cost previous medical cost, US dollars previous_number_symptoms previous number symptoms, \"0\", \"1\", \">=2\" previous_number_relapses previous number relapses trt current treatment, \"drug0\" \"drug1\" y count outcome, current number relapses years length follow-, years","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/countExample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated data with count outcome — countExample","text":"","code":"data(countExample) str(countExample) #> 'data.frame':\t4000 obs. of  9 variables: #>  $ age                     : num [1:4000, 1] -21.22 -2.22 -10.22 6.78 4.78 ... #>   ..- attr(*, \"scaled:center\")= num 46.2 #>  $ female                  : int  0 1 1 0 1 0 1 0 1 1 ... #>  $ previous_treatment      : Factor w/ 3 levels \"drugA\",\"drugB\",..: 1 1 1 1 3 3 3 3 3 1 ... #>  $ previous_cost           : num [1:4000, 1] 0.451 -0.194 -0.534 -0.337 -0.271 ... #>   ..- attr(*, \"scaled:center\")= num 13824 #>   ..- attr(*, \"scaled:scale\")= num 20172 #>  $ previous_number_symptoms: Factor w/ 3 levels \"0\",\"1\",\">=2\": 2 2 2 2 2 2 2 3 2 1 ... #>  $ previous_number_relapses: int  0 0 1 1 0 0 0 0 1 1 ... #>  $ trt                     : Factor w/ 2 levels \"drug0\",\"drug1\": 2 1 1 2 2 1 2 2 2 2 ... #>  $ y                       : int  0 0 0 0 1 0 0 0 0 0 ... #>  $ years                   : num  0.2847 0.6105 2.653 0.0383 2.2697 ... rate <- countExample$y / countExample$years"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/cox.rmst.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","title":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","text":"Estimate restricted mean survival time (RMST) based Cox regression model","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/cox.rmst.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","text":"","code":"cox.rmst(y, d, x.cate, xnew, tau0)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/cox.rmst.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. xnew Matrix p.cate baseline covariates want estimate RMST; dimension m (observations new data set) p.cate tau0 truncation time defining restricted mean time lost.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/cox.rmst.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate restricted mean survival time (RMST) based on Cox regression model — cox.rmst","text":"estimated RMST new subjects covariates xnew; vector size m.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.html","id":null,"dir":"Reference","previous_headings":"","what":"Data preprocessing\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","title":"Data preprocessing\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","text":"Data preprocessing Apply beginning pmcount() cvcount(), arg.checks()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data preprocessing\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","text":"","code":"data.preproc(   fun,   cate.model,   ps.model,   data,   prop.cutoff = NULL,   prop.multi = NULL,   ps.method,   initial.predictor.method = NULL )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data preprocessing\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","text":"fun function argument check needed; \"pm\" pmcount(), \"cv\" cvcount(), \"drinf\" drcount.inference(). default. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'boosting', 'poisson' (fast), 'gam'. Default NULL, assigns 'boosting' count outcomes.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data preprocessing\nApply at the beginning of pmcount() and cvcount(), after arg.checks() — data.preproc","text":"list 6 elements:            - y: outcome; vector length n (observations)            - trt: binary treatment; vector length n - x.ps: matrix p.ps baseline covariates (plus intercept); dimension n p.ps + 1 - x.cate: matrix p.cate baseline covariates; dimension n p.cate - time: offset; vector length n - fun = \"pm\":                - prop: formatted prop.cutoff - fun = \"cv\" - prop.onlyhigh: formatted prop.cutoff 0 removed applicable                - prop.bi; formatted prop.cutoff 0 1 removed applicable                - prop.multi: formatted prop.multi, starting 0 ending 1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Data preprocessing\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","title":"Data preprocessing\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","text":"Data preprocessing Apply beginning catefitmean() catecvmean(), arg.checks()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data preprocessing\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","text":"","code":"data.preproc.mean(   fun,   cate.model,   init.model,   ps.model,   data,   prop.cutoff = NULL,   prop.multi = NULL,   ps.method,   score.method = NULL,   initial.predictor.method = NULL )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data preprocessing\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","text":"fun function argument check needed; \"pm\" catefitmean(), \"cv\" catecvmean(), \"drinf\" drmean.inference(). default. cate.model formula describing outcome model fitted. outcome must appear left-hand side. init.model formula describing initial predictor model. outcome must appear left-hand side. must specified score.method = contrastReg twoReg. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. data data frame containing variables outcome propensity score models; data frame n rows (1 row per observation). prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. initial.predictor.method character vector method used get initial outcome predictions conditional covariates. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'boosting', 'poisson' (fast), 'gam'. Default NULL, assigns 'boosting' count outcomes.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data preprocessing\nApply at the beginning of catefitmean() and catecvmean(), after arg.checks() — data.preproc.mean","text":"list 6 elements:            - y: outcome; vector length n (observations)            - trt: binary treatment; vector length n - x.ps: matrix p.ps baseline covariates (plus intercept); dimension n p.ps + 1 - x.cate: matrix p.cate baseline covariates; dimension n p.cate - x.init: matrix p.init baseline covariates; dimension n p.init - fun = \"pm\":                - prop: formatted prop.cutoff - fun = \"cv\" - prop.onlyhigh: formatted prop.cutoff 0 removed applicable                - prop.bi; formatted prop.cutoff 0 1 removed applicable                - prop.multi: formatted prop.multi, starting 0 ending 1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Data preprocessing\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","title":"Data preprocessing\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","text":"Data preprocessing Apply beginning catefitcount(), catecvcount(), catefitsurv(), catecvsurv(), arg.checks()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data preprocessing\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","text":"","code":"data.preproc.surv(   fun,   cate.model,   ps.model,   ipcw.model = NULL,   tau0 = NULL,   data,   prop.cutoff = NULL,   prop.multi = NULL,   ps.method,   initial.predictor.method = NULL,   response = \"count\" )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data preprocessing\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","text":"fun function argument check needed; \"catefit\" catefitcount() catefitsurv(), \"crossv\" catecvcount() catecvsurv(), \"drinf\" drcount.inference() drsurv.inference(). default. cate.model formula describing outcome model fitted. outcome must appear left-hand side. ps.model formula describing propensity score model fitted. treatment must appear left-hand side. treatment must numeric vector coded 0/1. data RCT, specify ps.model intercept-model. ipcw.model formula describing inverse probability censoring weighting(IPCW) model fitted. covariates outcome model, set ipcw.model = NULL. Otherwise, left-hand side must empty right-hand side covariates model. tau0 truncation time defining restricted mean time lost. Default NULL, corresponds setting truncation time maximum survival time data data data frame containing variables outcome, propensity score, IPCW models; data frame n rows (1 row per observation). prop.cutoff vector numerical values ((0, 1]) specifying percentiles estimated log CATE scores define nested subgroups. element represents cutoff separate observations nested subgroups (vs cutoff). length prop.cutoff number nested subgroups. equally-spaced sequence proportions ending 1 recommended. Default seq(0.5, 1, length = 6). prop.multi vector numerical values ([0, 1]) specifying percentiles estimated log CATE scores define mutually exclusive subgroups. start 0, end 1, length(prop.multi) > 2. element represents cutoff separate observations length(prop.multi) - 1 mutually exclusive subgroups. Default c(0, 1/3, 2/3, 1). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. initial.predictor.method character vector method used get initial outcome predictions conditional covariates. applies score.method includes 'twoReg' 'contrastReg'. Allowed values include one 'randomForest' (survival outcomes ), 'boosting', 'logistic' (survival outcomes , fast), 'poisson' (count outcomes , fast), 'gam' (count outcomes ). Default NULL, assigns 'boosting' count outcomes 'randomForest' survival outcomes. response type response variables; count (default) survival.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/data.preproc.surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data preprocessing\nApply at the beginning of catefitcount(), catecvcount(), catefitsurv(), and catecvsurv(), after arg.checks() — data.preproc.surv","text":"list elements:            - y: outcome; vector length n (observations)            - d : event indicator; vector length n; respone = \"survival\" - trt: binary treatment; vector length n - x.ps: matrix p.ps baseline covariates specified propensity score model (plus intercept); dimension n p.ps + 1 - x.cate: matrix p.cate baseline covariates specified outcome model; dimension n p.cate - x.ipcw: matrix p.ipw baseline covarites specified inverse probability censoring weighting model; dimension n p.ipw - time: offset; vector length n; response = \"count\" - fun = \"catefit\":                - prop: formatted prop.cutoff - prop.no1: formatted prop.cutoff 1 removed applicable; otherwise prop.no1 prop            - fun = \"crossv\" - prop.onlyhigh: formatted prop.cutoff 0 removed applicable                - prop.bi; formatted prop.cutoff 0 1 removed applicable                - prop.multi: formatted prop.multi, starting 0 ending 1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of the average treatment effect for count data — drcount","title":"Doubly robust estimator of the average treatment effect for count data — drcount","text":"Doubly robust estimator average treatment effect two treatments, rate ratio treatment 1 treatment 0 count outcomes.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of the average treatment effect for count data — drcount","text":"","code":"drcount(   y,   trt,   x.cate,   x.ps,   time,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   interactions = TRUE )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of the average treatment effect for count data — drcount","text":"y numeric vector size n element representing observed count outcome subject. trt numeric vector (0, 1) size n element representing treatment received subject. x.cate numeric matrix dimension n p.cate column representing baseline covariate specified outcome model subjects. x.ps numeric matrix dimension n p.ps + 1 leading column 1 intercept remaining column representing baseline covariate specified propensity score model subjects. time numeric vector size n element representing log-transformed person-years follow-subject. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value 0 1 estimated propensity scores truncated. Default 0.01. maxPS numerical value 0 1 estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. interactions logical value indicating whether outcome model allow treatment-covariate interaction x. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of the average treatment effect for count data — drcount","text":"Return list 4 elements: log.rate.ratio:  numeric value estimated log rate ratio. rate0:  numeric value estimated rate group trt=0. rate1:  numeric value estimated rate group trt=1.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of the average treatment effect for continuous data — drmean","title":"Doubly robust estimator of the average treatment effect for continuous data — drmean","text":"Doubly robust estimator average treatment effect two treatments, mean difference treatment 1 treatment 0 continuous outcomes.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of the average treatment effect for continuous data — drmean","text":"","code":"drmean(   y,   trt,   x.cate,   x.ps,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   interactions = TRUE )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of the average treatment effect for continuous data — drmean","text":"y numeric vector size n element representing observed continuous outcome subject. trt numeric vector (0, 1) size n element representing treatment received subject. x.cate numeric matrix dimension n p.cate column representing baseline covariate specified outcome model subjects. x.ps numeric matrix dimension n p.ps + 1 leading column 1 intercept remaining column representing baseline covariate specified propensity score model subjects ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. interactions logical value indicating whether outcome model assume interactions x trt. TRUE, interactions assumed least 10 patients received treatment option. Default TRUE.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of the average treatment effect for continuous data — drmean","text":"Return list 4 elements: mean.diff:  numeric value estimated mean difference. mean.diff0:  numeric value estimated mean difference   treatment group 0. mean.diff1:  numeric value estimated mean difference   treatment group 1.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","title":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","text":"Doubly robust estimator average treatment effect two treatments, restricted mean time lost (RMTL) ratio treatment 1 treatment 0 survival outcomes.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","text":"","code":"drsurv(   y,   d,   x.cate,   x.ps,   x.ipcw,   trt,   yf = NULL,   tau0,   surv.min = 0.025,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   ipcw.method = \"breslow\" )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. trt Treatment received; vector size n treatment coded 0/1. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. tau0 truncation time defining restricted mean time lost. surv.min Lower truncation limit probability censored (positive close 0). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/drsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimator of the average treatment effect with Cox model for survival data — drsurv","text":"Return list 4 elements: rmst1:  numeric value estimated restricted mean survival time n group trt = 1. rmst0:  numeric value estimated restricted mean survival time n group trt = 0. log.rmtl.ratio:  numeric value estimated log rmtl ratio. log.hazard.ratio:  numeric value estimated log hazard ratio.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estcount.bilevel.subgroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the Average Treatment Effect of the log risk ratio in multiple\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","title":"Estimate the Average Treatment Effect of the log risk ratio in multiple\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","text":"care higher subgroup (cutoff), need trt.est.high set onlyhigh TRUE Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == TRUE;  estcount.bilevel.subgroups() always takes subgroup top highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estcount.bilevel.subgroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the Average Treatment Effect of the log risk ratio in multiple\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","text":"","code":"estcount.bilevel.subgroups(   y,   x.cate,   x.ps,   time,   trt,   score,   higher.y,   prop,   onlyhigh,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estcount.bilevel.subgroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the Average Treatment Effect of the log risk ratio in multiple\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","text":"y Observed outcome; vector size n (observations) x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) time Log-transformed person-years follow-; vector size n trt Treatment received; vector size n units treatment coded 0/1 score Estimated log CATE scores n observations one four methods (boosting, naive Poisson, two regressions, contrast regression); vector size n higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated log CATE scores define subgroups calculate ATE ; vector floats (0,1] (onlyhigh=T) (0,1) (onlyhigh=F):              element prop represents high/low cutoff bi-level subgroup length prop              number bi-level subgroups onlyhigh Indicator returning ATEs higher--cutoff category bi-level subgroups; boolean ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estcount.bilevel.subgroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the Average Treatment Effect of the log risk ratio in multiple\nbi-level subgroups defined by the proportions — estcount.bilevel.subgroups","text":"ate.est.high: estimated ATEs multiple bi-level subgroups higher--cutoff category; vector size equal length prop; always returned         ate.est.low: estimated ATEs multiple bi-level subgroups lower--cutoff category;         vector size equal length prop; returned onlyhigh == TRUE","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estcount.multilevel.subgroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","title":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","text":"Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == TRUE;  subgroups defined estcount.multilevel.subgroup() start lowest highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estcount.multilevel.subgroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","text":"","code":"estcount.multilevel.subgroup(   y,   x.cate,   x.ps,   time,   trt,   score,   higher.y,   prop,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estcount.multilevel.subgroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","text":"y Observed outcome; vector size n (observations) x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) time Log-transformed person-years follow-; vector size n trt Treatment received; vector size n units treatment coded 0/1 score Estimated log CATE scores n observations one four methods (boosting, naive Poisson, two regressions, contrast regression); vector size n higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated log CATE scores define subgroups calculate ATE ; vector floats [0,1] always starting 0 ending 1:              element prop represents inclusive cutoffs multilevel subgroup length prop              number categories multilevel subgroup ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estcount.multilevel.subgroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the log RR ratio in one multilevel subgroup defined by the proportions — estcount.multilevel.subgroup","text":"estimated ATEs categories one multilevel subgroup; vector size equal length categories multilevel subgroup","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estmean.bilevel.subgroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the mean difference in multiple bi-level subgroups\ndefined by the proportions — estmean.bilevel.subgroups","title":"Estimate the ATE of the mean difference in multiple bi-level subgroups\ndefined by the proportions — estmean.bilevel.subgroups","text":"care higher subgroup (cutoff), need trt.est.high set onlyhigh TRUE. Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == TRUE. estcount.bilevel.subgroups() always takes subgroup top highest adjusted scores,higher adjusted scores always represent high responders treatment group 1.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estmean.bilevel.subgroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the mean difference in multiple bi-level subgroups\ndefined by the proportions — estmean.bilevel.subgroups","text":"","code":"estmean.bilevel.subgroups(   y,   x.cate,   x.ps,   trt,   score,   higher.y,   prop,   onlyhigh,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estmean.bilevel.subgroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the mean difference in multiple bi-level subgroups\ndefined by the proportions — estmean.bilevel.subgroups","text":"y Observed outcome; vector size n (observations) x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) trt Treatment received; vector size n units treatment coded 0/1 score Estimated CATE scores n observations one six methods (boosting, linear regression, two regressions, contrast regression, random forest, generalized additive model); vector size n higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated CATE scores define subgroups calculate ATE ; vector floats (0,1] (onlyhigh=T) (0,1) (onlyhigh=F):              element prop represents high/low cutoff bi-level subgroup length prop              number bi-level subgroups onlyhigh Indicator returning ATEs higher--cutoff category bi-level subgroups; boolean ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estmean.bilevel.subgroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the mean difference in multiple bi-level subgroups\ndefined by the proportions — estmean.bilevel.subgroups","text":"ate.est.high: estimated ATEs multiple bi-level subgroups higher--cutoff category; vector size equal length prop; always returned         ate.est.low: estimated ATEs multiple bi-level subgroups lower--cutoff category;         vector size equal length prop; returned onlyhigh == TRUE","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estmean.multilevel.subgroup.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","title":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","text":"Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == TRUE;  subgroups defined estmean.multilevel.subgroup() start lowest highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estmean.multilevel.subgroup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","text":"","code":"estmean.multilevel.subgroup(   y,   x.cate,   x.ps,   trt,   score,   higher.y,   prop,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estmean.multilevel.subgroup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","text":"y Observed outcome; vector size n (observations) x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) trt Treatment received; vector size n units treatment coded 0/1 score Estimated CATE scores n observations one six methods (boosting, linear regression, two regressions, contrast regression, random forest, generalized additive model); vector size n higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated CATE scores define subgroups calculate ATE ; vector floats [0,1] always starting 0 ending 1:              element prop represents inclusive cutoffs multilevel subgroup length prop              number categories multilevel subgroup ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estmean.multilevel.subgroup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the mean difference in one multilevel subgroup defined by the proportions — estmean.multilevel.subgroup","text":"estimated ATEs categories one multilevel subgroup; vector size equal length categories multilevel subgroup","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estsurv.bilevel.subgroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","text":"care higher subgroup (cutoff), need ate.rmtl.high hr.high set \"onlyhigh\" TRUE Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == FALSE;  estsurv() function always takes subgroup top highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estsurv.bilevel.subgroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","text":"","code":"estsurv.bilevel.subgroups(   y,   d,   x.cate,   x.ps,   x.ipcw,   trt,   yf,   tau0 = tau0,   score,   higher.y,   prop,   onlyhigh,   surv.min = 0.025,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   ipcw.method = \"breslow\" )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estsurv.bilevel.subgroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. trt Treatment received; vector size n treatment coded 0/1. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. tau0 truncation time defining restricted mean time lost. score Estimated log CATE scores n observations one five methods (random forest, boosting, naive Poisson, two regressions, contrast regression); vector size n. higher.y logical value indicating whether higher (TRUE) lower (FALSE) prop Proportions corresponding percentiles estimated log CATE scores define subgroups calculate ATE ; vector floats (0,1] (onlyhigh=TRUE) (0,1) (onlyhigh=FALSE):              element prop represents high/low cutoff bi-level subgroup length prop              number bi-level subgroups onlyhigh Indicator returning ATEs higher--cutoff category bi-level subgroups; boolean. surv.min Lower truncation limit probability censored (positive close 0). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estsurv.bilevel.subgroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in multiple bi-level subgroups defined by the proportions — estsurv.bilevel.subgroups","text":"ate.rmtl.high: estimated ATEs (ratio RMTL) multiple bi-level subgroups higher--cutoff category; vector size equal length prop; always returned.         ate.rmtl.low: estimated ATEs (ratio RMTL) multiple bi-level subgroups lower--cutoff category;         vector size equal length prop; returned onlyhigh = TRUE.         hr.high: unadjusted hazard ratio multiple bi-level subgroups higher--cutoff category;         vector size equal length prop; always returned.         hr.low: unadjusted hazard ratio multiple bi-level subgroups lower--cutoff category;         vector size equal length prop; returned onlyhigh = TRUE","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estsurv.multilevel.subgroups.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","text":"Scores adjusted opposite sign higher.y == FALSE; scores stay higher.y == FALSE;  estsurv function multilevel subgroups start lowest highest adjusted scores,  higher adjusted scores always represent high responders trt=1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estsurv.multilevel.subgroups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","text":"","code":"estsurv.multilevel.subgroups(   y,   d,   x.cate,   x.ps,   x.ipcw,   trt,   yf,   tau0 = tau0,   score,   higher.y,   prop,   surv.min = 0.025,   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   ipcw.method = \"breslow\" )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estsurv.multilevel.subgroups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. trt Treatment received; vector size n treatment coded 0/1. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. tau0 truncation time defining restricted mean time lost. score Estimated log CATE scores n observations one five methods (random forest, boosting, naive Poisson, two regressions, contrast regression); vector size n. higher.y logical value indicating whether higher (TRUE) lower (FALSE) values outcome desirable. Default TRUE. prop Proportions corresponding percentiles estimated log CATE scores define subgroups calculate ATE ; vector floats [0,1] always starting 0 ending 1:              element prop represents inclusive cutoffs multilevel subgroup length prop              number categories multilevel subgroup surv.min Lower truncation limit probability censored (positive close 0). ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99. ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/estsurv.multilevel.subgroups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the ATE of the RMTL ratio and unadjusted hazard ratio in one multilevel subgroup defined by the proportions — estsurv.multilevel.subgroups","text":"ate.rmtl: estimated ATEs (ratio RMTL) categories one multilevel subgroup; vector size equal length categories multilevel subgroup.         ate.hr: unadjusted hazard ratio categories one multilevel subgroup;         vector size equal length categories multilevel subgroup.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/glm.ps.html","id":null,"dir":"Reference","previous_headings":"","what":"Propensity score estimation with LASSO — glm.ps","title":"Propensity score estimation with LASSO — glm.ps","text":"Propensity score based multivariate logistic regression LASSO penalization two-way interactions","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/glm.ps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Propensity score estimation with LASSO — glm.ps","text":"","code":"glm.ps(trt, x.ps, xnew = NULL, minPS = 0.01, maxPS = 0.99)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/glm.ps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Propensity score estimation with LASSO — glm.ps","text":"trt Treatment received; vector size n (observations) treatment coded 0/1 x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) xnew Matrix p.ps baseline covariates (plus leading column 1 intercept) want propensity scores predictions; dimension m (observations new data set) p.ps + 1 minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/glm.ps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Propensity score estimation with LASSO — glm.ps","text":"trimmed propensity score unit; vector size n (xnew NULL) m","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/glm.simplereg.ps.html","id":null,"dir":"Reference","previous_headings":"","what":"Propensity score estimation with a linear model — glm.simplereg.ps","title":"Propensity score estimation with a linear model — glm.simplereg.ps","text":"Propensity score based multivariate logistic regression main effects ","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/glm.simplereg.ps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Propensity score estimation with a linear model — glm.simplereg.ps","text":"","code":"glm.simplereg.ps(trt, x.ps, xnew = NULL, minPS = 0.01, maxPS = 0.99)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/glm.simplereg.ps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Propensity score estimation with a linear model — glm.simplereg.ps","text":"trt Treatment received; vector size n (observations) treatment coded 0/1 x.ps matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) xnew matrix p.ps baseline covariates (plus leading column 1 intercept) want PS predictions; dimension m (observations new data set) p.ps + 1 minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS numerical value ((0, 1]) estimated propensity scores truncated. Must strictly greater minPS. Default 0.99.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/glm.simplereg.ps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Propensity score estimation with a linear model — glm.simplereg.ps","text":"estimated propensity score unit; vector size n (xnew NULL) m","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxcount.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the CATE model using specified scoring methods — intxcount","title":"Estimate the CATE model using specified scoring methods — intxcount","text":"Coefficients CATE estimated boosting, naive Poisson, two regression, contrast regression, negative binomial","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxcount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the CATE model using specified scoring methods — intxcount","text":"","code":"intxcount(   y,   trt,   x.cate,   x.ps,   time,   score.method = c(\"boosting\", \"poisson\", \"twoReg\", \"contrastReg\", \"negBin\"),   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   initial.predictor.method = \"boosting\",   xvar.smooth = NULL,   tree.depth = 2,   n.trees.boosting = 200,   B = 3,   Kfold = 6,   plot.gbmperf = TRUE,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2),   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxcount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the CATE model using specified scoring methods — intxcount","text":"y Observed outcome; vector size n (observations) trt Treatment received; vector size n units treatment coded 0/1 x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) time Log-transformed person-years follow-; vector size n score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. Default specifies 5 methods. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS number estimated propensity scores trimmed; scalar initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'poisson' (fastest), 'boosting' (default) 'gam'. xvar.smooth vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxcount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the CATE model using specified scoring methods — intxcount","text":"Depending score.method , outputs combination following:           result.boosting: Results boosting fit best iteration, trt = 0 trt = 1 separately           result.poisson: Naive Poisson estimator (beta1 - beta0); vector length p.cate + 1           result.twoReg: Two regression estimator (beta1 - beta0); vector length p.cate + 1           result.contrastReg: list contrast regression results 3 elements:               $delta.contrastReg: Contrast regression DR estimator; vector length p.cate + 1               $sigma.contrastReg: Variance covariance matrix delta.contrastReg; matrix size p.cate + 1 p.cate + 1               $converge.contrastReg: Indicator Newton Raphson algorithm converged delta_0; boolean           result.negBin: Negative binomial estimator (beta1 - beta0); vector length p.cate + 1           best.iter: Largest best iterations boosting (used)           fgam: Formula applied GAM (used)","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxmean.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the CATE model using specified scoring methods — intxmean","title":"Estimate the CATE model using specified scoring methods — intxmean","text":"Coefficients CATE estimated boosting, linear regression, two regression, contrast regression, random forest, generalized additive model","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxmean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the CATE model using specified scoring methods — intxmean","text":"","code":"intxmean(   y,   trt,   x.cate,   x.init,   x.ps,   score.method = c(\"boosting\", \"gaussian\", \"twoReg\", \"contrastReg\", \"gam\",     \"randomForest\"),   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   initial.predictor.method = \"boosting\",   xvar.smooth.init,   xvar.smooth.score,   tree.depth = 2,   n.trees.rf = 1000,   n.trees.boosting = 200,   B = 1,   Kfold = 2,   plot.gbmperf = TRUE,   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxmean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the CATE model using specified scoring methods — intxmean","text":"y Observed outcome; vector size n (observations) trt Treatment received; vector size n units treatment coded 0/1 x.cate Matrix p.cate baseline covariates; dimension n p.cate (covariates outcome model) x.init Matrix p.init baseline covariates; dimension n p.init must specified score.method = contrastReg twoReg. x.ps Matrix p.ps baseline covariates (plus leading column 1 intercept); dimension n p.ps + 1 (covariates propensity score model plus intercept) score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. Default specifies 6 methods. ps.method character value method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS number estimated propensity scores trimmed; scalar initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'gaussian' (fastest), 'boosting' (default) 'gam'. xvar.smooth.init vector characters indicating name variables used smooth terms initial.predictor.method = 'gam'. variables must selected variables listed init.model. Default NULL, uses variables init.model. xvar.smooth.score vector characters indicating name variables used smooth terms score.method = 'gam'. variables must selected variables listed cate.model. Default NULL, uses variables cate.model. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 2. n.trees.rf positive integer specifying number trees. Used score.method = 'randomForest'. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 200. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 6. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxmean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the CATE model using specified scoring methods — intxmean","text":"Depending score.method , outputs combination following:           result.boosting: Results boosting fit best iteration, trt = 0 trt = 1 separately           result.gaussian: Linear regression estimator (beta1 - beta0); vector length p.cate + 1           result.twoReg: Two regression estimator (beta1 - beta0); vector length p.cate + 1           result.contrastReg: list contrast regression results 3 elements:               $delta.contrastReg: Contrast regression DR estimator; vector length p.cate + 1               $sigma.contrastReg: Variance covariance matrix delta.contrastReg; matrix size p.cate + 1 p.cate + 1           result.randomForest: Results random forest fit best iteration, trt = 0 trt = 1 separately           result.gam: Results generalized additive model fit best iteration, trt = 0 trt = 1 separately           best.iter: Largest best iterations boosting (used)           fgam: Formula applied GAM initial.predictor.method = 'gam' warn.fit: Warnings occurred fitting score.method err.fit:: Errors occurred fitting score.method","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxsurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","title":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","text":"Coefficients CATE estimated random forest, boosting, naive Poisson, two regression, contrast regression","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxsurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","text":"","code":"intxsurv(   y,   d,   trt,   x.cate,   x.ps,   x.ipcw,   yf = NULL,   tau0,   surv.min = 0.025,   score.method = c(\"randomForest\", \"boosting\", \"poisson\", \"twoReg\", \"contrastReg\"),   ps.method = \"glm\",   minPS = 0.01,   maxPS = 0.99,   ipcw.method = \"breslow\",   initial.predictor.method = \"randomForest\",   tree.depth = 3,   n.trees.rf = 1000,   n.trees.boosting = 150,   B = 3,   Kfold = 5,   plot.gbmperf = TRUE,   error.maxNR = 0.001,   max.iterNR = 100,   tune = c(0.5, 2),   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxsurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. trt Treatment received; vector size n treatment coded 0/1. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. x.ps Matrix p.ps baseline covariates specified propensity score model; dimension n p.ps. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. tau0 truncation time defining restricted mean time lost. surv.min Lower truncation limit probability censored (positive close 0). score.method vector one multiple methods estimate CATE score. Allowed values :  'randomForest', 'boosting', 'poisson', 'twoReg', 'contrastReg'. Default specifies 5 methods. ps.method character vector method estimate propensity score. Allowed values include one : 'glm' logistic regression main effects (default), 'lasso' logistic regression main effects LASSO penalization two-way interactions (added model interactions specified ps.model). Relevant ps.model one variable. minPS numerical value ([0, 1]) estimated propensity scores truncated. Default 0.01. maxPS number estimated propensity scores trimmed; scalar ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'. initial.predictor.method character vector method used get initial outcome predictions conditional covariates cate.model score.method = 'twoReg' 'contrastReg'. Allowed values include one 'randomForest', 'boosting' 'logistic' (fastest). Default 'randomForest'. tree.depth positive integer specifying depth individual trees boosting (usually 2-3). Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default 3. n.trees.rf positive integer specifying maximum number trees random forest. Used score.method = 'ranfomForest' initial.predictor.method = 'randomForest' score.method = 'twoReg' 'contrastReg'. Default 1000. n.trees.boosting positive integer specifying maximum number trees boosting (usually 100-1000). Used score.method = 'boosting' initial.predictor.method = 'boosting' score.method = 'twoReg' 'contrastReg'. Default 150. B positive integer specifying number time cross-fitting repeated score.method = 'twoReg' 'contrastReg'. Default 3. Kfold positive integer specifying number folds (parts) used cross-fitting partition data score.method = 'twoReg' 'contrastReg'. Default 5. plot.gbmperf logical value indicating whether plot performance measures boosting. Used score.method = 'boosting' score.method = 'twoReg' 'contrastReg' initial.predictor.method = 'boosting'. Default TRUE. error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 100. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2). ... Additional arguments gbm()","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/intxsurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the CATE model using specified scoring methods for survival outcomes — intxsurv","text":"Depending score.method , outputs combination following:           result.randomForest: Results random forest fit, trt = 0 trt = 1 separately           result.boosting: Results boosting fit, trt = 0 trt = 1 separately           result.poisson: Naive Poisson estimator (beta1 - beta0); vector length p.cate + 1           result.twoReg: Two regression estimator (beta1 - beta0); vector length p.cate + 1           result.contrastReg: list contrast regression results 2 elements:               $delta.contrastReg: Contrast regression DR estimator; vector length p.cate + 1               $converge.contrastReg: Indicator Newton Raphson algorithm converged delta_0; boolean","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/ipcw.surv.html","id":null,"dir":"Reference","previous_headings":"","what":"Probability of being censored — ipcw.surv","title":"Probability of being censored — ipcw.surv","text":"Probability censored used correct effect right censoring.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/ipcw.surv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Probability of being censored — ipcw.surv","text":"","code":"ipcw.surv(   y,   d,   x.ipcw,   yf = NULL,   ipcw.method = \"breslow\",   tau0,   surv.min = 0.025 )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/ipcw.surv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Probability of being censored — ipcw.surv","text":"y Observed survival censoring time; vector size n. d event indicator, normally 1 = event, 0 = censored; vector size n. x.ipcw Matrix p.ipw baseline covariate specified inverse probability censoring weighting; dimension n p.ipw. yf Follow-time, interpreted potential censoring time; vector size n potential censoring time known. unknown, set yf == NULL yf taken y function. ipcw.method censoring model. Allowed values : 'breslow' (Cox regression Breslow estimator baseline survivor function), 'aft (exponential)', 'aft (weibull)', 'aft (lognormal)' 'aft (loglogistic)'. Default 'breslow'. tau0 truncation time defining restricted mean time lost. surv.min Lower truncation limit probability censored (positive close 0).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/ipcw.surv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Probability of being censored — ipcw.surv","text":"vector size n estimated probabilities Pr(C > min(y, tau0) | x.ipcw)","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/meanCatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","text":"Storing errors warnings occurred estimating ATEs nested subgroups. errors warnings, estimated mean difference provided. warnings errors, estimated mean difference provided warning attribute set. errors, NA values returned mean difference. error attribute set also provided.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/meanCatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","text":"","code":"meanCatch(fun)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/meanCatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","text":"fun drsurv function...","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/meanCatch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup for continuous data — meanCatch","text":"list containing","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/meanExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data with a continuous outcome — meanExample","title":"Simulated data with a continuous outcome — meanExample","text":"dataset containing continuous outcome 6 baseline covariates","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/meanExample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated data with a continuous outcome — meanExample","text":"","code":"data(meanExample)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/meanExample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data with a continuous outcome — meanExample","text":"dataframe 4000 rows (patients) 9 variables: age age baseline, centered 48 years old, years female sex, 0 male, 1 female previous_treatment previous treatment, \"drugA\", \"drugB\", \"drugC\" previous_cost previous medical cost, US dollars previous_number_symptoms previous number symptoms, \"0\", \"1\", \">=2\" previous_number_relapses previous number relapses trt current treatment, \"drug0\" \"drug1\" y count outcome, current number relapses","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/meanExample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated data with a continuous outcome — meanExample","text":"","code":"data(meanExample) str(meanExample) #> 'data.frame':\t4000 obs. of  8 variables: #>  $ age                     : num [1:4000, 1] 11.8 -8.2 -3.2 -16.2 -8.2 ... #>   ..- attr(*, \"scaled:center\")= num 46.2 #>  $ female                  : int  1 0 0 1 1 0 1 1 1 1 ... #>  $ previous_treatment      : Factor w/ 3 levels \"drugA\",\"drugB\",..: 3 3 1 3 2 3 3 3 3 1 ... #>  $ previous_cost           : num [1:4000, 1] -0.331 -0.575 0.519 -0.519 -0.567 ... #>   ..- attr(*, \"scaled:center\")= num 13788 #>   ..- attr(*, \"scaled:scale\")= num 20150 #>  $ previous_number_symptoms: Factor w/ 3 levels \"0\",\"1\",\">=2\": 2 2 3 2 2 2 2 2 1 3 ... #>  $ previous_status_measure : num  6.15 2.003 3.786 1.889 -0.516 ... #>  $ trt                     : chr  \"drug1\" \"drug0\" \"drug0\" \"drug0\" ... #>  $ y                       : num [1:4000, 1] 21.93 -8.26 -3.32 -22.13 -7.91 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:4000] \"1\" \"2\" \"3\" \"4\" ... #>   .. ..$ : NULL"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmglmcount.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","text":"Doubly robust estimators coefficients two regression","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmglmcount.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","text":"","code":"onearmglmcount.dr(y, x.cate, time, trt, ps, f.predictor)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmglmcount.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","text":"y Observed outcome; vector size n x.cate Matrix p baseline covariates; dimension n p time Log-transformed person-years follow-; vector size n trt Treatment received; vector size n units treatment coded 0/1 ps Estimated propensity scores observations; vector size n f.predictor Initial prediction outcome (expected number relapses one unit exposure time) conditioned covariates x one treatment group r; mu_r(x), step 1 two regression; vector size n","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmglmcount.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmcount.dr","text":"Doubly robust estimators regression coefficients beta_r doubly robust estimating equation r = 0, 1 treatment received; vector size p + 1 (intercept included)","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmglmmean.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","text":"Doubly robust estimators coefficients two regression","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmglmmean.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","text":"","code":"onearmglmmean.dr(y, x.cate, trt, ps, f.predictor)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmglmmean.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","text":"y Observed outcome; vector size n x.cate Matrix p baseline covariates; dimension n p trt Treatment received; vector size n units treatment coded 0/1 ps Estimated propensity scores observations; vector size n f.predictor Initial prediction outcome (expected number relapses one unit exposure time) conditioned covariates x one treatment group r; mu_r(x), step 1 two regression; vector size n","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmglmmean.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the two regression — onearmglmmean.dr","text":"Doubly robust estimators regression coefficients beta_r doubly robust estimating equation r = 0, 1 treatment received; vector size p + 1 (intercept included)","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmsurv.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","title":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","text":"Doubly robust estimators coefficients two regression","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmsurv.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","text":"","code":"onearmsurv.dr(ynew, dnew, trt, x.cate, tau0, weightsurv, ps, f.predictor)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmsurv.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","text":"ynew Truncated survival censoring time; vector size n. dnew event indicator truncation, 1 = event censored truncation, 0 = censored truncation; vector size n. trt Treatment received; vector size n treatment coded 0/1. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. tau0 truncation time defining restricted mean time lost. weightsurv Estimated inverse probability censoring weights truncation observations; vector size n. ps Estimated propensity scores observations; vector size n f.predictor Initial prediction outcome (restricted mean time loss) conditioned covariates x.cate one treatment group r; mu_r(x.cate), step 1 two regression; vector size n","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/onearmsurv.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the two regression — onearmsurv.dr","text":"Doubly robust estimators two regression coefficients beta_r r = 0, 1 treatment received; vector size p.cate + 1 (intercept included)","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.atefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Histogram of bootstrap estimates — plot.atefit","title":"Histogram of bootstrap estimates — plot.atefit","text":"Histogram bootstrap estimates","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.atefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Histogram of bootstrap estimates — plot.atefit","text":"","code":"# S3 method for atefit plot(x, bins, alpha = 0.7, title = waiver(), theme = theme_classic(), ...)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.atefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Histogram of bootstrap estimates — plot.atefit","text":"x object class \"atefit\". bins Number bins alpha Opacity title text title theme Defaults theme_classic(). options include theme_grey(), theme_bw(), theme_light(), theme_dark(), theme_void() ... parameters","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.atefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Histogram of bootstrap estimates — plot.atefit","text":"plot class ggplot, displaying estimated ATE across bootstrap samples","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.atefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Histogram of bootstrap estimates — plot.atefit","text":"Create histogram displaying distribution bootstrap estimates. red vertical reference line represents final estimate.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.atefit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Histogram of bootstrap estimates — plot.atefit","text":"Thomas Debray","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.precmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Two side-by-side line plots of validation curves from the ","title":"Two side-by-side line plots of validation curves from the ","text":"Provides validation curves two side--side plots, visualizing estimated ATEs series nested subgroups training set validation set separately, line represents one scoring method specified catecv() catecvmean(). run results catecv() catecvmean() obtained.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.precmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two side-by-side line plots of validation curves from the ","text":"","code":"# S3 method for precmed plot(   x,   cv.i = NULL,   combine = \"mean\",   show.abc = TRUE,   valid.only = FALSE,   plot.hr = FALSE,   ylab = NULL,   legend.position = \"bottom\",   xlim = NULL,   title = waiver(),   theme = theme_classic(),   ... )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.precmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two side-by-side line plots of validation curves from the ","text":"x object class \"precmed\". cv.positive integer indicating index CV iteration results plotted. Allowed values : positive integer \\(<=\\) cv.n catecv() NULL. cv.= NULL, results across CV iterations combined according combine plotted. Default NULL. combine character value indicating combine estimated ATEs across CV iterations validation curve nested subgroup, separately training validation results. Allowed values : 'mean' 'median'. Used cv.= NULL. Default 'mean'. show.abc logical value indicating whether show ABC statistics validation set. Used x$abc = TRUE xlim limited smaller range (.e., xlim = NULL equal entire x$prop.onlyhigh range). cv.NULL, ABC statistics based combined CV iterations. cv.integer, ABC statistics based solely CV iteration. Default TRUE. valid.logical value indicating whether validation curves validation set plotted (TRUE). Otherwise, validation curves training validation sets plotted side--side (FALSE). Default FALSE. plot.hr logical value indicating whether hazard ratios plotted validation curves (TRUE). Otherwise, restricted mean time lost plotted (FALSE). argument applicable survival outcomes. Default FALSE. ylab character value y-axis label describe ATE . Default NULL, creates default y-axis label based available data. legend.position character value legend position argument passed ggplot object. Default 'bottom'. xlim numeric value range x-axis. Default NULL, means range specified. title text title theme Defaults theme_classic(). options include theme_grey(), theme_bw(), theme_light(), theme_dark(), theme_void() ... parameters","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.precmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two side-by-side line plots of validation curves from the ","text":"Returns two side--side line plots, one shows validation curves training sets validation curves validation sets. gray horizontal dashed line overall ATE included reference. ABC statistics added legend show.abc = TRUE.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.precmed.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Two side-by-side line plots of validation curves from the ","text":"plot() takes outputs catecv() generates two plots validation curves side--side, one training set one validation set. Separate validation curves produced scoring method specified via score.method catecv() catecvmean(). validation curves (ABC statistics, applicable) can help compare performance different scoring methods terms discerning potential treatment heterogeneity subgroups internal validation. Steeper validation curves validation set suggest presence treatment effect heterogeneity (ability scoring methods capture ) flat validation curves indicate absence treatment effect heterogeneity (inability scoring method capture ).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.precmed.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Two side-by-side line plots of validation curves from the ","text":"Yadlowsky, S., Pellegrini, F., Lionetto, F., Braune, S., & Tian, L. (2020). Estimation validation ratio-based conditional average treatment effects using observational data. Journal American Statistical Association, 1-18. https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1772080","code":""},{"path":[]},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/plot.precmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Two side-by-side line plots of validation curves from the ","text":"","code":"# \\donttest{ # Count outcome eval_1 <- catecv(response = \"count\",                  data = countExample,                  score.method = \"poisson\",                  cate.model = y ~ age + female + previous_treatment +                                   previous_cost + previous_number_relapses + offset(log(years)),                  ps.model = trt ~ age + previous_treatment,                  higher.y = FALSE,                  cv.n = 5) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.  # default setting plot(eval_1)   # turn off ABC annotation plot(eval_1, show.abc = FALSE)   # use a different theme plot(eval_1, theme = ggplot2::theme_bw())   # plot the validation curves from the 2nd CV iteration instead of the mean # of all validation curves plot(eval_1, cv.i = 2)   # median of the validation curves plot(eval_1, combine = \"median\")   # plot validation curves in validation set only plot(eval_1, valid.only = TRUE)   # Survival outcome library(survival) tau0 <- with(survivalExample,              min(quantile(y[trt == \"drug1\"], 0.95), quantile(y[trt == \"drug0\"], 0.95))) eval_2 <- catecv(response = \"survival\",                  data = survivalExample,                  score.method = c(\"poisson\", \"randomForest\"),                  cate.model = Surv(y, d) ~ age + female + previous_cost +                                            previous_number_relapses,                  ps.model = trt ~ age + previous_treatment,                  initial.predictor.method = \"randomForest\",                  ipcw.model = ~ age + previous_cost + previous_treatment,                  tau0 = tau0,                  cv.n = 5,                  seed = 999) #> Warning: Variable trt was recoded to 0/1 with drug0->0 and drug1->1.   # default setting, plot RMTL ratios in both training and validation sets plot(eval_2)   # plot hazard ratio plot(eval_2, plot.hr = TRUE) #> Warning: ABC will not be shown in hazard ratio plot.   # }"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.atefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for atefit — print.atefit","title":"Print function for atefit — print.atefit","text":"Print function atefit","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.atefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for atefit — print.atefit","text":"","code":"# S3 method for atefit print(x, ...)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.atefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for atefit — print.atefit","text":"x object class \"atefit\". ... parameters","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.atefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print function for atefit — print.atefit","text":"return value","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.atefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print function for atefit — print.atefit","text":"Display estimated treatment effects survival outcomes (log restricted mean time lost ratio log hazard ratio) count outcomes (log rate ratio).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.atefit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print function for atefit — print.atefit","text":"Thomas Debray","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.catefit.html","id":null,"dir":"Reference","previous_headings":"","what":"Print function for atefit — print.catefit","title":"Print function for atefit — print.catefit","text":"Print function atefit","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.catefit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print function for atefit — print.catefit","text":"","code":"# S3 method for catefit print(x, ...)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.catefit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print function for atefit — print.catefit","text":"x object class \"catefit\". ... parameters","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.catefit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print function for atefit — print.catefit","text":"return value","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.catefit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print function for atefit — print.catefit","text":"Display estimated treatment effects survival outcomes (log restricted mean time lost ratio log hazard ratio) count outcomes (log rate ratio).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/print.catefit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print function for atefit — print.catefit","text":"Thomas Debray","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scorecount.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","text":"Based intxcount results CATE coefficients estimated boosting, naive Poisson, two regression, contrast regression, negative binomial","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scorecount.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","text":"","code":"scorecount(   fit,   x.cate,   time,   score.method = c(\"boosting\", \"poisson\", \"twoReg\", \"contrastReg\", \"negBin\") )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scorecount.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","text":"fit List objects generated intxcount: outputs boosting, naive Poisson, two regression, contrast regression, negative binomial x.cate Matrix p.cate baseline covariates; dimension n (observations) p.cate (covariates outcome model) time Log-transformed person-years follow-; vector size n score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'poisson', 'twoReg', 'contrastReg', 'negBin'. Default specifies 5 methods.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scorecount.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods — scorecount","text":"score.boosting: Estimated log CATE score n observations boosting method; vector size n score.poisson: Estimated log CATE score n observations naive Poisson method; vector size n score.twoReg: Estimated log CATE score n observations two regression method; vector size n score.contrastReg: Estimated log CATE score n observations contrast regression method; vector size n score.negBin: Estimated log CATE score n observations naive Poisson method; vector size n score = NA corresponding method called","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scoremean.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","title":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","text":"Based intxmean results CATE coefficients estimated boosting, linear regression, two regression, contrast regression, random forest, generalized additive model","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scoremean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","text":"","code":"scoremean(   fit,   x.cate,   score.method = c(\"boosting\", \"gaussian\", \"twoReg\", \"contrastReg\", \"randomForest\",     \"gam\") )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scoremean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","text":"fit List objects generated intxmean: outputs boosting, linear regression, two regression, contrast regression, random forest, generalized additive model x.cate Matrix p.cate baseline covariates; dimension n (observations) p.cate (covariates outcome model) score.method vector one multiple methods estimate CATE score. Allowed values : 'boosting', 'gaussian', 'twoReg', 'contrastReg', 'randomForest', 'gam'. Default specifies 6 methods.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scoremean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the CATE score given the baseline covariates for specified scoring method methods — scoremean","text":"score.boosting: Estimated CATE score n observations boosting method; vector size n score.gaussian: Estimated CATE score n observations linear regression method; vector size n score.twoReg: Estimated CATE score n observations two regression method; vector size n score.contrastReg: Estimated CATE score n observations contrast regression method; vector size n score.randomForest: Estimated CATE score n observations random forest method; vector size n score.gam: Estimated CATE score n observations generalized additive model; vector size n score = NA corresponding method called","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scoresurv.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","text":"Based intxsurv results CATE coefficients estimated random forest, boosting, naive Poisson, two regression, contrast regression","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scoresurv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","text":"","code":"scoresurv(   fit,   x.cate,   tau0,   score.method = c(\"randomForest\", \"boosting\", \"poisson\", \"twoReg\", \"contrastReg\") )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scoresurv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","text":"fit List objects generated intxsurv: outputs random forest, boosting, naive Poisson, two regression, contrast regression x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. tau0 truncation time defining restricted mean time lost. score.method vector one multiple methods estimate CATE score. Allowed values : 'randomForest', 'boosting', 'poisson', 'twoReg', 'contrastReg'. Default specifies 5 methods.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/scoresurv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the log CATE score given the baseline covariates and follow-up time for specified scoring method methods for survival outcomes — scoresurv","text":"score.randomForest: Estimated log CATE score n observations random forest method; vector size n score.boosting: Estimated log CATE score n observations boosting method; vector size n score.poisson: Estimated log CATE score n observations naive Poisson method; vector size n score.twoReg: Estimated log CATE score n observations two regression method; vector size n score.contrastReg: Estimated log CATE score n observations contrast regression method; vector size n score = NA corresponding method called","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/survCatch.html","id":null,"dir":"Reference","previous_headings":"","what":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","text":"Storing errors warnings occurred estimating ATEs nested subgroups. errors warnings, estimated log.rmtl.ratio log.hazard.ratio provided. warnings errors, estimated log.rmtl.ratio log.hazard.ratio provided warning attribute set. errors, NA values returned log.rmtl.ratio log.hazard.ratio. error attribute set also provided.","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/survCatch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","text":"","code":"survCatch(fun)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/survCatch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","text":"fun drsurv function...","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/survCatch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Catch errors and warnings when estimating the ATEs in the nested subgroup — survCatch","text":"list containing","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/survivalExample.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated data with survival outcome — survivalExample","title":"Simulated data with survival outcome — survivalExample","text":"dataset containing time--event outcome, event indicator, treatment group, 6 baseline covariates","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/survivalExample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated data with survival outcome — survivalExample","text":"","code":"data(survivalExample)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/survivalExample.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated data with survival outcome — survivalExample","text":"dataframe 4000 rows (patients) 9 variables: age age baseline, centered 48 years old, years female sex, 0 male, 1 female previous_treatment previous treatment, \"drugA\", \"drugB\", \"drugC\" previous_cost previous medical cost, US dollars previous_number_symptoms previous number symptoms, \"0\", \"1\", \">=2\" previous_number_relapses previous number relapses trt current treatment, \"drug0\" \"drug1\" y time first relapse censoring d event indicator, 1: relapse, 0: censored","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/survivalExample.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated data with survival outcome — survivalExample","text":"","code":"data(survivalExample) str(survivalExample) #> 'data.frame':\t4000 obs. of  9 variables: #>  $ age                     : num [1:4000, 1] -26.83 -2.83 -12.83 -20.83 6.17 ... #>   ..- attr(*, \"scaled:center\")= num 45.8 #>  $ female                  : int  1 1 1 0 0 1 1 1 1 1 ... #>  $ previous_treatment      : Factor w/ 3 levels \"drugA\",\"drugB\",..: 3 1 3 1 3 1 3 3 3 1 ... #>  $ previous_cost           : num [1:4000, 1] -0.341 -0.239 -0.171 -0.392 -0.518 ... #>   ..- attr(*, \"scaled:center\")= num 14362 #>   ..- attr(*, \"scaled:scale\")= num 24266 #>  $ previous_number_symptoms: Factor w/ 3 levels \"0\",\"1\",\">=2\": 2 2 2 3 3 2 3 2 2 2 ... #>  $ previous_number_relapses: int  0 1 2 0 1 0 0 2 0 0 ... #>  $ trt                     : Factor w/ 2 levels \"drug0\",\"drug1\": 1 1 1 1 2 1 2 2 2 2 ... #>  $ y                       : num  102.1 51.3 104.9 61.5 35.6 ... #>  $ d                       : num  0 0 0 0 0 0 0 0 0 1 ..."},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmglmcount.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","text":"Newton-Raphson algorithm used solve estimating equation bar S_n (delta) = 0","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmglmcount.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","text":"","code":"twoarmglmcount.dr(   y,   x.cate,   time,   trt,   ps,   f1.predictor,   f0.predictor,   error.maxNR = 0.001,   max.iterNR = 150,   tune = c(0.5, 2) )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmglmcount.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","text":"y Observed outcome; vector size n x.cate Matrix p.cate baseline covariates; dimension n p.cate time Log-transformed person-years follow-; vector size n trt Treatment received; vector size n units treatment coded 0/1 ps Estimated propensity scores observations; vector size n f1.predictor Initial predictions outcome (expected number relapses one unit exposure time) conditioned covariates x treatment group trt = 1; mu_1(x), step 1 two regression; vector size n f0.predictor Initial predictions outcome (expected number relapses one unit exposure time) conditioned covariates x treatment group trt = 0; mu_0(x), step 1 two regression; vector size n error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 150. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmglmcount.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmglmcount.dr","text":"coef: Doubly robust estimators regression coefficients delta_0; vector size p + 1 (intercept included)         vcov: Variance-covariance matrix estimated coefficient delta_0; matrix size p + 1 p + 1         converge: Indicator Newton Raphson algorithm converged delta_0; boolean","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmglmmean.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix — twoarmglmmean.dr","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix — twoarmglmmean.dr","text":"Solving estimating equation bar S_n (delta) = 0","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmglmmean.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix — twoarmglmmean.dr","text":"","code":"twoarmglmmean.dr(y, x.cate, trt, ps, f1.predictor, f0.predictor)"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmglmmean.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix — twoarmglmmean.dr","text":"y Observed outcome; vector size n x.cate Matrix p.cate baseline covariates; dimension n p.cate trt Treatment received; vector size n units treatment coded 0/1 ps Estimated propensity scores observations; vector size n f1.predictor Initial predictions outcome (expected number relapses one unit exposure time) conditioned covariates x treatment group trt = 1; mu_1(x), step 1 two regression; vector size n f0.predictor Initial predictions outcome (expected number relapses one unit exposure time) conditioned covariates x treatment group trt = 0; mu_0(x), step 1 two regression; vector size n","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmglmmean.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix — twoarmglmmean.dr","text":"coef: Doubly robust estimators regression coefficients delta_0; vector size p + 1 (intercept included)         vcov: Variance-covariance matrix estimated coefficient delta_0; matrix size p + 1 p + 1","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmsurv.dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmsurv.dr","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmsurv.dr","text":"Newton-Raphson algorithm used solve estimating equation bar S_n (delta) = 0","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmsurv.dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmsurv.dr","text":"","code":"twoarmsurv.dr(   ynew,   dnew,   trt,   x.cate,   tau0,   weightsurv,   ps,   f1.predictor,   f0.predictor,   error.maxNR = 0.001,   max.iterNR = 100,   tune = c(0.5, 2) )"},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmsurv.dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmsurv.dr","text":"ynew Truncated survival time; vector size n dnew Event indicator truncation; vector size n trt Treatment received; vector size n treatment coded 0/1. x.cate Matrix p.cate baseline covariates specified outcome model; dimension n p.cate. tau0 truncation time defining restricted mean time lost. weightsurv Estimated inverse probability censoring weights truncation observations; vector size n. ps Estimated propensity scores observations; vector size n f1.predictor Initial predictions outcome (restricted mean time loss) conditioned covariates x.cate treatment group trt = 1; mu_1(x.cate), step 1 two regression; vector size n f0.predictor Initial predictions outcome (restricted mean time loss) conditioned covariates x.cate treatment group trt = 0; mu_0(x.cate), step 1 two regression; vector size n error.maxNR numerical value > 0 indicating minimum value mean absolute error Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 0.001. max.iterNR positive integer indicating maximum number iterations Newton Raphson algorithm. Used score.method = 'contrastReg'. Default 100. tune vector 2 numerical values > 0 specifying tuning parameters Newton Raphson algorithm. tune[1] step size, tune[2] specifies quantity added diagonal slope matrix prevent singularity. Used score.method = 'contrastReg'. Default c(0.5, 2).","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/reference/twoarmsurv.dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust estimators of the coefficients in the contrast regression\n as well as their covariance matrix and convergence information — twoarmsurv.dr","text":"coef: Doubly robust estimators contrast regression coefficients delta_0; vector size p.cate + 1 (intercept included)         converge: Indicator Newton Raphson algorithm converged delta_0; boolean","code":""},{"path":"https://smartdata-analysis-and-statistics.github.io/precmed/news/index.html","id":"precmed-1009000","dir":"Changelog","previous_headings":"","what":"precmed 1.0.0.9000","title":"precmed 1.0.0.9000","text":"Added NEWS.md file track changes package.","code":""}]
